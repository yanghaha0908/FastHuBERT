[2023-07-04 09:52:33,556][HYDRA] Launching 1 jobs locally
[2023-07-04 09:52:33,557][HYDRA] 	#0 : common.user_dir=/mnt/lustre/sjtu/home/gry10/FastHuBERT task.data=/mnt/lustre/sjtu/home/gry10/fairseq/bpe_manifest task.label_dir=/mnt/lustre/sjtu/home/gry10/fairseq/bpe_manifest task.labels=[wp] dataset.train_subset=train_clean_100 dataset.valid_subset=dev_other dataset.num_workers=2 dataset.skip_invalid_size_inputs_valid_test=True model.w2v_path=/mnt/lustre/sjtu/home/gry10/fairseq/fasthubert_pretrain_ckpt/checkpoint20.pt model.mask_prob=0.65 checkpoint.save_dir=/mnt/lustre/sjtu/home/gry10/fairseq/debug distributed_training.distributed_world_size=1 optimization.update_freq=[8] optimization.lr=[3e-05] optimization.max_update=80000 lr_scheduler.warmup_steps=8000 lr_scheduler.hold_steps=32000 lr_scheduler.decay_steps=40000 task._name=fasthubert_pretraining dataset.max_tokens=8750 task.stats_npz_path=/data/ygr/librispeech/npyfiles/global_cmvn.npy criterion._name=fasthubert_ctc_bpe criterion.bert_tokenizer=/mnt/lustre/sjtu/home/gry10/fairseq/bpe_txt/librispeech960_vocab2000.json dataset.validate_after_updates=20000
[2023-07-04 09:52:35,279][fairseq_cli.train][INFO] - {'_name': None, 'common': {'_name': None, 'no_progress_bar': False, 'log_interval': 200, 'log_format': 'json', 'log_file': None, 'aim_repo': None, 'aim_run_hash': None, 'tensorboard_logdir': 'tblog', 'wandb_project': None, 'azureml_logging': False, 'seed': 1337, 'cpu': False, 'tpu': False, 'bf16': False, 'memory_efficient_bf16': False, 'fp16': True, 'memory_efficient_fp16': False, 'fp16_no_flatten_grads': False, 'fp16_init_scale': 128, 'fp16_scale_window': None, 'fp16_scale_tolerance': 0.0, 'on_cpu_convert_precision': False, 'min_loss_scale': 0.0001, 'threshold_loss_scale': None, 'amp': False, 'amp_batch_retries': 2, 'amp_init_scale': 128, 'amp_scale_window': None, 'user_dir': '/mnt/lustre/sjtu/home/gry10/FastHuBERT', 'empty_cache_freq': 0, 'all_gather_list_size': 16384, 'model_parallel_size': 1, 'quantization_config_path': None, 'profile': False, 'reset_logging': False, 'suppress_crashes': False, 'use_plasma_view': False, 'plasma_path': '/tmp/plasma'}, 'common_eval': {'_name': None, 'path': None, 'post_process': None, 'quiet': False, 'model_overrides': '{}', 'results_path': None}, 'distributed_training': {'_name': None, 'distributed_world_size': 1, 'distributed_num_procs': 1, 'distributed_rank': 0, 'distributed_backend': 'nccl', 'distributed_init_method': None, 'distributed_port': -1, 'device_id': 0, 'distributed_no_spawn': False, 'ddp_backend': 'c10d', 'ddp_comm_hook': 'none', 'bucket_cap_mb': 25, 'fix_batches_to_gpus': False, 'find_unused_parameters': True, 'gradient_as_bucket_view': False, 'fast_stat_sync': False, 'heartbeat_timeout': -1, 'broadcast_buffers': False, 'slowmo_momentum': None, 'slowmo_base_algorithm': 'localsgd', 'localsgd_frequency': 3, 'nprocs_per_node': 8, 'pipeline_model_parallel': False, 'pipeline_balance': None, 'pipeline_devices': None, 'pipeline_chunks': 0, 'pipeline_encoder_balance': None, 'pipeline_encoder_devices': None, 'pipeline_decoder_balance': None, 'pipeline_decoder_devices': None, 'pipeline_checkpoint': 'never', 'zero_sharding': 'none', 'fp16': True, 'memory_efficient_fp16': False, 'tpu': False, 'no_reshard_after_forward': False, 'fp32_reduce_scatter': False, 'cpu_offload': False, 'use_sharded_state': False, 'not_fsdp_flatten_parameters': False}, 'dataset': {'_name': None, 'num_workers': 2, 'skip_invalid_size_inputs_valid_test': True, 'max_tokens': 8750, 'batch_size': None, 'required_batch_size_multiple': 8, 'required_seq_len_multiple': 1, 'dataset_impl': None, 'data_buffer_size': 10, 'train_subset': 'train_clean_100', 'valid_subset': 'dev_other', 'combine_valid_subsets': None, 'ignore_unused_valid_subsets': False, 'validate_interval': 5, 'validate_interval_updates': 0, 'validate_after_updates': 20000, 'fixed_validation_seed': None, 'disable_validation': False, 'max_tokens_valid': 8750, 'batch_size_valid': None, 'max_valid_steps': None, 'curriculum': 0, 'gen_subset': 'test', 'num_shards': 1, 'shard_id': 0, 'grouped_shuffling': False, 'update_epoch_batch_itr': False, 'update_ordered_indices_seed': False}, 'optimization': {'_name': None, 'max_epoch': 0, 'max_update': 80000, 'stop_time_hours': 0.0, 'clip_norm': 0.0, 'sentence_avg': True, 'update_freq': [8], 'lr': [3e-05], 'stop_min_lr': -1.0, 'use_bmuf': False, 'skip_remainder_batch': False, 'debug_param_names': False}, 'checkpoint': {'_name': None, 'save_dir': '/mnt/lustre/sjtu/home/gry10/fairseq/debug', 'restore_file': 'checkpoint_last.pt', 'continue_once': None, 'finetune_from_model': None, 'reset_dataloader': False, 'reset_lr_scheduler': False, 'reset_meters': False, 'reset_optimizer': False, 'optimizer_overrides': '{}', 'save_interval': 5, 'save_interval_updates': 0, 'keep_interval_updates': 1, 'keep_interval_updates_pattern': -1, 'keep_last_epochs': -1, 'keep_best_checkpoints': -1, 'no_save': False, 'no_epoch_checkpoints': True, 'no_last_checkpoints': False, 'no_save_optimizer_state': False, 'best_checkpoint_metric': 'wer', 'maximize_best_checkpoint_metric': False, 'patience': -1, 'checkpoint_suffix': '', 'checkpoint_shard_count': 1, 'load_checkpoint_on_all_dp_ranks': False, 'write_checkpoints_asynchronously': False, 'model_parallel_size': 1}, 'bmuf': {'_name': None, 'block_lr': 1.0, 'block_momentum': 0.875, 'global_sync_iter': 50, 'warmup_iterations': 500, 'use_nbm': False, 'average_sync': False, 'distributed_world_size': 1}, 'generation': {'_name': None, 'beam': 5, 'beam_mt': 0, 'nbest': 1, 'max_len_a': 0.0, 'max_len_b': 200, 'max_len_a_mt': 0.0, 'max_len_b_mt': 200, 'min_len': 1, 'match_source_len': False, 'unnormalized': False, 'no_early_stop': False, 'no_beamable_mm': False, 'lenpen': 1.0, 'lenpen_mt': 1.0, 'unkpen': 0.0, 'replace_unk': None, 'sacrebleu': False, 'score_reference': False, 'prefix_size': 0, 'no_repeat_ngram_size': 0, 'sampling': False, 'sampling_topk': -1, 'sampling_topp': -1.0, 'constraints': None, 'temperature': 1.0, 'diverse_beam_groups': -1, 'diverse_beam_strength': 0.5, 'diversity_rate': -1.0, 'print_alignment': None, 'print_step': False, 'lm_path': None, 'lm_weight': 0.0, 'iter_decode_eos_penalty': 0.0, 'iter_decode_max_iter': 10, 'iter_decode_force_max_iter': False, 'iter_decode_with_beam': 1, 'iter_decode_with_external_reranker': False, 'retain_iter_history': False, 'retain_dropout': False, 'retain_dropout_modules': None, 'decoding_format': None, 'no_seed_provided': False, 'eos_token': None}, 'eval_lm': {'_name': None, 'output_word_probs': False, 'output_word_stats': False, 'context_window': 0, 'softmax_batch': 9223372036854775807}, 'interactive': {'_name': None, 'buffer_size': 0, 'input': '-'}, 'model': {'_name': 'hubert_ctc', 'w2v_path': '/mnt/lustre/sjtu/home/gry10/fairseq/fasthubert_pretrain_ckpt/checkpoint20.pt', 'no_pretrained_weights': False, 'dropout_input': 0.0, 'final_dropout': 0.0, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_embed_dim': 768, 'apply_mask': True, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_channel_length': 64, 'mask_channel_prob': 0.5, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'freeze_finetune_updates': 10000, 'feature_grad_mult': 0.0, 'layerdrop': 0.1, 'normalize': False, 'data': '/mnt/lustre/sjtu/home/gry10/fairseq/bpe_manifest', 'w2v_args': None, 'conv_kernel_sizes': '5', 'conv_channels': 1024, 'input_feat_per_channel': 80, 'input_channels': 1, 'fbank_encoder_dim': 512}, 'task': {'_name': 'fasthubert_pretraining', 'data': '/mnt/lustre/sjtu/home/gry10/fairseq/bpe_manifest', 'fine_tuning': True, 'labels': ['wp'], 'label_dir': '/mnt/lustre/sjtu/home/gry10/fairseq/bpe_manifest', 'label_rate': -1.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': None, 'min_sample_size': None, 'single_target': True, 'random_crop': False, 'pad_audio': True, 'stats_npz_path': '/data/ygr/librispeech/npyfiles/global_cmvn.npy'}, 'criterion': {'_name': 'fasthubert_ctc_bpe', 'zero_infinity': True, 'sentence_avg': '${optimization.sentence_avg}', 'post_process': 'letter', 'wer_kenlm_model': None, 'wer_lexicon': None, 'wer_lm_weight': 2.0, 'wer_word_score': -1.0, 'wer_args': None, 'bert_tokenizer': '/mnt/lustre/sjtu/home/gry10/fairseq/bpe_txt/librispeech960_vocab2000.json'}, 'optimizer': {'_name': 'adam', 'adam_betas': '(0.9,0.98)', 'adam_eps': 1e-08, 'weight_decay': 0.0, 'use_old_adam': False, 'fp16_adam_stats': False, 'tpu': False, 'lr': [3e-05]}, 'lr_scheduler': {'_name': 'tri_stage', 'warmup_steps': 8000, 'hold_steps': 32000, 'decay_steps': 40000, 'phase_ratio': None, 'init_lr_scale': 0.01, 'final_lr_scale': 0.05, 'max_update': 80000.0, 'lr': [3e-05]}, 'scoring': None, 'bpe': None, 'tokenizer': None, 'ema': {'_name': None, 'store_ema': False, 'ema_decay': 0.9999, 'ema_start_update': 0, 'ema_seed_model': None, 'ema_update_freq': 1, 'ema_fp32': False}, 'job_logging_cfg': {'version': 1, 'formatters': {'simple': {'format': '[%(asctime)s][%(name)s][%(levelname)s] - %(message)s'}}, 'handlers': {'console': {'class': 'logging.StreamHandler', 'formatter': 'simple', 'stream': 'ext://sys.stdout'}, 'file': {'class': 'logging.FileHandler', 'formatter': 'simple', 'filename': 'hydra_train.log'}}, 'root': {'level': 'INFO', 'handlers': ['console', 'file']}, 'disable_existing_loggers': False}}
[2023-07-04 09:52:35,290][fairseq.tasks.hubert_pretraining][INFO] - current directory is /mnt/lustre/sjtu/home/gry10/fairseq/multirun/2023-07-04/09-52-32/0
[2023-07-04 09:52:35,290][fairseq.tasks.hubert_pretraining][INFO] - HubertPretrainingTask Config {'_name': 'fasthubert_pretraining', 'data': '/mnt/lustre/sjtu/home/gry10/fairseq/bpe_manifest', 'fine_tuning': True, 'labels': ['wp'], 'label_dir': '/mnt/lustre/sjtu/home/gry10/fairseq/bpe_manifest', 'label_rate': -1.0, 'sample_rate': 16000, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': None, 'min_sample_size': None, 'single_target': True, 'random_crop': False, 'pad_audio': True, 'stats_npz_path': '/data/ygr/librispeech/npyfiles/global_cmvn.npy'}
[2023-07-04 09:52:38,332][fairseq.tasks.hubert_pretraining][INFO] - current directory is /mnt/lustre/sjtu/home/gry10/fairseq/multirun/2023-07-04/09-52-32/0
[2023-07-04 09:52:38,333][fairseq.tasks.hubert_pretraining][INFO] - HubertPretrainingTask Config {'_name': 'fasthubert_pretraining', 'data': '/mnt/lustre/sjtu/home/gry10/fairseq/bpe_manifest', 'fine_tuning': False, 'labels': ['phn'], 'label_dir': '/mnt/lustre/sjtu/home/gry10/wav2vec-U/origin', 'label_rate': 50.0, 'sample_rate': 100, 'normalize': False, 'enable_padding': False, 'max_keep_size': None, 'max_sample_size': 1562, 'min_sample_size': 200, 'single_target': False, 'random_crop': True, 'pad_audio': False, 'stats_npz_path': '/data/ygr/librispeech/npyfiles/global_cmvn.npy'}
[2023-07-04 09:52:38,346][fairseq.models.hubert.hubert][INFO] - HubertModel Config: {'_name': 'fasthubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 64, 'mask_channel_prob': 0.5, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'input_feat_per_channel': 80, 'input_channels': 1, 'conv_channels': 1024, 'fbank_encoder_dim': 512, 'conv_kernel_sizes': '5,5', 'ils': True, 'predict_layers': '[3,11]', 'freq_mask_F': 30, 'freq_mask_N': 2, 'time_mask_N': 2, 'time_mask_T': 40, 'time_mask_p': 1.0, 'time_wrap_W': 0}
[2023-07-04 09:52:40,872][FastHuBERT.model.fasthubert][INFO] - FastHubertModelConfig: {'_name': 'fasthubert', 'label_rate': 50.0, 'extractor_mode': default, 'encoder_layers': 12, 'encoder_embed_dim': 768, 'encoder_ffn_embed_dim': 3072, 'encoder_attention_heads': 12, 'activation_fn': gelu, 'layer_type': transformer, 'dropout': 0.0, 'attention_dropout': 0.0, 'activation_dropout': 0.1, 'encoder_layerdrop': 0.1, 'dropout_input': 0.0, 'dropout_features': 0.1, 'final_dim': 256, 'untie_final_proj': True, 'layer_norm_first': False, 'conv_feature_layers': '[(512,10,5)] + [(512,3,2)] * 4 + [(512,2,2)] * 2', 'conv_bias': False, 'logit_temp': 0.1, 'target_glu': False, 'feature_grad_mult': 0.0, 'mask_length': 10, 'mask_prob': 0.65, 'mask_selection': static, 'mask_other': 0.0, 'no_mask_overlap': False, 'mask_min_space': 1, 'mask_channel_length': 64, 'mask_channel_prob': 0.5, 'mask_channel_selection': static, 'mask_channel_other': 0.0, 'no_mask_channel_overlap': False, 'mask_channel_min_space': 1, 'conv_pos': 128, 'conv_pos_groups': 16, 'latent_temp': [2.0, 0.5, 0.999995], 'skip_masked': False, 'skip_nomask': False, 'checkpoint_activations': False, 'required_seq_len_multiple': 2, 'depthwise_conv_kernel_size': 31, 'attn_type': '', 'pos_enc_type': 'abs', 'fp16': False, 'input_feat_per_channel': 80, 'input_channels': 1, 'conv_channels': 1024, 'fbank_encoder_dim': 512, 'conv_kernel_sizes': '5,5', 'ils': True, 'predict_layers': '[3,11]', 'freq_mask_F': 30, 'freq_mask_N': 2, 'time_mask_N': 2, 'time_mask_T': 40, 'time_mask_p': 1.0, 'time_wrap_W': 0}
[2023-07-04 09:52:41,815][fairseq_cli.train][INFO] - task: HubertFbankPretrainingTask
[2023-07-04 09:52:41,815][fairseq_cli.train][INFO] - model: HubertCtc
[2023-07-04 09:52:41,815][fairseq_cli.train][INFO] - criterion: CtcBpeCriterion
[2023-07-04 09:52:41,945][fairseq_cli.train][INFO] - num. shared model params: 98,953,295 (num. trained: 98,953,295)
[2023-07-04 09:52:41,946][fairseq_cli.train][INFO] - num. expert model params: 0 (num. trained: 0)
[2023-07-04 09:52:41,985][FastHuBERT.data.hubert_fbank_dataset][INFO] - max_keep=None, min_keep=None, loaded 2864, skipped 0 short and 0 long, longest-loaded=3514, shortest-loaded=105
[2023-07-04 09:52:41,991][fairseq.data.audio.hubert_dataset][INFO] - /mnt/lustre/sjtu/home/gry10/fairseq/bpe_manifest/dev_other.wp is sequence label. skipped
[2023-07-04 09:52:41,991][FastHuBERT.data.hubert_fbank_dataset][INFO] - pad_audio=True, random_crop=False, normalize=False, max_sample_size=9223372036854775807
[2023-07-04 09:52:45,710][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias <- w2v_encoder.w2v_model.feature_extractor.conv_layers.1.0.bias
[2023-07-04 09:52:45,711][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias <- w2v_encoder.w2v_model.feature_extractor.conv_layers.2.0.bias
[2023-07-04 09:52:45,711][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias <- w2v_encoder.w2v_model.feature_extractor.conv_layers.3.0.bias
[2023-07-04 09:52:45,711][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias <- w2v_encoder.w2v_model.feature_extractor.conv_layers.4.0.bias
[2023-07-04 09:52:45,711][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias <- w2v_encoder.w2v_model.feature_extractor.conv_layers.5.0.bias
[2023-07-04 09:52:45,711][fairseq.trainer][INFO] - detected shared parameter: w2v_encoder.w2v_model.feature_extractor.conv_layers.0.0.bias <- w2v_encoder.w2v_model.feature_extractor.conv_layers.6.0.bias
[2023-07-04 09:52:45,713][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-07-04 09:52:45,713][fairseq.utils][INFO] - rank   0: capabilities =  8.6  ; total memory = 23.700 GB ; name = NVIDIA GeForce RTX 3090                 
[2023-07-04 09:52:45,713][fairseq.utils][INFO] - ***********************CUDA enviroments for all 1 workers***********************
[2023-07-04 09:52:45,714][fairseq_cli.train][INFO] - training on 1 devices (GPUs/TPUs)
[2023-07-04 09:52:45,714][fairseq_cli.train][INFO] - max tokens per device = 8750 and max sentences per device = None
[2023-07-04 09:52:45,720][fairseq.trainer][INFO] - Preparing to load checkpoint /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_last.pt
[2023-07-04 09:52:45,720][fairseq.trainer][INFO] - No existing checkpoint found /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_last.pt
[2023-07-04 09:52:45,720][fairseq.trainer][INFO] - loading train data for epoch 1
[2023-07-04 09:52:45,775][FastHuBERT.data.hubert_fbank_dataset][INFO] - max_keep=None, min_keep=None, loaded 28539, skipped 0 short and 0 long, longest-loaded=2451, shortest-loaded=139
[2023-07-04 09:52:45,815][fairseq.data.audio.hubert_dataset][INFO] - /mnt/lustre/sjtu/home/gry10/fairseq/bpe_manifest/train_clean_100.wp is sequence label. skipped
[2023-07-04 09:52:45,815][FastHuBERT.data.hubert_fbank_dataset][INFO] - pad_audio=True, random_crop=False, normalize=False, max_sample_size=9223372036854775807
[2023-07-04 09:52:45,924][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 09:52:45,928][fairseq.trainer][INFO] - begin training epoch 1
[2023-07-04 09:52:45,928][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 09:52:49,937][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2023-07-04 09:52:50,322][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
[2023-07-04 09:52:50,679][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2023-07-04 09:52:51,060][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 8.0
[2023-07-04 09:52:51,382][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 4.0
[2023-07-04 09:52:51,705][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 2.0
[2023-07-04 09:52:52,045][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 1.0
[2023-07-04 09:52:52,527][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.5
[2023-07-04 09:53:46,006][train_inner][INFO] - {"epoch": 1, "update": 0.359, "loss": "3068.72", "ntokens": "2486.83", "nsentences": "49.24", "nll_loss": "60.762", "wps": "9330.5", "ups": "3.75", "wpb": "2486.8", "bsz": "49.2", "num_updates": "200", "lr": "1.0425e-06", "gnorm": "2032.76", "loss_scale": "0.5", "train_wall": "58.87", "gb_free": "21.6", "wall": "60"}
[2023-07-04 09:54:39,204][train_inner][INFO] - {"epoch": 1, "update": 0.705, "loss": "3117.59", "ntokens": "2499.03", "nsentences": "48.465", "nll_loss": "60.461", "wps": "9400.7", "ups": "3.76", "wpb": "2499", "bsz": "48.5", "num_updates": "400", "lr": "1.785e-06", "gnorm": "2090.76", "loss_scale": "0.5", "train_wall": "52.26", "gb_free": "21.6", "wall": "113"}
[2023-07-04 09:55:22,661][fairseq_cli.train][INFO] - end of epoch 1 (average epoch stats below)
[2023-07-04 09:55:22,675][train][INFO] - {"epoch": 1, "train_loss": "3062.28", "train_ntokens": "2492.96", "train_nsentences": "49.2802", "train_nll_loss": "60.534", "train_wps": "9491.1", "train_ups": "3.81", "train_wpb": "2493", "train_bsz": "49.3", "train_num_updates": "571", "train_lr": "2.41984e-06", "train_gnorm": "2066.06", "train_loss_scale": "0.5", "train_train_wall": "153.81", "train_gb_free": "21.6", "train_wall": "157"}
[2023-07-04 09:55:22,734][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 09:55:22,743][fairseq.trainer][INFO] - begin training epoch 2
[2023-07-04 09:55:22,743][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 09:55:29,897][train_inner][INFO] - {"epoch": 2, "update": 1.05, "loss": "2997.24", "ntokens": "2495.16", "nsentences": "50.225", "nll_loss": "60.331", "wps": "9846.1", "ups": "3.95", "wpb": "2495.2", "bsz": "50.2", "num_updates": "600", "lr": "2.5275e-06", "gnorm": "2084.62", "loss_scale": "0.5", "train_wall": "49.49", "gb_free": "21.6", "wall": "164"}
[2023-07-04 09:56:29,927][train_inner][INFO] - {"epoch": 2, "update": 1.396, "loss": "3073.74", "ntokens": "2495.37", "nsentences": "48.885", "nll_loss": "60.215", "wps": "8314.8", "ups": "3.33", "wpb": "2495.4", "bsz": "48.9", "num_updates": "800", "lr": "3.27e-06", "gnorm": "2188.14", "loss_scale": "0.5", "train_wall": "59.02", "gb_free": "21.6", "wall": "224"}
[2023-07-04 09:57:18,143][train_inner][INFO] - {"epoch": 2, "update": 1.741, "loss": "2982.13", "ntokens": "2487.59", "nsentences": "49.935", "nll_loss": "59.862", "wps": "10320.2", "ups": "4.15", "wpb": "2487.6", "bsz": "49.9", "num_updates": "1000", "lr": "4.0125e-06", "gnorm": "2240.23", "loss_scale": "0.5", "train_wall": "47.38", "gb_free": "21.6", "wall": "272"}
[2023-07-04 09:57:54,750][fairseq_cli.train][INFO] - end of epoch 2 (average epoch stats below)
[2023-07-04 09:57:54,758][train][INFO] - {"epoch": 2, "train_loss": "3028.05", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "59.856", "train_wps": "9493.6", "train_ups": "3.81", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "1150", "train_lr": "4.56937e-06", "train_gnorm": "2245.62", "train_loss_scale": "0.5", "train_train_wall": "149.16", "train_gb_free": "21.6", "train_wall": "309"}
[2023-07-04 09:57:54,774][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 09:57:54,779][fairseq.trainer][INFO] - begin training epoch 3
[2023-07-04 09:57:54,779][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 09:58:07,475][train_inner][INFO] - {"epoch": 3, "update": 2.086, "loss": "3034.86", "ntokens": "2501.84", "nsentences": "48.86", "nll_loss": "59.27", "wps": "10144.2", "ups": "4.05", "wpb": "2501.8", "bsz": "48.9", "num_updates": "1200", "lr": "4.755e-06", "gnorm": "2371.54", "loss_scale": "0.5", "train_wall": "48.15", "gb_free": "21.6", "wall": "322"}
[2023-07-04 09:58:33,057][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
[2023-07-04 09:58:56,347][train_inner][INFO] - {"epoch": 3, "update": 2.434, "loss": "2972.16", "ntokens": "2485.8", "nsentences": "49.33", "nll_loss": "58.982", "wps": "10174.4", "ups": "4.09", "wpb": "2485.8", "bsz": "49.3", "num_updates": "1400", "lr": "5.4975e-06", "gnorm": "2447.88", "loss_scale": "0.25", "train_wall": "48.02", "gb_free": "21.6", "wall": "371"}
[2023-07-04 09:59:45,046][train_inner][INFO] - {"epoch": 3, "update": 2.779, "loss": "2938.25", "ntokens": "2498.58", "nsentences": "49.505", "nll_loss": "58.216", "wps": "10262.9", "ups": "4.11", "wpb": "2498.6", "bsz": "49.5", "num_updates": "1600", "lr": "6.24e-06", "gnorm": "2575.9", "loss_scale": "0.25", "train_wall": "47.9", "gb_free": "21.6", "wall": "419"}
[2023-07-04 10:00:15,402][fairseq_cli.train][INFO] - end of epoch 3 (average epoch stats below)
[2023-07-04 10:00:15,410][train][INFO] - {"epoch": 3, "train_loss": "2958.11", "train_ntokens": "2493.34", "train_nsentences": "49.2924", "train_nll_loss": "58.481", "train_wps": "10246.7", "train_ups": "4.11", "train_wpb": "2493.3", "train_bsz": "49.3", "train_num_updates": "1728", "train_lr": "6.7152e-06", "train_gnorm": "2540.76", "train_loss_scale": "0.25", "train_train_wall": "137.98", "train_gb_free": "21.6", "train_wall": "450"}
[2023-07-04 10:00:15,431][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 10:00:15,436][fairseq.trainer][INFO] - begin training epoch 4
[2023-07-04 10:00:15,436][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 10:00:33,243][train_inner][INFO] - {"epoch": 4, "update": 3.124, "loss": "2914.48", "ntokens": "2488.4", "nsentences": "49.275", "nll_loss": "57.712", "wps": "10327.8", "ups": "4.15", "wpb": "2488.4", "bsz": "49.3", "num_updates": "1800", "lr": "6.9825e-06", "gnorm": "2688.9", "loss_scale": "0.25", "train_wall": "47.1", "gb_free": "21.6", "wall": "468"}
[2023-07-04 10:01:21,485][train_inner][INFO] - {"epoch": 4, "update": 3.47, "loss": "2883.59", "ntokens": "2489.31", "nsentences": "49.085", "nll_loss": "56.859", "wps": "10321.4", "ups": "4.15", "wpb": "2489.3", "bsz": "49.1", "num_updates": "2000", "lr": "7.725e-06", "gnorm": "2829.44", "loss_scale": "0.25", "train_wall": "47.41", "gb_free": "21.6", "wall": "516"}
[2023-07-04 10:02:10,509][train_inner][INFO] - {"epoch": 4, "update": 3.815, "loss": "2833.39", "ntokens": "2499.17", "nsentences": "49.23", "nll_loss": "55.814", "wps": "10196.8", "ups": "4.08", "wpb": "2499.2", "bsz": "49.2", "num_updates": "2200", "lr": "8.4675e-06", "gnorm": "2949.65", "loss_scale": "0.25", "train_wall": "48.22", "gb_free": "21.6", "wall": "565"}
[2023-07-04 10:02:36,048][fairseq_cli.train][INFO] - end of epoch 4 (average epoch stats below)
[2023-07-04 10:02:36,054][train][INFO] - {"epoch": 4, "train_loss": "2846.27", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "56.263", "train_wps": "10265.7", "train_ups": "4.12", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "2307", "train_lr": "8.86474e-06", "train_gnorm": "2890.61", "train_loss_scale": "0.25", "train_train_wall": "138.01", "train_gb_free": "21.6", "train_wall": "590"}
[2023-07-04 10:02:36,070][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 10:02:36,075][fairseq.trainer][INFO] - begin training epoch 5
[2023-07-04 10:02:36,076][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 10:02:58,991][train_inner][INFO] - {"epoch": 5, "update": 4.161, "loss": "2738.68", "ntokens": "2493.57", "nsentences": "49.98", "nll_loss": "54.893", "wps": "10288", "ups": "4.13", "wpb": "2493.6", "bsz": "50", "num_updates": "2400", "lr": "9.21e-06", "gnorm": "3023.74", "loss_scale": "0.25", "train_wall": "47.45", "gb_free": "21.6", "wall": "613"}
[2023-07-04 10:03:47,924][train_inner][INFO] - {"epoch": 5, "update": 4.506, "loss": "2719.73", "ntokens": "2494.24", "nsentences": "49.34", "nll_loss": "53.8", "wps": "10195.8", "ups": "4.09", "wpb": "2494.2", "bsz": "49.3", "num_updates": "2600", "lr": "9.9525e-06", "gnorm": "3196.54", "loss_scale": "0.25", "train_wall": "48.09", "gb_free": "21.6", "wall": "662"}
[2023-07-04 10:04:36,547][train_inner][INFO] - {"epoch": 5, "update": 4.851, "loss": "2669.75", "ntokens": "2493.7", "nsentences": "49.175", "nll_loss": "52.647", "wps": "10259.2", "ups": "4.11", "wpb": "2493.7", "bsz": "49.2", "num_updates": "2800", "lr": "1.0695e-05", "gnorm": "3339.72", "loss_scale": "0.25", "train_wall": "47.82", "gb_free": "21.6", "wall": "711"}
[2023-07-04 10:04:57,215][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 5 @ 2886 updates
[2023-07-04 10:04:57,217][fairseq.trainer][INFO] - Saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_last.pt
[2023-07-04 10:05:00,620][fairseq.trainer][INFO] - Finished saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_last.pt
[2023-07-04 10:05:00,737][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_last.pt (epoch 5 @ 2886 updates, score None) (writing took 3.5222884844988585 seconds)
[2023-07-04 10:05:00,738][fairseq_cli.train][INFO] - end of epoch 5 (average epoch stats below)
[2023-07-04 10:05:00,766][train][INFO] - {"epoch": 5, "train_loss": "2692.05", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "53.214", "train_wps": "9978.7", "train_ups": "4", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "2886", "train_lr": "1.10143e-05", "train_gnorm": "3257.79", "train_loss_scale": "0.25", "train_train_wall": "138.53", "train_gb_free": "21.6", "train_wall": "735"}
[2023-07-04 10:05:00,789][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 10:05:00,804][fairseq.trainer][INFO] - begin training epoch 6
[2023-07-04 10:05:00,804][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 10:05:28,889][train_inner][INFO] - {"epoch": 6, "update": 5.197, "loss": "2634.88", "ntokens": "2493.05", "nsentences": "48.56", "nll_loss": "51.323", "wps": "9527.5", "ups": "3.82", "wpb": "2493.1", "bsz": "48.6", "num_updates": "3000", "lr": "1.14375e-05", "gnorm": "3479.89", "loss_scale": "0.25", "train_wall": "47.69", "gb_free": "21.6", "wall": "763"}
[2023-07-04 10:06:17,050][train_inner][INFO] - {"epoch": 6, "update": 5.542, "loss": "2499.33", "ntokens": "2488.39", "nsentences": "49.715", "nll_loss": "49.933", "wps": "10335.2", "ups": "4.15", "wpb": "2488.4", "bsz": "49.7", "num_updates": "3200", "lr": "1.218e-05", "gnorm": "3548.08", "loss_scale": "0.25", "train_wall": "47.34", "gb_free": "21.6", "wall": "811"}
[2023-07-04 10:06:54,711][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
[2023-07-04 10:07:06,199][train_inner][INFO] - {"epoch": 6, "update": 5.889, "loss": "2416.39", "ntokens": "2487.97", "nsentences": "49.89", "nll_loss": "48.455", "wps": "10125.7", "ups": "4.07", "wpb": "2488", "bsz": "49.9", "num_updates": "3400", "lr": "1.29225e-05", "gnorm": "3676.77", "loss_scale": "0.25", "train_wall": "48.2", "gb_free": "21.6", "wall": "860"}
[2023-07-04 10:07:21,813][fairseq_cli.train][INFO] - end of epoch 6 (average epoch stats below)
[2023-07-04 10:07:21,820][train][INFO] - {"epoch": 6, "train_loss": "2495.34", "train_ntokens": "2493.35", "train_nsentences": "49.2941", "train_nll_loss": "49.333", "train_wps": "10217.5", "train_ups": "4.1", "train_wpb": "2493.4", "train_bsz": "49.3", "train_num_updates": "3464", "train_lr": "1.31601e-05", "train_gnorm": "3626.62", "train_loss_scale": "0.25", "train_train_wall": "138.26", "train_gb_free": "21.6", "train_wall": "876"}
[2023-07-04 10:07:21,945][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 10:07:21,950][fairseq.trainer][INFO] - begin training epoch 7
[2023-07-04 10:07:21,950][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 10:07:55,199][train_inner][INFO] - {"epoch": 7, "update": 6.235, "loss": "2442.46", "ntokens": "2504.28", "nsentences": "47.965", "nll_loss": "46.781", "wps": "10246.5", "ups": "4.09", "wpb": "2504.3", "bsz": "48", "num_updates": "3600", "lr": "1.3665e-05", "gnorm": "3897.2", "loss_scale": "0.25", "train_wall": "47.7", "gb_free": "21.6", "wall": "909"}
[2023-07-04 10:08:43,010][train_inner][INFO] - {"epoch": 7, "update": 6.58, "loss": "2224.7", "ntokens": "2490.13", "nsentences": "50.645", "nll_loss": "45.247", "wps": "10418.6", "ups": "4.18", "wpb": "2490.1", "bsz": "50.6", "num_updates": "3800", "lr": "1.44075e-05", "gnorm": "3887.12", "loss_scale": "0.25", "train_wall": "47.11", "gb_free": "21.6", "wall": "957"}
[2023-07-04 10:09:30,140][train_inner][INFO] - {"epoch": 7, "update": 6.926, "loss": "2225.57", "ntokens": "2495.8", "nsentences": "48.62", "nll_loss": "43.356", "wps": "10592.9", "ups": "4.24", "wpb": "2495.8", "bsz": "48.6", "num_updates": "4000", "lr": "1.515e-05", "gnorm": "4131.83", "loss_scale": "0.25", "train_wall": "46.45", "gb_free": "21.6", "wall": "1004"}
[2023-07-04 10:09:40,393][fairseq_cli.train][INFO] - end of epoch 7 (average epoch stats below)
[2023-07-04 10:09:40,400][train][INFO] - {"epoch": 7, "train_loss": "2261.28", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "44.699", "train_wps": "10418.7", "train_ups": "4.18", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "4043", "train_lr": "1.53096e-05", "train_gnorm": "3988.46", "train_loss_scale": "0.25", "train_train_wall": "136", "train_gb_free": "21.6", "train_wall": "1015"}
[2023-07-04 10:09:40,418][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 10:09:40,423][fairseq.trainer][INFO] - begin training epoch 8
[2023-07-04 10:09:40,423][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 10:10:19,649][train_inner][INFO] - {"epoch": 8, "update": 7.271, "loss": "2078.6", "ntokens": "2493.2", "nsentences": "49.9", "nll_loss": "41.602", "wps": "10073.7", "ups": "4.04", "wpb": "2493.2", "bsz": "49.9", "num_updates": "4200", "lr": "1.58925e-05", "gnorm": "4120.02", "loss_scale": "0.25", "train_wall": "48.4", "gb_free": "21.6", "wall": "1054"}
[2023-07-04 10:11:07,320][train_inner][INFO] - {"epoch": 8, "update": 7.617, "loss": "2049.09", "ntokens": "2505.35", "nsentences": "48.5", "nll_loss": "39.667", "wps": "10512.5", "ups": "4.2", "wpb": "2505.3", "bsz": "48.5", "num_updates": "4400", "lr": "1.6635e-05", "gnorm": "4343.4", "loss_scale": "0.25", "train_wall": "46.95", "gb_free": "21.6", "wall": "1102"}
[2023-07-04 10:11:55,759][train_inner][INFO] - {"epoch": 8, "update": 7.962, "loss": "1891.02", "ntokens": "2481.96", "nsentences": "49.5", "nll_loss": "37.714", "wps": "10249.5", "ups": "4.13", "wpb": "2482", "bsz": "49.5", "num_updates": "4600", "lr": "1.73775e-05", "gnorm": "4322.77", "loss_scale": "0.25", "train_wall": "47.71", "gb_free": "21.6", "wall": "1150"}
[2023-07-04 10:12:00,773][fairseq_cli.train][INFO] - end of epoch 8 (average epoch stats below)
[2023-07-04 10:12:00,780][train][INFO] - {"epoch": 8, "train_loss": "1989.99", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "39.337", "train_wps": "10285.1", "train_ups": "4.12", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "4622", "train_lr": "1.74592e-05", "train_gnorm": "4280.4", "train_loss_scale": "0.25", "train_train_wall": "137.92", "train_gb_free": "21.6", "train_wall": "1155"}
[2023-07-04 10:12:00,797][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 10:12:00,801][fairseq.trainer][INFO] - begin training epoch 9
[2023-07-04 10:12:00,802][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 10:12:43,014][train_inner][INFO] - {"epoch": 9, "update": 8.307, "loss": "1803.52", "ntokens": "2486.54", "nsentences": "49.13", "nll_loss": "35.635", "wps": "10525.7", "ups": "4.23", "wpb": "2486.5", "bsz": "49.1", "num_updates": "4800", "lr": "1.812e-05", "gnorm": "4456.4", "loss_scale": "0.25", "train_wall": "46.26", "gb_free": "21.6", "wall": "1197"}
[2023-07-04 10:13:31,043][train_inner][INFO] - {"epoch": 9, "update": 8.653, "loss": "1705.8", "ntokens": "2497.75", "nsentences": "49.16", "nll_loss": "33.573", "wps": "10403", "ups": "4.16", "wpb": "2497.8", "bsz": "49.2", "num_updates": "5000", "lr": "1.88625e-05", "gnorm": "4551.15", "loss_scale": "0.25", "train_wall": "47.27", "gb_free": "21.6", "wall": "1245"}
[2023-07-04 10:14:19,805][train_inner][INFO] - {"epoch": 9, "update": 8.998, "loss": "1582.28", "ntokens": "2497.55", "nsentences": "49.48", "nll_loss": "31.347", "wps": "10246", "ups": "4.1", "wpb": "2497.6", "bsz": "49.5", "num_updates": "5200", "lr": "1.9605e-05", "gnorm": "4606.23", "loss_scale": "0.25", "train_wall": "48.03", "gb_free": "21.6", "wall": "1294"}
[2023-07-04 10:14:20,005][fairseq_cli.train][INFO] - end of epoch 9 (average epoch stats below)
[2023-07-04 10:14:20,014][train][INFO] - {"epoch": 9, "train_loss": "1689.6", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "33.399", "train_wps": "10369.9", "train_ups": "4.16", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "5201", "train_lr": "1.96087e-05", "train_gnorm": "4541.01", "train_loss_scale": "0.25", "train_train_wall": "136.8", "train_gb_free": "21.6", "train_wall": "1294"}
[2023-07-04 10:14:20,031][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 10:14:20,041][fairseq.trainer][INFO] - begin training epoch 10
[2023-07-04 10:14:20,041][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 10:15:07,159][train_inner][INFO] - {"epoch": 10, "update": 9.344, "loss": "1453.88", "ntokens": "2496.09", "nsentences": "50.135", "nll_loss": "29.202", "wps": "10544.4", "ups": "4.22", "wpb": "2496.1", "bsz": "50.1", "num_updates": "5400", "lr": "2.03475e-05", "gnorm": "4700.81", "loss_scale": "0.5", "train_wall": "46.32", "gb_free": "21.6", "wall": "1341"}
[2023-07-04 10:15:07,366][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 0.25
[2023-07-04 10:15:54,666][train_inner][INFO] - {"epoch": 10, "update": 9.691, "loss": "1367.24", "ntokens": "2490.88", "nsentences": "48.835", "nll_loss": "26.805", "wps": "10488", "ups": "4.21", "wpb": "2490.9", "bsz": "48.8", "num_updates": "5600", "lr": "2.109e-05", "gnorm": "4762.16", "loss_scale": "0.25", "train_wall": "46.82", "gb_free": "21.6", "wall": "1389"}
[2023-07-04 10:16:37,710][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 10 @ 5779 updates
[2023-07-04 10:16:37,712][fairseq.trainer][INFO] - Saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_last.pt
[2023-07-04 10:16:41,218][fairseq.trainer][INFO] - Finished saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_last.pt
[2023-07-04 10:16:41,361][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_last.pt (epoch 10 @ 5779 updates, score None) (writing took 3.6504276115447283 seconds)
[2023-07-04 10:16:41,361][fairseq_cli.train][INFO] - end of epoch 10 (average epoch stats below)
[2023-07-04 10:16:41,368][train][INFO] - {"epoch": 10, "train_loss": "1361.16", "train_ntokens": "2493.51", "train_nsentences": "49.301", "train_nll_loss": "26.913", "train_wps": "10196.5", "train_ups": "4.09", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "5779", "train_lr": "2.17545e-05", "train_gnorm": "4678.29", "train_loss_scale": "0.25", "train_train_wall": "135.32", "train_gb_free": "21.6", "train_wall": "1436"}
[2023-07-04 10:16:41,385][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 10:16:41,390][fairseq.trainer][INFO] - begin training epoch 11
[2023-07-04 10:16:41,391][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 10:16:46,371][train_inner][INFO] - {"epoch": 11, "update": 10.036, "loss": "1240.41", "ntokens": "2491.18", "nsentences": "48.965", "nll_loss": "24.381", "wps": "9637.7", "ups": "3.87", "wpb": "2491.2", "bsz": "49", "num_updates": "5800", "lr": "2.18325e-05", "gnorm": "4545.38", "loss_scale": "0.25", "train_wall": "47.02", "gb_free": "21.6", "wall": "1441"}
[2023-07-04 10:17:33,643][train_inner][INFO] - {"epoch": 11, "update": 10.382, "loss": "1115.96", "ntokens": "2500.66", "nsentences": "49.76", "nll_loss": "22.206", "wps": "10581.3", "ups": "4.23", "wpb": "2500.7", "bsz": "49.8", "num_updates": "6000", "lr": "2.2575e-05", "gnorm": "4278.33", "loss_scale": "0.25", "train_wall": "46.56", "gb_free": "21.6", "wall": "1488"}
[2023-07-04 10:18:21,744][train_inner][INFO] - {"epoch": 11, "update": 10.727, "loss": "1023.82", "ntokens": "2486.76", "nsentences": "48.81", "nll_loss": "20.095", "wps": "10341.6", "ups": "4.16", "wpb": "2486.8", "bsz": "48.8", "num_updates": "6200", "lr": "2.33175e-05", "gnorm": "4009.72", "loss_scale": "0.25", "train_wall": "47.39", "gb_free": "21.6", "wall": "1536"}
[2023-07-04 10:19:00,219][fairseq_cli.train][INFO] - end of epoch 11 (average epoch stats below)
[2023-07-04 10:19:00,226][train][INFO] - {"epoch": 11, "train_loss": "1033.48", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "20.429", "train_wps": "10397.9", "train_ups": "4.17", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "6358", "train_lr": "2.39041e-05", "train_gnorm": "4014.64", "train_loss_scale": "0.25", "train_train_wall": "136.48", "train_gb_free": "21.6", "train_wall": "1575"}
[2023-07-04 10:19:00,249][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 10:19:00,258][fairseq.trainer][INFO] - begin training epoch 12
[2023-07-04 10:19:00,258][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 10:19:10,376][train_inner][INFO] - {"epoch": 12, "update": 11.073, "loss": "921.529", "ntokens": "2491.76", "nsentences": "48.735", "nll_loss": "18.024", "wps": "10248.8", "ups": "4.11", "wpb": "2491.8", "bsz": "48.7", "num_updates": "6400", "lr": "2.406e-05", "gnorm": "3630.82", "loss_scale": "0.25", "train_wall": "47.59", "gb_free": "21.6", "wall": "1585"}
[2023-07-04 10:19:56,554][train_inner][INFO] - {"epoch": 12, "update": 11.418, "loss": "814.771", "ntokens": "2482.91", "nsentences": "49.47", "nll_loss": "16.234", "wps": "10755.7", "ups": "4.33", "wpb": "2482.9", "bsz": "49.5", "num_updates": "6600", "lr": "2.48025e-05", "gnorm": "3164.94", "loss_scale": "0.25", "train_wall": "45.53", "gb_free": "21.6", "wall": "1631"}
[2023-07-04 10:20:43,940][train_inner][INFO] - {"epoch": 12, "update": 11.763, "loss": "741.068", "ntokens": "2507.29", "nsentences": "49.35", "nll_loss": "14.586", "wps": "10584.4", "ups": "4.22", "wpb": "2507.3", "bsz": "49.4", "num_updates": "6800", "lr": "2.5545e-05", "gnorm": "2761.78", "loss_scale": "0.25", "train_wall": "46.72", "gb_free": "21.6", "wall": "1678"}
[2023-07-04 10:21:13,773][fairseq_cli.train][INFO] - end of epoch 12 (average epoch stats below)
[2023-07-04 10:21:13,782][train][INFO] - {"epoch": 12, "train_loss": "762.803", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "15.079", "train_wps": "10810.8", "train_ups": "4.34", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "6937", "train_lr": "2.60536e-05", "train_gnorm": "2871.32", "train_loss_scale": "0.25", "train_train_wall": "131.39", "train_gb_free": "21.6", "train_wall": "1708"}
[2023-07-04 10:21:13,802][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 10:21:13,808][fairseq.trainer][INFO] - begin training epoch 13
[2023-07-04 10:21:13,809][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 10:21:27,320][train_inner][INFO] - {"epoch": 13, "update": 12.109, "loss": "664.791", "ntokens": "2495.78", "nsentences": "49.675", "nll_loss": "13.232", "wps": "11508.6", "ups": "4.61", "wpb": "2495.8", "bsz": "49.7", "num_updates": "7000", "lr": "2.62875e-05", "gnorm": "2320.22", "loss_scale": "0.25", "train_wall": "42.54", "gb_free": "21.6", "wall": "1722"}
[2023-07-04 10:22:13,886][train_inner][INFO] - {"epoch": 13, "update": 12.454, "loss": "620.66", "ntokens": "2491.41", "nsentences": "48.575", "nll_loss": "12.101", "wps": "10702.1", "ups": "4.3", "wpb": "2491.4", "bsz": "48.6", "num_updates": "7200", "lr": "2.703e-05", "gnorm": "1932.83", "loss_scale": "0.25", "train_wall": "45.91", "gb_free": "21.6", "wall": "1768"}
[2023-07-04 10:23:03,588][train_inner][INFO] - {"epoch": 13, "update": 12.8, "loss": "566.138", "ntokens": "2496.84", "nsentences": "49.17", "nll_loss": "11.149", "wps": "10049", "ups": "4.02", "wpb": "2496.8", "bsz": "49.2", "num_updates": "7400", "lr": "2.77725e-05", "gnorm": "1511.68", "loss_scale": "0.25", "train_wall": "48.88", "gb_free": "21.6", "wall": "1818"}
[2023-07-04 10:23:32,061][fairseq_cli.train][INFO] - end of epoch 13 (average epoch stats below)
[2023-07-04 10:23:32,068][train][INFO] - {"epoch": 13, "train_loss": "584.09", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "11.546", "train_wps": "10440.8", "train_ups": "4.19", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "7516", "train_lr": "2.82032e-05", "train_gnorm": "1669.51", "train_loss_scale": "0.5", "train_train_wall": "135.95", "train_gb_free": "21.6", "train_wall": "1846"}
[2023-07-04 10:23:32,088][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 10:23:32,096][fairseq.trainer][INFO] - begin training epoch 14
[2023-07-04 10:23:32,097][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 10:23:52,844][train_inner][INFO] - {"epoch": 14, "update": 13.145, "loss": "517.48", "ntokens": "2492.51", "nsentences": "50.24", "nll_loss": "10.431", "wps": "10122.4", "ups": "4.06", "wpb": "2492.5", "bsz": "50.2", "num_updates": "7600", "lr": "2.8515e-05", "gnorm": "1140.1", "loss_scale": "0.5", "train_wall": "48.2", "gb_free": "21.6", "wall": "1867"}
[2023-07-04 10:24:38,863][train_inner][INFO] - {"epoch": 14, "update": 13.491, "loss": "502.77", "ntokens": "2496.97", "nsentences": "49.04", "nll_loss": "9.874", "wps": "10853.8", "ups": "4.35", "wpb": "2497", "bsz": "49", "num_updates": "7800", "lr": "2.92575e-05", "gnorm": "876.267", "loss_scale": "0.5", "train_wall": "45.37", "gb_free": "21.6", "wall": "1913"}
[2023-07-04 10:25:25,367][train_inner][INFO] - {"epoch": 14, "update": 13.836, "loss": "482.873", "ntokens": "2493.72", "nsentences": "48.84", "nll_loss": "9.457", "wps": "10726.6", "ups": "4.3", "wpb": "2493.7", "bsz": "48.8", "num_updates": "8000", "lr": "3e-05", "gnorm": "618.661", "loss_scale": "0.5", "train_wall": "45.85", "gb_free": "21.6", "wall": "1960"}
[2023-07-04 10:25:48,165][fairseq_cli.train][INFO] - end of epoch 14 (average epoch stats below)
[2023-07-04 10:25:48,173][train][INFO] - {"epoch": 14, "train_loss": "489.55", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "9.677", "train_wps": "10608.2", "train_ups": "4.25", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "8095", "train_lr": "3e-05", "train_gnorm": "742.822", "train_loss_scale": "0.5", "train_train_wall": "133.83", "train_gb_free": "21.6", "train_wall": "1982"}
[2023-07-04 10:25:48,189][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 10:25:48,194][fairseq.trainer][INFO] - begin training epoch 15
[2023-07-04 10:25:48,195][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 10:26:13,679][train_inner][INFO] - {"epoch": 15, "update": 14.181, "loss": "458.906", "ntokens": "2488.85", "nsentences": "49.65", "nll_loss": "9.155", "wps": "10304.7", "ups": "4.14", "wpb": "2488.8", "bsz": "49.6", "num_updates": "8200", "lr": "3e-05", "gnorm": "406.894", "loss_scale": "0.5", "train_wall": "47.3", "gb_free": "21.6", "wall": "2008"}
[2023-07-04 10:27:00,725][train_inner][INFO] - {"epoch": 15, "update": 14.527, "loss": "448.182", "ntokens": "2492.35", "nsentences": "49.555", "nll_loss": "8.911", "wps": "10596.8", "ups": "4.25", "wpb": "2492.3", "bsz": "49.6", "num_updates": "8400", "lr": "3e-05", "gnorm": "261.15", "loss_scale": "0.5", "train_wall": "46.35", "gb_free": "21.6", "wall": "2055"}
[2023-07-04 10:27:47,326][train_inner][INFO] - {"epoch": 15, "update": 14.872, "loss": "444.778", "ntokens": "2490.58", "nsentences": "49.055", "nll_loss": "8.76", "wps": "10690.3", "ups": "4.29", "wpb": "2490.6", "bsz": "49.1", "num_updates": "8600", "lr": "3e-05", "gnorm": "159.396", "loss_scale": "0.5", "train_wall": "45.94", "gb_free": "21.6", "wall": "2102"}
[2023-07-04 10:28:03,908][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 15 @ 8674 updates
[2023-07-04 10:28:03,909][fairseq.trainer][INFO] - Saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_last.pt
[2023-07-04 10:28:06,836][fairseq.trainer][INFO] - Finished saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_last.pt
[2023-07-04 10:28:06,948][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_last.pt (epoch 15 @ 8674 updates, score None) (writing took 3.0403693169355392 seconds)
[2023-07-04 10:28:06,949][fairseq_cli.train][INFO] - end of epoch 15 (average epoch stats below)
[2023-07-04 10:28:06,957][train][INFO] - {"epoch": 15, "train_loss": "448.222", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "8.86", "train_wps": "10403.5", "train_ups": "4.17", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "8674", "train_lr": "3e-05", "train_gnorm": "226.474", "train_loss_scale": "0.5", "train_train_wall": "133.47", "train_gb_free": "21.6", "train_wall": "2121"}
[2023-07-04 10:28:06,973][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 10:28:06,977][fairseq.trainer][INFO] - begin training epoch 16
[2023-07-04 10:28:06,978][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 10:28:37,797][train_inner][INFO] - {"epoch": 16, "update": 15.218, "loss": "439.343", "ntokens": "2499.7", "nsentences": "49.035", "nll_loss": "8.618", "wps": "9906.8", "ups": "3.96", "wpb": "2499.7", "bsz": "49", "num_updates": "8800", "lr": "3e-05", "gnorm": "96.103", "loss_scale": "0.5", "train_wall": "46.45", "gb_free": "21.6", "wall": "2152"}
[2023-07-04 10:29:27,009][train_inner][INFO] - {"epoch": 16, "update": 15.563, "loss": "429.032", "ntokens": "2496.25", "nsentences": "49.465", "nll_loss": "8.502", "wps": "10146.7", "ups": "4.06", "wpb": "2496.2", "bsz": "49.5", "num_updates": "9000", "lr": "3e-05", "gnorm": "68.06", "loss_scale": "0.5", "train_wall": "45.02", "gb_free": "21.6", "wall": "2201"}
[2023-07-04 10:30:14,904][train_inner][INFO] - {"epoch": 16, "update": 15.908, "loss": "423.093", "ntokens": "2490.3", "nsentences": "49.26", "nll_loss": "8.369", "wps": "10400.9", "ups": "4.18", "wpb": "2490.3", "bsz": "49.3", "num_updates": "9200", "lr": "3e-05", "gnorm": "59.84", "loss_scale": "0.5", "train_wall": "47.21", "gb_free": "21.6", "wall": "2249"}
[2023-07-04 10:30:27,546][fairseq_cli.train][INFO] - end of epoch 16 (average epoch stats below)
[2023-07-04 10:30:27,555][train][INFO] - {"epoch": 16, "train_loss": "427.942", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "8.459", "train_wps": "10269.3", "train_ups": "4.12", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "9253", "train_lr": "3e-05", "train_gnorm": "67.985", "train_loss_scale": "0.5", "train_train_wall": "134.79", "train_gb_free": "21.6", "train_wall": "2262"}
[2023-07-04 10:30:27,571][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 10:30:27,576][fairseq.trainer][INFO] - begin training epoch 17
[2023-07-04 10:30:27,576][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 10:31:02,772][train_inner][INFO] - {"epoch": 17, "update": 16.254, "loss": "413.377", "ntokens": "2489.26", "nsentences": "49.745", "nll_loss": "8.261", "wps": "10402.3", "ups": "4.18", "wpb": "2489.3", "bsz": "49.7", "num_updates": "9400", "lr": "3e-05", "gnorm": "53.113", "loss_scale": "0.5", "train_wall": "46.88", "gb_free": "21.6", "wall": "2297"}
[2023-07-04 10:31:49,749][train_inner][INFO] - {"epoch": 17, "update": 16.599, "loss": "414.533", "ntokens": "2497.82", "nsentences": "49.205", "nll_loss": "8.166", "wps": "10636.2", "ups": "4.26", "wpb": "2497.8", "bsz": "49.2", "num_updates": "9600", "lr": "3e-05", "gnorm": "56.848", "loss_scale": "1", "train_wall": "46.31", "gb_free": "21.6", "wall": "2344"}
[2023-07-04 10:32:36,574][train_inner][INFO] - {"epoch": 17, "update": 16.945, "loss": "409.971", "ntokens": "2490.43", "nsentences": "48.975", "nll_loss": "8.062", "wps": "10639", "ups": "4.27", "wpb": "2490.4", "bsz": "49", "num_updates": "9800", "lr": "3e-05", "gnorm": "49.969", "loss_scale": "1", "train_wall": "46.17", "gb_free": "21.6", "wall": "2391"}
[2023-07-04 10:32:44,276][fairseq_cli.train][INFO] - end of epoch 17 (average epoch stats below)
[2023-07-04 10:32:44,283][train][INFO] - {"epoch": 17, "train_loss": "411.816", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "8.14", "train_wps": "10559.8", "train_ups": "4.23", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "9832", "train_lr": "3e-05", "train_gnorm": "53.438", "train_loss_scale": "1", "train_train_wall": "134.48", "train_gb_free": "21.6", "train_wall": "2399"}
[2023-07-04 10:32:44,297][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 10:32:44,302][fairseq.trainer][INFO] - begin training epoch 18
[2023-07-04 10:32:44,302][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 10:33:24,586][train_inner][INFO] - {"epoch": 18, "update": 17.29, "loss": "399.206", "ntokens": "2495.12", "nsentences": "49.89", "nll_loss": "7.982", "wps": "10395.7", "ups": "4.17", "wpb": "2495.1", "bsz": "49.9", "num_updates": "10000", "lr": "3e-05", "gnorm": "48.131", "loss_scale": "1", "train_wall": "47.06", "gb_free": "21.6", "wall": "2439"}
[2023-07-04 10:34:49,703][train_inner][INFO] - {"epoch": 18, "update": 17.636, "loss": "270.103", "ntokens": "2498.96", "nsentences": "48.44", "nll_loss": "5.236", "wps": "5872.2", "ups": "2.35", "wpb": "2499", "bsz": "48.4", "num_updates": "10200", "lr": "3e-05", "gnorm": "182.636", "loss_scale": "1", "train_wall": "84.33", "gb_free": "20.8", "wall": "2524"}
[2023-07-04 10:36:11,577][train_inner][INFO] - {"epoch": 18, "update": 17.981, "loss": "210.756", "ntokens": "2489.38", "nsentences": "49.85", "nll_loss": "4.22", "wps": "6081.6", "ups": "2.44", "wpb": "2489.4", "bsz": "49.9", "num_updates": "10400", "lr": "3e-05", "gnorm": "119.86", "loss_scale": "1", "train_wall": "81.14", "gb_free": "20.8", "wall": "2606"}
[2023-07-04 10:36:16,591][fairseq_cli.train][INFO] - end of epoch 18 (average epoch stats below)
[2023-07-04 10:36:16,599][train][INFO] - {"epoch": 18, "train_loss": "286.212", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "5.658", "train_wps": "6800.3", "train_ups": "2.73", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "10411", "train_lr": "3e-05", "train_gnorm": "120.976", "train_loss_scale": "1", "train_train_wall": "209.9", "train_gb_free": "20.8", "train_wall": "2611"}
[2023-07-04 10:36:16,620][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 10:36:16,626][fairseq.trainer][INFO] - begin training epoch 19
[2023-07-04 10:36:16,627][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 10:37:38,114][train_inner][INFO] - {"epoch": 19, "update": 18.326, "loss": "189.879", "ntokens": "2481.38", "nsentences": "48.96", "nll_loss": "3.747", "wps": "5735.4", "ups": "2.31", "wpb": "2481.4", "bsz": "49", "num_updates": "10600", "lr": "3e-05", "gnorm": "118.992", "loss_scale": "1", "train_wall": "85.44", "gb_free": "20.8", "wall": "2692"}
[2023-07-04 10:39:02,805][train_inner][INFO] - {"epoch": 19, "update": 18.672, "loss": "172.846", "ntokens": "2500.63", "nsentences": "49.265", "nll_loss": "3.405", "wps": "5905.8", "ups": "2.36", "wpb": "2500.6", "bsz": "49.3", "num_updates": "10800", "lr": "3e-05", "gnorm": "115.158", "loss_scale": "1", "train_wall": "83.9", "gb_free": "20.7", "wall": "2777"}
[2023-07-04 10:40:24,393][fairseq_cli.train][INFO] - end of epoch 19 (average epoch stats below)
[2023-07-04 10:40:24,400][train][INFO] - {"epoch": 19, "train_loss": "174.056", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "3.441", "train_wps": "5826.4", "train_ups": "2.34", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "10990", "train_lr": "3e-05", "train_gnorm": "115.66", "train_loss_scale": "1", "train_train_wall": "245.21", "train_gb_free": "20.8", "train_wall": "2859"}
[2023-07-04 10:40:24,418][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 10:40:24,423][fairseq.trainer][INFO] - begin training epoch 20
[2023-07-04 10:40:24,423][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 10:40:29,019][train_inner][INFO] - {"epoch": 20, "update": 19.017, "loss": "160.556", "ntokens": "2494.39", "nsentences": "49.375", "nll_loss": "3.178", "wps": "5787", "ups": "2.32", "wpb": "2494.4", "bsz": "49.4", "num_updates": "11000", "lr": "3e-05", "gnorm": "114.549", "loss_scale": "1", "train_wall": "85.14", "gb_free": "20.8", "wall": "2863"}
[2023-07-04 10:41:52,024][train_inner][INFO] - {"epoch": 20, "update": 19.363, "loss": "149.353", "ntokens": "2501.09", "nsentences": "49.845", "nll_loss": "2.977", "wps": "6027", "ups": "2.41", "wpb": "2501.1", "bsz": "49.8", "num_updates": "11200", "lr": "3e-05", "gnorm": "112.333", "loss_scale": "1", "train_wall": "82.25", "gb_free": "20.9", "wall": "2946"}
[2023-07-04 10:43:14,827][train_inner][INFO] - {"epoch": 20, "update": 19.708, "loss": "141.765", "ntokens": "2483.16", "nsentences": "49.425", "nll_loss": "2.822", "wps": "5998.4", "ups": "2.42", "wpb": "2483.2", "bsz": "49.4", "num_updates": "11400", "lr": "3e-05", "gnorm": "117.166", "loss_scale": "1", "train_wall": "82.03", "gb_free": "20.8", "wall": "3029"}
[2023-07-04 10:44:25,604][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 20 @ 11569 updates
[2023-07-04 10:44:25,605][fairseq.trainer][INFO] - Saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_last.pt
[2023-07-04 10:44:29,661][fairseq.trainer][INFO] - Finished saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_last.pt
[2023-07-04 10:44:29,747][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_last.pt (epoch 20 @ 11569 updates, score None) (writing took 4.143525747582316 seconds)
[2023-07-04 10:44:29,748][fairseq_cli.train][INFO] - end of epoch 20 (average epoch stats below)
[2023-07-04 10:44:29,755][train][INFO] - {"epoch": 20, "train_loss": "143.561", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "2.838", "train_wps": "5884.5", "train_ups": "2.36", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "11569", "train_lr": "3e-05", "train_gnorm": "113.469", "train_loss_scale": "2", "train_train_wall": "238.21", "train_gb_free": "20.8", "train_wall": "3104"}
[2023-07-04 10:44:29,769][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 10:44:29,773][fairseq.trainer][INFO] - begin training epoch 21
[2023-07-04 10:44:29,773][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 10:44:42,517][train_inner][INFO] - {"epoch": 21, "update": 20.054, "loss": "137.524", "ntokens": "2500.55", "nsentences": "48.59", "nll_loss": "2.672", "wps": "5734.9", "ups": "2.29", "wpb": "2500.6", "bsz": "48.6", "num_updates": "11600", "lr": "3e-05", "gnorm": "110.043", "loss_scale": "2", "train_wall": "81.99", "gb_free": "20.7", "wall": "3117"}
[2023-07-04 10:46:05,888][train_inner][INFO] - {"epoch": 21, "update": 20.399, "loss": "126.496", "ntokens": "2481.89", "nsentences": "49.675", "nll_loss": "2.532", "wps": "5954.3", "ups": "2.4", "wpb": "2481.9", "bsz": "49.7", "num_updates": "11800", "lr": "3e-05", "gnorm": "112.309", "loss_scale": "2", "train_wall": "82.59", "gb_free": "20.8", "wall": "3200"}
[2023-07-04 10:47:31,039][train_inner][INFO] - {"epoch": 21, "update": 20.744, "loss": "125.405", "ntokens": "2496.48", "nsentences": "48.82", "nll_loss": "2.452", "wps": "5864.2", "ups": "2.35", "wpb": "2496.5", "bsz": "48.8", "num_updates": "12000", "lr": "3e-05", "gnorm": "110.277", "loss_scale": "2", "train_wall": "84.36", "gb_free": "20.8", "wall": "3285"}
[2023-07-04 10:48:34,008][fairseq_cli.train][INFO] - end of epoch 21 (average epoch stats below)
[2023-07-04 10:48:34,015][train][INFO] - {"epoch": 21, "train_loss": "125.484", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "2.48", "train_wps": "5910.9", "train_ups": "2.37", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "12148", "train_lr": "3e-05", "train_gnorm": "111.543", "train_loss_scale": "2", "train_train_wall": "241.7", "train_gb_free": "20.8", "train_wall": "3348"}
[2023-07-04 10:48:34,031][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 10:48:34,036][fairseq.trainer][INFO] - begin training epoch 22
[2023-07-04 10:48:34,036][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 10:48:55,321][train_inner][INFO] - {"epoch": 22, "update": 21.09, "loss": "121.32", "ntokens": "2501.84", "nsentences": "49.215", "nll_loss": "2.387", "wps": "5937.4", "ups": "2.37", "wpb": "2501.8", "bsz": "49.2", "num_updates": "12200", "lr": "3e-05", "gnorm": "112.36", "loss_scale": "2", "train_wall": "83.17", "gb_free": "20.8", "wall": "3370"}
[2023-07-04 10:50:16,906][train_inner][INFO] - {"epoch": 22, "update": 21.435, "loss": "115.215", "ntokens": "2493.38", "nsentences": "49.78", "nll_loss": "2.3", "wps": "6113", "ups": "2.45", "wpb": "2493.4", "bsz": "49.8", "num_updates": "12400", "lr": "3e-05", "gnorm": "107.971", "loss_scale": "2", "train_wall": "80.86", "gb_free": "20.7", "wall": "3451"}
[2023-07-04 10:51:41,568][train_inner][INFO] - {"epoch": 22, "update": 21.781, "loss": "112.174", "ntokens": "2493.53", "nsentences": "49.66", "nll_loss": "2.234", "wps": "5891.2", "ups": "2.36", "wpb": "2493.5", "bsz": "49.7", "num_updates": "12600", "lr": "3e-05", "gnorm": "107.017", "loss_scale": "2", "train_wall": "83.87", "gb_free": "20.8", "wall": "3536"}
[2023-07-04 10:52:34,013][fairseq_cli.train][INFO] - end of epoch 22 (average epoch stats below)
[2023-07-04 10:52:34,038][train][INFO] - {"epoch": 22, "train_loss": "113.392", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "2.241", "train_wps": "6015.7", "train_ups": "2.41", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "12727", "train_lr": "3e-05", "train_gnorm": "108.282", "train_loss_scale": "2", "train_train_wall": "237.46", "train_gb_free": "20.8", "train_wall": "3588"}
[2023-07-04 10:52:34,058][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 10:52:34,062][fairseq.trainer][INFO] - begin training epoch 23
[2023-07-04 10:52:34,063][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 10:53:03,192][train_inner][INFO] - {"epoch": 23, "update": 22.126, "loss": "109.201", "ntokens": "2490.4", "nsentences": "48.57", "nll_loss": "2.13", "wps": "6102.8", "ups": "2.45", "wpb": "2490.4", "bsz": "48.6", "num_updates": "12800", "lr": "3e-05", "gnorm": "109.308", "loss_scale": "2", "train_wall": "80.54", "gb_free": "20.8", "wall": "3617"}
[2023-07-04 10:54:24,997][train_inner][INFO] - {"epoch": 23, "update": 22.472, "loss": "106.652", "ntokens": "2498.34", "nsentences": "49.705", "nll_loss": "2.122", "wps": "6108.6", "ups": "2.45", "wpb": "2498.3", "bsz": "49.7", "num_updates": "13000", "lr": "3e-05", "gnorm": "108.174", "loss_scale": "2", "train_wall": "81.02", "gb_free": "20.8", "wall": "3699"}
[2023-07-04 10:55:50,781][train_inner][INFO] - {"epoch": 23, "update": 22.817, "loss": "103.058", "ntokens": "2489.38", "nsentences": "49.28", "nll_loss": "2.04", "wps": "5804.4", "ups": "2.33", "wpb": "2489.4", "bsz": "49.3", "num_updates": "13200", "lr": "3e-05", "gnorm": "109.465", "loss_scale": "2", "train_wall": "85.01", "gb_free": "20.8", "wall": "3785"}
[2023-07-04 10:56:35,348][fairseq_cli.train][INFO] - end of epoch 23 (average epoch stats below)
[2023-07-04 10:56:35,356][train][INFO] - {"epoch": 23, "train_loss": "104.4", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "2.064", "train_wps": "5983", "train_ups": "2.4", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "13306", "train_lr": "3e-05", "train_gnorm": "108.592", "train_loss_scale": "2", "train_train_wall": "238.76", "train_gb_free": "20.8", "train_wall": "3830"}
[2023-07-04 10:56:35,381][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 10:56:35,387][fairseq.trainer][INFO] - begin training epoch 24
[2023-07-04 10:56:35,388][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 10:57:15,163][train_inner][INFO] - {"epoch": 24, "update": 23.162, "loss": "100.612", "ntokens": "2495.43", "nsentences": "49.155", "nll_loss": "1.982", "wps": "5915", "ups": "2.37", "wpb": "2495.4", "bsz": "49.2", "num_updates": "13400", "lr": "3e-05", "gnorm": "106.378", "loss_scale": "2", "train_wall": "83.24", "gb_free": "20.7", "wall": "3869"}
[2023-07-04 10:58:36,573][train_inner][INFO] - {"epoch": 24, "update": 23.508, "loss": "98.34", "ntokens": "2492.39", "nsentences": "49.625", "nll_loss": "1.958", "wps": "6123.7", "ups": "2.46", "wpb": "2492.4", "bsz": "49.6", "num_updates": "13600", "lr": "3e-05", "gnorm": "106.855", "loss_scale": "4", "train_wall": "80.67", "gb_free": "20.8", "wall": "3951"}
[2023-07-04 10:59:57,405][train_inner][INFO] - {"epoch": 24, "update": 23.853, "loss": "96.852", "ntokens": "2492.55", "nsentences": "49.3", "nll_loss": "1.916", "wps": "6168.1", "ups": "2.47", "wpb": "2492.6", "bsz": "49.3", "num_updates": "13800", "lr": "3e-05", "gnorm": "108.737", "loss_scale": "4", "train_wall": "80.11", "gb_free": "20.8", "wall": "4032"}
[2023-07-04 11:00:31,833][fairseq_cli.train][INFO] - end of epoch 24 (average epoch stats below)
[2023-07-04 11:00:31,843][train][INFO] - {"epoch": 24, "train_loss": "98.199", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "1.941", "train_wps": "6105.3", "train_ups": "2.45", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "13885", "train_lr": "3e-05", "train_gnorm": "107.619", "train_loss_scale": "4", "train_train_wall": "233.97", "train_gb_free": "20.8", "train_wall": "4066"}
[2023-07-04 11:00:31,860][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 11:00:31,866][fairseq.trainer][INFO] - begin training epoch 25
[2023-07-04 11:00:31,866][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 11:01:20,193][train_inner][INFO] - {"epoch": 25, "update": 24.199, "loss": "94.707", "ntokens": "2486.03", "nsentences": "48.905", "nll_loss": "1.863", "wps": "6012.2", "ups": "2.42", "wpb": "2486", "bsz": "48.9", "num_updates": "14000", "lr": "3e-05", "gnorm": "107.078", "loss_scale": "4", "train_wall": "81.62", "gb_free": "20.7", "wall": "4114"}
[2023-07-04 11:02:41,347][train_inner][INFO] - {"epoch": 25, "update": 24.544, "loss": "92.508", "ntokens": "2504.49", "nsentences": "49.895", "nll_loss": "1.843", "wps": "6172.8", "ups": "2.46", "wpb": "2504.5", "bsz": "49.9", "num_updates": "14200", "lr": "3e-05", "gnorm": "105.795", "loss_scale": "4", "train_wall": "80.41", "gb_free": "20.9", "wall": "4196"}
[2023-07-04 11:04:07,741][train_inner][INFO] - {"epoch": 25, "update": 24.889, "loss": "92.636", "ntokens": "2496.8", "nsentences": "48.745", "nll_loss": "1.809", "wps": "5781.7", "ups": "2.32", "wpb": "2496.8", "bsz": "48.7", "num_updates": "14400", "lr": "3e-05", "gnorm": "107.971", "loss_scale": "4", "train_wall": "85.55", "gb_free": "20.8", "wall": "4282"}
[2023-07-04 11:04:37,126][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 25 @ 14464 updates
[2023-07-04 11:04:37,128][fairseq.trainer][INFO] - Saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_last.pt
[2023-07-04 11:04:41,035][fairseq.trainer][INFO] - Finished saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_last.pt
[2023-07-04 11:04:41,128][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_last.pt (epoch 25 @ 14464 updates, score None) (writing took 4.001230761408806 seconds)
[2023-07-04 11:04:41,128][fairseq_cli.train][INFO] - end of epoch 25 (average epoch stats below)
[2023-07-04 11:04:41,140][train][INFO] - {"epoch": 25, "train_loss": "92.501", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "1.828", "train_wps": "5791.6", "train_ups": "2.32", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "14464", "train_lr": "3e-05", "train_gnorm": "106.996", "train_loss_scale": "4", "train_train_wall": "242.53", "train_gb_free": "20.7", "train_wall": "4315"}
[2023-07-04 11:04:41,228][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 11:04:41,240][fairseq.trainer][INFO] - begin training epoch 26
[2023-07-04 11:04:41,240][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 11:05:40,171][train_inner][INFO] - {"epoch": 26, "update": 25.235, "loss": "89.284", "ntokens": "2486.17", "nsentences": "48.94", "nll_loss": "1.758", "wps": "5382.4", "ups": "2.16", "wpb": "2486.2", "bsz": "48.9", "num_updates": "14600", "lr": "3e-05", "gnorm": "107.326", "loss_scale": "4", "train_wall": "86.98", "gb_free": "20.8", "wall": "4374"}
[2023-07-04 11:07:09,815][train_inner][INFO] - {"epoch": 26, "update": 25.58, "loss": "87.775", "ntokens": "2495.86", "nsentences": "49.47", "nll_loss": "1.74", "wps": "5571.8", "ups": "2.23", "wpb": "2495.9", "bsz": "49.5", "num_updates": "14800", "lr": "3e-05", "gnorm": "106.946", "loss_scale": "4", "train_wall": "88.71", "gb_free": "20.7", "wall": "4464"}
[2023-07-04 11:08:47,432][train_inner][INFO] - {"epoch": 26, "update": 25.926, "loss": "86.204", "ntokens": "2493.19", "nsentences": "49.61", "nll_loss": "1.715", "wps": "5108.9", "ups": "2.05", "wpb": "2493.2", "bsz": "49.6", "num_updates": "15000", "lr": "3e-05", "gnorm": "106.775", "loss_scale": "4", "train_wall": "96.58", "gb_free": "20.7", "wall": "4562"}
[2023-07-04 11:09:10,021][fairseq_cli.train][INFO] - end of epoch 26 (average epoch stats below)
[2023-07-04 11:09:10,037][train][INFO] - {"epoch": 26, "train_loss": "87.321", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "1.726", "train_wps": "5369.4", "train_ups": "2.15", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "15043", "train_lr": "3e-05", "train_gnorm": "106.809", "train_loss_scale": "4", "train_train_wall": "265.55", "train_gb_free": "20.8", "train_wall": "4584"}
[2023-07-04 11:09:10,102][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 11:09:10,107][fairseq.trainer][INFO] - begin training epoch 27
[2023-07-04 11:09:10,107][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 11:10:24,643][train_inner][INFO] - {"epoch": 27, "update": 26.271, "loss": "86.6", "ntokens": "2500.39", "nsentences": "48.85", "nll_loss": "1.692", "wps": "5145", "ups": "2.06", "wpb": "2500.4", "bsz": "48.9", "num_updates": "15200", "lr": "3e-05", "gnorm": "111.777", "loss_scale": "4", "train_wall": "94.75", "gb_free": "20.7", "wall": "4659"}
[2023-07-04 11:12:03,410][train_inner][INFO] - {"epoch": 27, "update": 26.617, "loss": "84.676", "ntokens": "2489.19", "nsentences": "48.75", "nll_loss": "1.658", "wps": "5043.1", "ups": "2.03", "wpb": "2489.2", "bsz": "48.8", "num_updates": "15400", "lr": "3e-05", "gnorm": "107.745", "loss_scale": "4", "train_wall": "97.57", "gb_free": "20.9", "wall": "4758"}
[2023-07-04 11:13:38,365][train_inner][INFO] - {"epoch": 27, "update": 26.962, "loss": "82.229", "ntokens": "2493.26", "nsentences": "50.095", "nll_loss": "1.652", "wps": "5254.1", "ups": "2.11", "wpb": "2493.3", "bsz": "50.1", "num_updates": "15600", "lr": "3e-05", "gnorm": "104.751", "loss_scale": "4", "train_wall": "93.97", "gb_free": "20.7", "wall": "4853"}
[2023-07-04 11:13:48,651][fairseq_cli.train][INFO] - end of epoch 27 (average epoch stats below)
[2023-07-04 11:13:48,687][train][INFO] - {"epoch": 27, "train_loss": "84.105", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "1.663", "train_wps": "5181.9", "train_ups": "2.08", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "15622", "train_lr": "3e-05", "train_gnorm": "108.186", "train_loss_scale": "4", "train_train_wall": "274.12", "train_gb_free": "20.7", "train_wall": "4863"}
[2023-07-04 11:13:48,751][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 11:13:48,793][fairseq.trainer][INFO] - begin training epoch 28
[2023-07-04 11:13:48,793][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 11:15:13,553][train_inner][INFO] - {"epoch": 28, "update": 27.307, "loss": "79.879", "ntokens": "2488.57", "nsentences": "49.3", "nll_loss": "1.582", "wps": "5229.7", "ups": "2.1", "wpb": "2488.6", "bsz": "49.3", "num_updates": "15800", "lr": "3e-05", "gnorm": "105.951", "loss_scale": "8", "train_wall": "93.24", "gb_free": "20.9", "wall": "4948"}
[2023-07-04 11:16:44,266][train_inner][INFO] - {"epoch": 28, "update": 27.653, "loss": "80.245", "ntokens": "2493.05", "nsentences": "49.31", "nll_loss": "1.587", "wps": "5497.7", "ups": "2.21", "wpb": "2493.1", "bsz": "49.3", "num_updates": "16000", "lr": "3e-05", "gnorm": "106.938", "loss_scale": "8", "train_wall": "89.77", "gb_free": "20.8", "wall": "5039"}
[2023-07-04 11:18:13,210][train_inner][INFO] - {"epoch": 28, "update": 27.998, "loss": "79.172", "ntokens": "2495.99", "nsentences": "49.13", "nll_loss": "1.558", "wps": "5613.5", "ups": "2.25", "wpb": "2496", "bsz": "49.1", "num_updates": "16200", "lr": "3e-05", "gnorm": "106.429", "loss_scale": "8", "train_wall": "87.98", "gb_free": "20.8", "wall": "5127"}
[2023-07-04 11:18:13,645][fairseq_cli.train][INFO] - end of epoch 28 (average epoch stats below)
[2023-07-04 11:18:13,656][train][INFO] - {"epoch": 28, "train_loss": "79.667", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "1.575", "train_wps": "5449", "train_ups": "2.19", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "16201", "train_lr": "3e-05", "train_gnorm": "106.342", "train_loss_scale": "8", "train_train_wall": "261.25", "train_gb_free": "20.8", "train_wall": "5128"}
[2023-07-04 11:18:13,695][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 11:18:13,706][fairseq.trainer][INFO] - begin training epoch 29
[2023-07-04 11:18:13,707][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 11:19:49,868][train_inner][INFO] - {"epoch": 29, "update": 28.344, "loss": "77.412", "ntokens": "2491.21", "nsentences": "49.475", "nll_loss": "1.537", "wps": "5156.7", "ups": "2.07", "wpb": "2491.2", "bsz": "49.5", "num_updates": "16400", "lr": "3e-05", "gnorm": "106.007", "loss_scale": "8", "train_wall": "95.16", "gb_free": "20.8", "wall": "5224"}
[2023-07-04 11:21:16,612][train_inner][INFO] - {"epoch": 29, "update": 28.689, "loss": "76.821", "ntokens": "2495.57", "nsentences": "48.79", "nll_loss": "1.502", "wps": "5755", "ups": "2.31", "wpb": "2495.6", "bsz": "48.8", "num_updates": "16600", "lr": "3e-05", "gnorm": "106.355", "loss_scale": "8", "train_wall": "85.82", "gb_free": "20.7", "wall": "5311"}
[2023-07-04 11:22:42,084][fairseq_cli.train][INFO] - end of epoch 29 (average epoch stats below)
[2023-07-04 11:22:42,100][train][INFO] - {"epoch": 29, "train_loss": "76.638", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "1.515", "train_wps": "5378.5", "train_ups": "2.16", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "16780", "train_lr": "3e-05", "train_gnorm": "106.588", "train_loss_scale": "8", "train_train_wall": "263.56", "train_gb_free": "20.9", "train_wall": "5396"}
[2023-07-04 11:22:42,125][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 11:22:42,132][fairseq.trainer][INFO] - begin training epoch 30
[2023-07-04 11:22:42,132][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 11:22:52,930][train_inner][INFO] - {"epoch": 30, "update": 29.035, "loss": "74.985", "ntokens": "2490.11", "nsentences": "49.805", "nll_loss": "1.5", "wps": "5171.6", "ups": "2.08", "wpb": "2490.1", "bsz": "49.8", "num_updates": "16800", "lr": "3e-05", "gnorm": "106.984", "loss_scale": "8", "train_wall": "93.29", "gb_free": "20.7", "wall": "5407"}
[2023-07-04 11:24:27,266][train_inner][INFO] - {"epoch": 30, "update": 29.38, "loss": "74.207", "ntokens": "2495.99", "nsentences": "48.93", "nll_loss": "1.455", "wps": "5292.7", "ups": "2.12", "wpb": "2496", "bsz": "48.9", "num_updates": "17000", "lr": "3e-05", "gnorm": "106.919", "loss_scale": "8", "train_wall": "92.93", "gb_free": "20.7", "wall": "5502"}
[2023-07-04 11:26:02,063][train_inner][INFO] - {"epoch": 30, "update": 29.725, "loss": "74.793", "ntokens": "2500.82", "nsentences": "48.8", "nll_loss": "1.459", "wps": "5278", "ups": "2.11", "wpb": "2500.8", "bsz": "48.8", "num_updates": "17200", "lr": "3e-05", "gnorm": "107.816", "loss_scale": "8", "train_wall": "93.25", "gb_free": "20.8", "wall": "5596"}
[2023-07-04 11:27:18,177][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 30 @ 17359 updates
[2023-07-04 11:27:18,447][fairseq.trainer][INFO] - Saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_last.pt
[2023-07-04 11:27:22,682][fairseq.trainer][INFO] - Finished saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_last.pt
[2023-07-04 11:27:22,812][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_last.pt (epoch 30 @ 17359 updates, score None) (writing took 4.63503360748291 seconds)
[2023-07-04 11:27:22,812][fairseq_cli.train][INFO] - end of epoch 30 (average epoch stats below)
[2023-07-04 11:27:22,844][train][INFO] - {"epoch": 30, "train_loss": "73.544", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "1.454", "train_wps": "5143.2", "train_ups": "2.06", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "17359", "train_lr": "3e-05", "train_gnorm": "106.642", "train_loss_scale": "8", "train_train_wall": "271.2", "train_gb_free": "20.8", "train_wall": "5677"}
[2023-07-04 11:27:22,870][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 11:27:22,882][fairseq.trainer][INFO] - begin training epoch 31
[2023-07-04 11:27:22,883][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 11:27:42,668][train_inner][INFO] - {"epoch": 31, "update": 30.071, "loss": "72.186", "ntokens": "2485.74", "nsentences": "49.64", "nll_loss": "1.442", "wps": "4945.4", "ups": "1.99", "wpb": "2485.7", "bsz": "49.6", "num_updates": "17400", "lr": "3e-05", "gnorm": "105.413", "loss_scale": "8", "train_wall": "93.9", "gb_free": "20.8", "wall": "5697"}
[2023-07-04 11:29:14,839][train_inner][INFO] - {"epoch": 31, "update": 30.416, "loss": "71.352", "ntokens": "2495.2", "nsentences": "49.465", "nll_loss": "1.414", "wps": "5419.6", "ups": "2.17", "wpb": "2495.2", "bsz": "49.5", "num_updates": "17600", "lr": "3e-05", "gnorm": "104.893", "loss_scale": "8", "train_wall": "89", "gb_free": "20.8", "wall": "5789"}
[2023-07-04 11:30:48,121][train_inner][INFO] - {"epoch": 31, "update": 30.762, "loss": "70.357", "ntokens": "2493.62", "nsentences": "49.315", "nll_loss": "1.391", "wps": "5347.4", "ups": "2.14", "wpb": "2493.6", "bsz": "49.3", "num_updates": "17800", "lr": "3e-05", "gnorm": "106.407", "loss_scale": "16", "train_wall": "90.84", "gb_free": "20.7", "wall": "5882"}
[2023-07-04 11:31:53,215][fairseq_cli.train][INFO] - end of epoch 31 (average epoch stats below)
[2023-07-04 11:31:53,230][train][INFO] - {"epoch": 31, "train_loss": "71.067", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "1.405", "train_wps": "5339.8", "train_ups": "2.14", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "17938", "train_lr": "3e-05", "train_gnorm": "105.8", "train_loss_scale": "16", "train_train_wall": "262.74", "train_gb_free": "20.8", "train_wall": "5948"}
[2023-07-04 11:31:53,275][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 11:31:53,287][fairseq.trainer][INFO] - begin training epoch 32
[2023-07-04 11:31:53,288][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 11:32:22,977][train_inner][INFO] - {"epoch": 32, "update": 31.107, "loss": "70.11", "ntokens": "2484.89", "nsentences": "49.105", "nll_loss": "1.385", "wps": "5240.4", "ups": "2.11", "wpb": "2484.9", "bsz": "49.1", "num_updates": "18000", "lr": "3e-05", "gnorm": "106.262", "loss_scale": "16", "train_wall": "92.8", "gb_free": "20.8", "wall": "5977"}
[2023-07-04 11:34:00,314][train_inner][INFO] - {"epoch": 32, "update": 31.453, "loss": "69.177", "ntokens": "2502.1", "nsentences": "49.275", "nll_loss": "1.362", "wps": "5142", "ups": "2.06", "wpb": "2502.1", "bsz": "49.3", "num_updates": "18200", "lr": "3e-05", "gnorm": "106.369", "loss_scale": "16", "train_wall": "94.11", "gb_free": "20.8", "wall": "6075"}
[2023-07-04 11:35:34,783][train_inner][INFO] - {"epoch": 32, "update": 31.798, "loss": "69.309", "ntokens": "2496.89", "nsentences": "48.955", "nll_loss": "1.359", "wps": "5287.2", "ups": "2.12", "wpb": "2496.9", "bsz": "49", "num_updates": "18400", "lr": "3e-05", "gnorm": "106.993", "loss_scale": "16", "train_wall": "91.8", "gb_free": "20.8", "wall": "6169"}
[2023-07-04 11:36:30,702][fairseq_cli.train][INFO] - end of epoch 32 (average epoch stats below)
[2023-07-04 11:36:30,737][train][INFO] - {"epoch": 32, "train_loss": "68.876", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "1.361", "train_wps": "5203.2", "train_ups": "2.09", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "18517", "train_lr": "3e-05", "train_gnorm": "106.361", "train_loss_scale": "16", "train_train_wall": "269.3", "train_gb_free": "20.8", "train_wall": "6225"}
[2023-07-04 11:36:30,780][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 11:36:30,794][fairseq.trainer][INFO] - begin training epoch 33
[2023-07-04 11:36:30,794][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 11:37:06,270][train_inner][INFO] - {"epoch": 33, "update": 32.143, "loss": "67.35", "ntokens": "2492.51", "nsentences": "49.925", "nll_loss": "1.349", "wps": "5451.7", "ups": "2.19", "wpb": "2492.5", "bsz": "49.9", "num_updates": "18600", "lr": "3e-05", "gnorm": "105.65", "loss_scale": "16", "train_wall": "88.9", "gb_free": "20.8", "wall": "6261"}
[2023-07-04 11:38:39,817][train_inner][INFO] - {"epoch": 33, "update": 32.489, "loss": "67.643", "ntokens": "2490.53", "nsentences": "49.36", "nll_loss": "1.341", "wps": "5325.5", "ups": "2.14", "wpb": "2490.5", "bsz": "49.4", "num_updates": "18800", "lr": "3e-05", "gnorm": "106.463", "loss_scale": "16", "train_wall": "91.83", "gb_free": "20.9", "wall": "6354"}
[2023-07-04 11:40:09,704][train_inner][INFO] - {"epoch": 33, "update": 32.834, "loss": "67.511", "ntokens": "2490.59", "nsentences": "48.725", "nll_loss": "1.321", "wps": "5542.6", "ups": "2.23", "wpb": "2490.6", "bsz": "48.7", "num_updates": "19000", "lr": "3e-05", "gnorm": "107", "loss_scale": "16", "train_wall": "88.07", "gb_free": "20.7", "wall": "6444"}
[2023-07-04 11:40:54,997][fairseq_cli.train][INFO] - end of epoch 33 (average epoch stats below)
[2023-07-04 11:40:55,009][train][INFO] - {"epoch": 33, "train_loss": "66.94", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "1.323", "train_wps": "5463.3", "train_ups": "2.19", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "19096", "train_lr": "3e-05", "train_gnorm": "106.258", "train_loss_scale": "16", "train_train_wall": "259.17", "train_gb_free": "20.9", "train_wall": "6489"}
[2023-07-04 11:40:55,035][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 11:40:55,042][fairseq.trainer][INFO] - begin training epoch 34
[2023-07-04 11:40:55,042][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 11:41:43,594][train_inner][INFO] - {"epoch": 34, "update": 33.18, "loss": "65.125", "ntokens": "2503.5", "nsentences": "49.71", "nll_loss": "1.293", "wps": "5333.8", "ups": "2.13", "wpb": "2503.5", "bsz": "49.7", "num_updates": "19200", "lr": "3e-05", "gnorm": "105.665", "loss_scale": "16", "train_wall": "91.8", "gb_free": "20.8", "wall": "6538"}
[2023-07-04 11:43:15,666][train_inner][INFO] - {"epoch": 34, "update": 33.525, "loss": "64.564", "ntokens": "2488.09", "nsentences": "49.215", "nll_loss": "1.277", "wps": "5405.7", "ups": "2.17", "wpb": "2488.1", "bsz": "49.2", "num_updates": "19400", "lr": "3e-05", "gnorm": "105.792", "loss_scale": "16", "train_wall": "89.95", "gb_free": "20.8", "wall": "6630"}
[2023-07-04 11:44:42,899][train_inner][INFO] - {"epoch": 34, "update": 33.87, "loss": "65.311", "ntokens": "2493.7", "nsentences": "49.305", "nll_loss": "1.291", "wps": "5718.4", "ups": "2.29", "wpb": "2493.7", "bsz": "49.3", "num_updates": "19600", "lr": "3e-05", "gnorm": "107.381", "loss_scale": "16", "train_wall": "85.52", "gb_free": "20.8", "wall": "6717"}
[2023-07-04 11:45:17,749][fairseq_cli.train][INFO] - end of epoch 34 (average epoch stats below)
[2023-07-04 11:45:17,800][train][INFO] - {"epoch": 34, "train_loss": "64.999", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "1.285", "train_wps": "5494.9", "train_ups": "2.2", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "19675", "train_lr": "3e-05", "train_gnorm": "106.642", "train_loss_scale": "16", "train_train_wall": "256.52", "train_gb_free": "20.8", "train_wall": "6752"}
[2023-07-04 11:45:17,898][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 11:45:17,912][fairseq.trainer][INFO] - begin training epoch 35
[2023-07-04 11:45:17,913][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 11:46:14,224][train_inner][INFO] - {"epoch": 35, "update": 34.216, "loss": "63.806", "ntokens": "2496.06", "nsentences": "49.495", "nll_loss": "1.265", "wps": "5467.4", "ups": "2.19", "wpb": "2496.1", "bsz": "49.5", "num_updates": "19800", "lr": "3e-05", "gnorm": "106.726", "loss_scale": "32", "train_wall": "89.32", "gb_free": "20.8", "wall": "6808"}
[2023-07-04 11:47:43,039][train_inner][INFO] - {"epoch": 35, "update": 34.561, "loss": "63.308", "ntokens": "2491.05", "nsentences": "49.275", "nll_loss": "1.252", "wps": "5610.7", "ups": "2.25", "wpb": "2491.1", "bsz": "49.3", "num_updates": "20000", "lr": "3e-05", "gnorm": "107.148", "loss_scale": "32", "train_wall": "87.05", "gb_free": "20.7", "wall": "6897"}
[2023-07-04 11:49:13,555][train_inner][INFO] - {"epoch": 35, "update": 34.907, "loss": "63.478", "ntokens": "2493.23", "nsentences": "49.2", "nll_loss": "1.253", "wps": "5510.1", "ups": "2.21", "wpb": "2493.2", "bsz": "49.2", "num_updates": "20200", "lr": "3e-05", "gnorm": "106.798", "loss_scale": "32", "train_wall": "89.38", "gb_free": "20.8", "wall": "6988"}
[2023-07-04 11:49:36,975][fairseq_cli.train][INFO] - begin validation on "dev_other" subset
[2023-07-04 11:49:58,157][dev_other][INFO] - {"epoch": 35, "dev_other_loss": "41.183", "dev_other_ntokens": "272.352", "dev_other_nsentences": "10.6074", "dev_other_nll_loss": "1.604", "dev_other_uer": "25.423", "dev_other_wer": "25.831", "dev_other_raw_wer": "25.831", "dev_other_wps": "3849", "dev_other_wpb": "272.4", "dev_other_bsz": "10.6", "dev_other_num_updates": "20254"}
[2023-07-04 11:49:58,163][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 35 @ 20254 updates
[2023-07-04 11:49:58,165][fairseq.trainer][INFO] - Saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt
[2023-07-04 11:50:01,632][fairseq.trainer][INFO] - Finished saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt
[2023-07-04 11:50:04,505][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt (epoch 35 @ 20254 updates, score 25.831) (writing took 6.342554925009608 seconds)
[2023-07-04 11:50:04,506][fairseq_cli.train][INFO] - end of epoch 35 (average epoch stats below)
[2023-07-04 11:50:04,518][train][INFO] - {"epoch": 35, "train_loss": "63.295", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "1.251", "train_wps": "5035.6", "train_ups": "2.02", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "20254", "train_lr": "3e-05", "train_gnorm": "106.901", "train_loss_scale": "32", "train_train_wall": "255", "train_gb_free": "20.8", "train_wall": "7039"}
[2023-07-04 11:50:04,549][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 11:50:04,562][fairseq.trainer][INFO] - begin training epoch 36
[2023-07-04 11:50:04,563][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 11:51:14,451][train_inner][INFO] - {"epoch": 36, "update": 35.252, "loss": "62.616", "ntokens": "2490.68", "nsentences": "49.245", "nll_loss": "1.238", "wps": "4121.9", "ups": "1.65", "wpb": "2490.7", "bsz": "49.2", "num_updates": "20400", "lr": "3e-05", "gnorm": "107.152", "loss_scale": "32", "train_wall": "91.95", "gb_free": "20.8", "wall": "7109"}
[2023-07-04 11:52:47,241][train_inner][INFO] - {"epoch": 36, "update": 35.598, "loss": "61.57", "ntokens": "2499.36", "nsentences": "48.835", "nll_loss": "1.203", "wps": "5388", "ups": "2.16", "wpb": "2499.4", "bsz": "48.8", "num_updates": "20600", "lr": "3e-05", "gnorm": "106.563", "loss_scale": "32", "train_wall": "91.67", "gb_free": "20.7", "wall": "7202"}
[2023-07-04 11:54:16,587][train_inner][INFO] - {"epoch": 36, "update": 35.943, "loss": "61.334", "ntokens": "2488.3", "nsentences": "49.63", "nll_loss": "1.223", "wps": "5571.1", "ups": "2.24", "wpb": "2488.3", "bsz": "49.6", "num_updates": "20800", "lr": "3e-05", "gnorm": "106.177", "loss_scale": "32", "train_wall": "88.45", "gb_free": "20.8", "wall": "7291"}
[2023-07-04 11:54:29,460][fairseq_cli.train][INFO] - end of epoch 36 (average epoch stats below)
[2023-07-04 11:54:29,492][train][INFO] - {"epoch": 36, "train_loss": "61.544", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "1.217", "train_wps": "5449.3", "train_ups": "2.19", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "20833", "train_lr": "3e-05", "train_gnorm": "106.357", "train_loss_scale": "32", "train_train_wall": "261.63", "train_gb_free": "20.8", "train_wall": "7304"}
[2023-07-04 11:54:29,522][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 11:54:29,531][fairseq.trainer][INFO] - begin training epoch 37
[2023-07-04 11:54:29,532][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 11:55:47,972][train_inner][INFO] - {"epoch": 37, "update": 36.288, "loss": "58.963", "ntokens": "2487.87", "nsentences": "49.315", "nll_loss": "1.169", "wps": "5447.2", "ups": "2.19", "wpb": "2487.9", "bsz": "49.3", "num_updates": "21000", "lr": "3e-05", "gnorm": "105.309", "loss_scale": "32", "train_wall": "90.03", "gb_free": "20.8", "wall": "7382"}
[2023-07-04 11:57:15,643][train_inner][INFO] - {"epoch": 37, "update": 36.634, "loss": "59.905", "ntokens": "2494.11", "nsentences": "49.105", "nll_loss": "1.179", "wps": "5691.4", "ups": "2.28", "wpb": "2494.1", "bsz": "49.1", "num_updates": "21200", "lr": "3e-05", "gnorm": "106.204", "loss_scale": "32", "train_wall": "86.76", "gb_free": "20.8", "wall": "7470"}
[2023-07-04 11:58:45,813][train_inner][INFO] - {"epoch": 37, "update": 36.979, "loss": "60.324", "ntokens": "2500.25", "nsentences": "49.545", "nll_loss": "1.195", "wps": "5547.8", "ups": "2.22", "wpb": "2500.2", "bsz": "49.5", "num_updates": "21400", "lr": "3e-05", "gnorm": "106.899", "loss_scale": "32", "train_wall": "89.22", "gb_free": "20.8", "wall": "7560"}
[2023-07-04 11:58:51,320][fairseq_cli.train][INFO] - end of epoch 37 (average epoch stats below)
[2023-07-04 11:58:51,343][train][INFO] - {"epoch": 37, "train_loss": "59.881", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "1.184", "train_wps": "5514.1", "train_ups": "2.21", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "21412", "train_lr": "3e-05", "train_gnorm": "106.39", "train_loss_scale": "32", "train_train_wall": "258.7", "train_gb_free": "20.8", "train_wall": "7566"}
[2023-07-04 11:58:51,412][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 11:58:51,420][fairseq.trainer][INFO] - begin training epoch 38
[2023-07-04 11:58:51,420][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 12:00:20,604][train_inner][INFO] - {"epoch": 38, "update": 37.325, "loss": "59.044", "ntokens": "2491.64", "nsentences": "48.58", "nll_loss": "1.151", "wps": "5258.1", "ups": "2.11", "wpb": "2491.6", "bsz": "48.6", "num_updates": "21600", "lr": "3e-05", "gnorm": "106.962", "loss_scale": "32", "train_wall": "92.37", "gb_free": "20.8", "wall": "7655"}
[2023-07-04 12:01:55,791][train_inner][INFO] - {"epoch": 38, "update": 37.67, "loss": "57.621", "ntokens": "2491.75", "nsentences": "49.635", "nll_loss": "1.148", "wps": "5237.6", "ups": "2.1", "wpb": "2491.8", "bsz": "49.6", "num_updates": "21800", "lr": "3e-05", "gnorm": "106.146", "loss_scale": "64", "train_wall": "93.94", "gb_free": "20.7", "wall": "7750"}
[2023-07-04 12:03:25,698][fairseq_cli.train][INFO] - end of epoch 38 (average epoch stats below)
[2023-07-04 12:03:25,740][train][INFO] - {"epoch": 38, "train_loss": "58.552", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "1.157", "train_wps": "5262.3", "train_ups": "2.11", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "21991", "train_lr": "3e-05", "train_gnorm": "106.449", "train_loss_scale": "64", "train_train_wall": "269.79", "train_gb_free": "20.8", "train_wall": "7840"}
[2023-07-04 12:03:25,784][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 12:03:25,797][fairseq.trainer][INFO] - begin training epoch 39
[2023-07-04 12:03:25,797][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 12:03:30,515][train_inner][INFO] - {"epoch": 39, "update": 38.016, "loss": "59.081", "ntokens": "2495.72", "nsentences": "49.66", "nll_loss": "1.176", "wps": "5271.7", "ups": "2.11", "wpb": "2495.7", "bsz": "49.7", "num_updates": "22000", "lr": "3e-05", "gnorm": "106.313", "loss_scale": "64", "train_wall": "93.29", "gb_free": "20.9", "wall": "7845"}
[2023-07-04 12:05:04,080][train_inner][INFO] - {"epoch": 39, "update": 38.361, "loss": "58.286", "ntokens": "2498.99", "nsentences": "48.93", "nll_loss": "1.141", "wps": "5342.8", "ups": "2.14", "wpb": "2499", "bsz": "48.9", "num_updates": "22200", "lr": "3e-05", "gnorm": "107.849", "loss_scale": "64", "train_wall": "92.53", "gb_free": "20.7", "wall": "7938"}
[2023-07-04 12:06:34,101][train_inner][INFO] - {"epoch": 39, "update": 38.706, "loss": "57.523", "ntokens": "2496.45", "nsentences": "48.915", "nll_loss": "1.127", "wps": "5547.4", "ups": "2.22", "wpb": "2496.4", "bsz": "48.9", "num_updates": "22400", "lr": "3e-05", "gnorm": "107.794", "loss_scale": "64", "train_wall": "89.05", "gb_free": "20.8", "wall": "8028"}
[2023-07-04 12:07:48,273][fairseq_cli.train][INFO] - end of epoch 39 (average epoch stats below)
[2023-07-04 12:07:48,289][train][INFO] - {"epoch": 39, "train_loss": "57.115", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "1.129", "train_wps": "5499.3", "train_ups": "2.21", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "22570", "train_lr": "3e-05", "train_gnorm": "106.825", "train_loss_scale": "64", "train_train_wall": "259.39", "train_gb_free": "20.7", "train_wall": "8103"}
[2023-07-04 12:07:48,318][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 12:07:48,326][fairseq.trainer][INFO] - begin training epoch 40
[2023-07-04 12:07:48,327][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 12:08:02,076][train_inner][INFO] - {"epoch": 40, "update": 39.052, "loss": "55.441", "ntokens": "2490", "nsentences": "50.095", "nll_loss": "1.115", "wps": "5661.6", "ups": "2.27", "wpb": "2490", "bsz": "50.1", "num_updates": "22600", "lr": "3e-05", "gnorm": "104.679", "loss_scale": "64", "train_wall": "86.75", "gb_free": "20.8", "wall": "8116"}
[2023-07-04 12:09:27,765][train_inner][INFO] - {"epoch": 40, "update": 39.397, "loss": "55.07", "ntokens": "2492.93", "nsentences": "49.305", "nll_loss": "1.089", "wps": "5819.8", "ups": "2.33", "wpb": "2492.9", "bsz": "49.3", "num_updates": "22800", "lr": "3e-05", "gnorm": "105.459", "loss_scale": "64", "train_wall": "84.85", "gb_free": "20.8", "wall": "8202"}
[2023-07-04 12:10:56,194][train_inner][INFO] - {"epoch": 40, "update": 39.743, "loss": "55.671", "ntokens": "2491.87", "nsentences": "49.275", "nll_loss": "1.101", "wps": "5636.9", "ups": "2.26", "wpb": "2491.9", "bsz": "49.3", "num_updates": "23000", "lr": "3e-05", "gnorm": "106.615", "loss_scale": "64", "train_wall": "86.6", "gb_free": "20.8", "wall": "8290"}
[2023-07-04 12:11:57,901][fairseq_cli.train][INFO] - begin validation on "dev_other" subset
[2023-07-04 12:12:13,105][dev_other][INFO] - {"epoch": 40, "dev_other_loss": "40.862", "dev_other_ntokens": "272.352", "dev_other_nsentences": "10.6074", "dev_other_nll_loss": "1.591", "dev_other_uer": "24.916", "dev_other_wer": "25.387", "dev_other_raw_wer": "25.387", "dev_other_wps": "4982.5", "dev_other_wpb": "272.4", "dev_other_bsz": "10.6", "dev_other_num_updates": "23149", "dev_other_best_wer": "25.387"}
[2023-07-04 12:12:13,110][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 40 @ 23149 updates
[2023-07-04 12:12:13,111][fairseq.trainer][INFO] - Saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt
[2023-07-04 12:12:17,600][fairseq.trainer][INFO] - Finished saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt
[2023-07-04 12:12:21,671][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt (epoch 40 @ 23149 updates, score 25.387) (writing took 8.556741911917925 seconds)
[2023-07-04 12:12:21,685][fairseq_cli.train][INFO] - end of epoch 40 (average epoch stats below)
[2023-07-04 12:12:21,803][train][INFO] - {"epoch": 40, "train_loss": "55.497", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "1.097", "train_wps": "5280.8", "train_ups": "2.12", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "23149", "train_lr": "3e-05", "train_gnorm": "106.11", "train_loss_scale": "64", "train_train_wall": "245.86", "train_gb_free": "20.8", "train_wall": "8376"}
[2023-07-04 12:12:21,962][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 12:12:21,971][fairseq.trainer][INFO] - begin training epoch 41
[2023-07-04 12:12:21,972][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 12:12:44,152][train_inner][INFO] - {"epoch": 41, "update": 40.088, "loss": "55.745", "ntokens": "2489.22", "nsentences": "49.12", "nll_loss": "1.1", "wps": "4612.1", "ups": "1.85", "wpb": "2489.2", "bsz": "49.1", "num_updates": "23200", "lr": "3e-05", "gnorm": "106.576", "loss_scale": "64", "train_wall": "82.74", "gb_free": "20.7", "wall": "8398"}
[2023-07-04 12:14:05,495][train_inner][INFO] - {"epoch": 41, "update": 40.434, "loss": "53.521", "ntokens": "2485.46", "nsentences": "49.69", "nll_loss": "1.07", "wps": "6112.2", "ups": "2.46", "wpb": "2485.5", "bsz": "49.7", "num_updates": "23400", "lr": "3e-05", "gnorm": "105.334", "loss_scale": "64", "train_wall": "80.59", "gb_free": "20.8", "wall": "8480"}
[2023-07-04 12:15:27,369][train_inner][INFO] - {"epoch": 41, "update": 40.779, "loss": "55.43", "ntokens": "2500.48", "nsentences": "48.93", "nll_loss": "1.085", "wps": "6108.9", "ups": "2.44", "wpb": "2500.5", "bsz": "48.9", "num_updates": "23600", "lr": "3e-05", "gnorm": "107.473", "loss_scale": "64", "train_wall": "81.15", "gb_free": "20.7", "wall": "8562"}
[2023-07-04 12:16:20,381][fairseq_cli.train][INFO] - end of epoch 41 (average epoch stats below)
[2023-07-04 12:16:20,399][train][INFO] - {"epoch": 41, "train_loss": "54.497", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "1.077", "train_wps": "6051.4", "train_ups": "2.43", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "23728", "train_lr": "3e-05", "train_gnorm": "106.464", "train_loss_scale": "64", "train_train_wall": "235.89", "train_gb_free": "20.8", "train_wall": "8615"}
[2023-07-04 12:16:20,440][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 12:16:20,451][fairseq.trainer][INFO] - begin training epoch 42
[2023-07-04 12:16:20,452][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 12:16:53,965][train_inner][INFO] - {"epoch": 42, "update": 41.124, "loss": "53.628", "ntokens": "2491.42", "nsentences": "49.575", "nll_loss": "1.067", "wps": "5755.1", "ups": "2.31", "wpb": "2491.4", "bsz": "49.6", "num_updates": "23800", "lr": "3e-05", "gnorm": "105.963", "loss_scale": "64", "train_wall": "85.37", "gb_free": "20.8", "wall": "8648"}
[2023-07-04 12:17:19,744][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2023-07-04 12:18:23,344][train_inner][INFO] - {"epoch": 42, "update": 41.472, "loss": "52.714", "ntokens": "2491.43", "nsentences": "48.295", "nll_loss": "1.022", "wps": "5576.1", "ups": "2.24", "wpb": "2491.4", "bsz": "48.3", "num_updates": "24000", "lr": "3e-05", "gnorm": "105.865", "loss_scale": "64", "train_wall": "87.45", "gb_free": "20.8", "wall": "8738"}
[2023-07-04 12:19:45,841][train_inner][INFO] - {"epoch": 42, "update": 41.817, "loss": "53.285", "ntokens": "2496.57", "nsentences": "50.275", "nll_loss": "1.073", "wps": "6053.2", "ups": "2.42", "wpb": "2496.6", "bsz": "50.3", "num_updates": "24200", "lr": "3e-05", "gnorm": "104.928", "loss_scale": "64", "train_wall": "81.73", "gb_free": "20.7", "wall": "8820"}
[2023-07-04 12:20:29,734][fairseq_cli.train][INFO] - end of epoch 42 (average epoch stats below)
[2023-07-04 12:20:29,745][train][INFO] - {"epoch": 42, "train_loss": "53.175", "train_ntokens": "2493.7", "train_nsentences": "49.3028", "train_nll_loss": "1.051", "train_wps": "5780.8", "train_ups": "2.32", "train_wpb": "2493.7", "train_bsz": "49.3", "train_num_updates": "24306", "train_lr": "3e-05", "train_gnorm": "105.49", "train_loss_scale": "64", "train_train_wall": "245.51", "train_gb_free": "20.8", "train_wall": "8864"}
[2023-07-04 12:20:29,771][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 12:20:29,779][fairseq.trainer][INFO] - begin training epoch 43
[2023-07-04 12:20:29,779][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 12:21:08,382][train_inner][INFO] - {"epoch": 43, "update": 42.162, "loss": "53.43", "ntokens": "2500.95", "nsentences": "49.035", "nll_loss": "1.048", "wps": "6060.8", "ups": "2.42", "wpb": "2500.9", "bsz": "49", "num_updates": "24400", "lr": "3e-05", "gnorm": "105.871", "loss_scale": "64", "train_wall": "81.32", "gb_free": "20.7", "wall": "8903"}
[2023-07-04 12:22:29,984][train_inner][INFO] - {"epoch": 43, "update": 42.508, "loss": "50.617", "ntokens": "2490.85", "nsentences": "50.3", "nll_loss": "1.022", "wps": "6105.6", "ups": "2.45", "wpb": "2490.8", "bsz": "50.3", "num_updates": "24600", "lr": "3e-05", "gnorm": "103.664", "loss_scale": "64", "train_wall": "80.86", "gb_free": "20.7", "wall": "8984"}
[2023-07-04 12:23:50,999][train_inner][INFO] - {"epoch": 43, "update": 42.853, "loss": "52.226", "ntokens": "2492.95", "nsentences": "48.8", "nll_loss": "1.022", "wps": "6155", "ups": "2.47", "wpb": "2492.9", "bsz": "48.8", "num_updates": "24800", "lr": "3e-05", "gnorm": "107.759", "loss_scale": "64", "train_wall": "80.27", "gb_free": "20.8", "wall": "9065"}
[2023-07-04 12:24:25,708][fairseq_cli.train][INFO] - end of epoch 43 (average epoch stats below)
[2023-07-04 12:24:25,718][train][INFO] - {"epoch": 43, "train_loss": "51.838", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "1.025", "train_wps": "6118.5", "train_ups": "2.45", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "24885", "train_lr": "3e-05", "train_gnorm": "105.731", "train_loss_scale": "64", "train_train_wall": "233.35", "train_gb_free": "20.8", "train_wall": "9100"}
[2023-07-04 12:24:25,740][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 12:24:25,746][fairseq.trainer][INFO] - begin training epoch 44
[2023-07-04 12:24:25,746][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 12:25:13,851][train_inner][INFO] - {"epoch": 44, "update": 43.199, "loss": "51.902", "ntokens": "2486.61", "nsentences": "48.74", "nll_loss": "1.017", "wps": "6003.3", "ups": "2.41", "wpb": "2486.6", "bsz": "48.7", "num_updates": "25000", "lr": "3e-05", "gnorm": "106.544", "loss_scale": "64", "train_wall": "81.79", "gb_free": "20.7", "wall": "9148"}
[2023-07-04 12:26:37,171][train_inner][INFO] - {"epoch": 44, "update": 43.544, "loss": "52.367", "ntokens": "2494.03", "nsentences": "49.61", "nll_loss": "1.042", "wps": "5987.4", "ups": "2.4", "wpb": "2494", "bsz": "49.6", "num_updates": "25200", "lr": "3e-05", "gnorm": "107.348", "loss_scale": "64", "train_wall": "81.21", "gb_free": "20.8", "wall": "9231"}
[2023-07-04 12:28:00,244][train_inner][INFO] - {"epoch": 44, "update": 43.889, "loss": "52.943", "ntokens": "2502.39", "nsentences": "48.81", "nll_loss": "1.033", "wps": "6025.3", "ups": "2.41", "wpb": "2502.4", "bsz": "48.8", "num_updates": "25400", "lr": "3e-05", "gnorm": "107.271", "loss_scale": "64", "train_wall": "82.14", "gb_free": "20.7", "wall": "9315"}
[2023-07-04 12:28:26,437][fairseq_cli.train][INFO] - end of epoch 44 (average epoch stats below)
[2023-07-04 12:28:26,446][train][INFO] - {"epoch": 44, "train_loss": "52.203", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "1.032", "train_wps": "5997.7", "train_ups": "2.41", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "25464", "train_lr": "3e-05", "train_gnorm": "106.942", "train_loss_scale": "64", "train_train_wall": "236.7", "train_gb_free": "20.7", "train_wall": "9341"}
[2023-07-04 12:28:26,471][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 12:28:26,476][fairseq.trainer][INFO] - begin training epoch 45
[2023-07-04 12:28:26,477][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 12:29:24,658][train_inner][INFO] - {"epoch": 45, "update": 44.235, "loss": "50.216", "ntokens": "2489.15", "nsentences": "49.655", "nll_loss": "1.002", "wps": "5898.2", "ups": "2.37", "wpb": "2489.2", "bsz": "49.7", "num_updates": "25600", "lr": "3e-05", "gnorm": "105.58", "loss_scale": "64", "train_wall": "82.2", "gb_free": "20.8", "wall": "9399"}
[2023-07-04 12:30:32,277][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
[2023-07-04 12:30:47,451][train_inner][INFO] - {"epoch": 45, "update": 44.582, "loss": "50.099", "ntokens": "2496.49", "nsentences": "49.655", "nll_loss": "0.996", "wps": "6031.5", "ups": "2.42", "wpb": "2496.5", "bsz": "49.7", "num_updates": "25800", "lr": "3e-05", "gnorm": "105.898", "loss_scale": "32", "train_wall": "82.03", "gb_free": "20.8", "wall": "9482"}
[2023-07-04 12:32:10,631][train_inner][INFO] - {"epoch": 45, "update": 44.927, "loss": "50.872", "ntokens": "2493.43", "nsentences": "49.075", "nll_loss": "1.001", "wps": "5996", "ups": "2.4", "wpb": "2493.4", "bsz": "49.1", "num_updates": "26000", "lr": "3e-05", "gnorm": "104.858", "loss_scale": "32", "train_wall": "82.44", "gb_free": "20.7", "wall": "9565"}
[2023-07-04 12:32:27,582][fairseq_cli.train][INFO] - begin validation on "dev_other" subset
[2023-07-04 12:32:42,896][dev_other][INFO] - {"epoch": 45, "dev_other_loss": "40.14", "dev_other_ntokens": "272.352", "dev_other_nsentences": "10.6074", "dev_other_nll_loss": "1.563", "dev_other_uer": "24.285", "dev_other_wer": "24.745", "dev_other_raw_wer": "24.745", "dev_other_wps": "5106.1", "dev_other_wpb": "272.4", "dev_other_bsz": "10.6", "dev_other_num_updates": "26042", "dev_other_best_wer": "24.745"}
[2023-07-04 12:32:42,898][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 45 @ 26042 updates
[2023-07-04 12:32:42,899][fairseq.trainer][INFO] - Saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt
[2023-07-04 12:32:46,219][fairseq.trainer][INFO] - Finished saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt
[2023-07-04 12:32:50,513][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt (epoch 45 @ 26042 updates, score 24.745) (writing took 7.614587090909481 seconds)
[2023-07-04 12:32:50,513][fairseq_cli.train][INFO] - end of epoch 45 (average epoch stats below)
[2023-07-04 12:32:50,523][train][INFO] - {"epoch": 45, "train_loss": "50.351", "train_ntokens": "2493.43", "train_nsentences": "49.2958", "train_nll_loss": "0.995", "train_wps": "5457.7", "train_ups": "2.19", "train_wpb": "2493.4", "train_bsz": "49.3", "train_num_updates": "26042", "train_lr": "3e-05", "train_gnorm": "105.62", "train_loss_scale": "32", "train_train_wall": "237.5", "train_gb_free": "20.8", "train_wall": "9605"}
[2023-07-04 12:32:50,538][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 12:32:50,542][fairseq.trainer][INFO] - begin training epoch 46
[2023-07-04 12:32:50,542][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 12:33:54,799][train_inner][INFO] - {"epoch": 46, "update": 45.273, "loss": "49.781", "ntokens": "2498.72", "nsentences": "48.815", "nll_loss": "0.973", "wps": "4798", "ups": "1.92", "wpb": "2498.7", "bsz": "48.8", "num_updates": "26200", "lr": "3e-05", "gnorm": "106.501", "loss_scale": "32", "train_wall": "80.11", "gb_free": "20.9", "wall": "9669"}
[2023-07-04 12:35:15,750][train_inner][INFO] - {"epoch": 46, "update": 45.618, "loss": "49.252", "ntokens": "2486.46", "nsentences": "49.335", "nll_loss": "0.977", "wps": "6143.9", "ups": "2.47", "wpb": "2486.5", "bsz": "49.3", "num_updates": "26400", "lr": "3e-05", "gnorm": "105.698", "loss_scale": "32", "train_wall": "80.2", "gb_free": "20.8", "wall": "9750"}
[2023-07-04 12:36:36,813][train_inner][INFO] - {"epoch": 46, "update": 45.964, "loss": "49.828", "ntokens": "2492.55", "nsentences": "49.735", "nll_loss": "0.994", "wps": "6150.4", "ups": "2.47", "wpb": "2492.6", "bsz": "49.7", "num_updates": "26600", "lr": "3e-05", "gnorm": "106.555", "loss_scale": "32", "train_wall": "80.33", "gb_free": "20.8", "wall": "9831"}
[2023-07-04 12:36:45,862][fairseq_cli.train][INFO] - end of epoch 46 (average epoch stats below)
[2023-07-04 12:36:45,873][train][INFO] - {"epoch": 46, "train_loss": "49.582", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.98", "train_wps": "6134.8", "train_ups": "2.46", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "26621", "train_lr": "3e-05", "train_gnorm": "106.401", "train_loss_scale": "32", "train_train_wall": "232.83", "train_gb_free": "20.9", "train_wall": "9840"}
[2023-07-04 12:36:45,890][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 12:36:45,894][fairseq.trainer][INFO] - begin training epoch 47
[2023-07-04 12:36:45,895][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 12:37:59,014][train_inner][INFO] - {"epoch": 47, "update": 46.309, "loss": "47.92", "ntokens": "2497.38", "nsentences": "49.135", "nll_loss": "0.943", "wps": "6077.1", "ups": "2.43", "wpb": "2497.4", "bsz": "49.1", "num_updates": "26800", "lr": "3e-05", "gnorm": "106.377", "loss_scale": "32", "train_wall": "81.15", "gb_free": "20.7", "wall": "9913"}
[2023-07-04 12:39:22,446][train_inner][INFO] - {"epoch": 47, "update": 46.655, "loss": "48.418", "ntokens": "2492.66", "nsentences": "49.23", "nll_loss": "0.956", "wps": "5976", "ups": "2.4", "wpb": "2492.7", "bsz": "49.2", "num_updates": "27000", "lr": "3e-05", "gnorm": "106.321", "loss_scale": "32", "train_wall": "82.67", "gb_free": "20.8", "wall": "9997"}
[2023-07-04 12:40:44,736][train_inner][INFO] - {"epoch": 47, "update": 47.0, "loss": "48.044", "ntokens": "2492.34", "nsentences": "49.32", "nll_loss": "0.951", "wps": "6058.2", "ups": "2.43", "wpb": "2492.3", "bsz": "49.3", "num_updates": "27200", "lr": "3e-05", "gnorm": "106.75", "loss_scale": "32", "train_wall": "81.34", "gb_free": "20.8", "wall": "10079"}
[2023-07-04 12:40:44,737][fairseq_cli.train][INFO] - end of epoch 47 (average epoch stats below)
[2023-07-04 12:40:44,746][train][INFO] - {"epoch": 47, "train_loss": "48.036", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.95", "train_wps": "6044.2", "train_ups": "2.42", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "27200", "train_lr": "3e-05", "train_gnorm": "106.34", "train_loss_scale": "32", "train_train_wall": "236.19", "train_gb_free": "20.8", "train_wall": "10079"}
[2023-07-04 12:40:44,764][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 12:40:44,770][fairseq.trainer][INFO] - begin training epoch 48
[2023-07-04 12:40:44,770][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 12:42:08,339][train_inner][INFO] - {"epoch": 48, "update": 47.345, "loss": "47.663", "ntokens": "2500.74", "nsentences": "49.58", "nll_loss": "0.945", "wps": "5983.1", "ups": "2.39", "wpb": "2500.7", "bsz": "49.6", "num_updates": "27400", "lr": "3e-05", "gnorm": "105.767", "loss_scale": "32", "train_wall": "82.16", "gb_free": "20.8", "wall": "10163"}
[2023-07-04 12:43:21,039][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2023-07-04 12:43:33,490][train_inner][INFO] - {"epoch": 48, "update": 47.693, "loss": "46.931", "ntokens": "2493.72", "nsentences": "49.3", "nll_loss": "0.928", "wps": "5857.9", "ups": "2.35", "wpb": "2493.7", "bsz": "49.3", "num_updates": "27600", "lr": "3e-05", "gnorm": "105.448", "loss_scale": "16", "train_wall": "84.12", "gb_free": "20.9", "wall": "10248"}
[2023-07-04 12:44:47,848][fairseq_cli.train][INFO] - end of epoch 48 (average epoch stats below)
[2023-07-04 12:44:47,858][train][INFO] - {"epoch": 48, "train_loss": "47.316", "train_ntokens": "2493.43", "train_nsentences": "49.2907", "train_nll_loss": "0.935", "train_wps": "5928.4", "train_ups": "2.38", "train_wpb": "2493.4", "train_bsz": "49.3", "train_num_updates": "27778", "train_lr": "3e-05", "train_gnorm": "105.796", "train_loss_scale": "16", "train_train_wall": "239.95", "train_gb_free": "20.8", "train_wall": "10322"}
[2023-07-04 12:44:47,876][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 12:44:47,881][fairseq.trainer][INFO] - begin training epoch 49
[2023-07-04 12:44:47,881][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 12:44:57,753][train_inner][INFO] - {"epoch": 49, "update": 48.038, "loss": "47.292", "ntokens": "2487.46", "nsentences": "48.855", "nll_loss": "0.929", "wps": "5904.8", "ups": "2.37", "wpb": "2487.5", "bsz": "48.9", "num_updates": "27800", "lr": "3e-05", "gnorm": "106.239", "loss_scale": "16", "train_wall": "83.16", "gb_free": "20.8", "wall": "10332"}
[2023-07-04 12:46:21,988][train_inner][INFO] - {"epoch": 49, "update": 48.383, "loss": "46.735", "ntokens": "2490.99", "nsentences": "49.54", "nll_loss": "0.929", "wps": "5927.1", "ups": "2.38", "wpb": "2491", "bsz": "49.5", "num_updates": "28000", "lr": "3e-05", "gnorm": "105.346", "loss_scale": "16", "train_wall": "83.22", "gb_free": "20.8", "wall": "10416"}
[2023-07-04 12:47:45,602][train_inner][INFO] - {"epoch": 49, "update": 48.729, "loss": "46.63", "ntokens": "2489.08", "nsentences": "49.055", "nll_loss": "0.919", "wps": "5954.5", "ups": "2.39", "wpb": "2489.1", "bsz": "49.1", "num_updates": "28200", "lr": "3e-05", "gnorm": "106.344", "loss_scale": "16", "train_wall": "82.83", "gb_free": "20.8", "wall": "10500"}
[2023-07-04 12:48:51,482][fairseq_cli.train][INFO] - end of epoch 49 (average epoch stats below)
[2023-07-04 12:48:51,492][train][INFO] - {"epoch": 49, "train_loss": "46.545", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.92", "train_wps": "5926.1", "train_ups": "2.38", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "28357", "train_lr": "3e-05", "train_gnorm": "105.545", "train_loss_scale": "16", "train_train_wall": "240.83", "train_gb_free": "20.8", "train_wall": "10566"}
[2023-07-04 12:48:51,513][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 12:48:51,519][fairseq.trainer][INFO] - begin training epoch 50
[2023-07-04 12:48:51,519][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 12:49:09,426][train_inner][INFO] - {"epoch": 50, "update": 49.074, "loss": "46.203", "ntokens": "2496.58", "nsentences": "49.39", "nll_loss": "0.914", "wps": "5957.5", "ups": "2.39", "wpb": "2496.6", "bsz": "49.4", "num_updates": "28400", "lr": "3e-05", "gnorm": "104.441", "loss_scale": "16", "train_wall": "82.75", "gb_free": "20.8", "wall": "10584"}
[2023-07-04 12:50:32,385][train_inner][INFO] - {"epoch": 50, "update": 49.42, "loss": "46.464", "ntokens": "2494.65", "nsentences": "48.965", "nll_loss": "0.912", "wps": "6014.9", "ups": "2.41", "wpb": "2494.7", "bsz": "49", "num_updates": "28600", "lr": "3e-05", "gnorm": "105.904", "loss_scale": "16", "train_wall": "82.18", "gb_free": "20.7", "wall": "10667"}
[2023-07-04 12:51:57,479][train_inner][INFO] - {"epoch": 50, "update": 49.765, "loss": "44.388", "ntokens": "2489.06", "nsentences": "49.575", "nll_loss": "0.884", "wps": "5850.8", "ups": "2.35", "wpb": "2489.1", "bsz": "49.6", "num_updates": "28800", "lr": "3e-05", "gnorm": "104.41", "loss_scale": "16", "train_wall": "84.3", "gb_free": "20.8", "wall": "10752"}
[2023-07-04 12:52:54,684][fairseq_cli.train][INFO] - begin validation on "dev_other" subset
[2023-07-04 12:53:09,151][dev_other][INFO] - {"epoch": 50, "dev_other_loss": "40.294", "dev_other_ntokens": "272.352", "dev_other_nsentences": "10.6074", "dev_other_nll_loss": "1.569", "dev_other_uer": "24.05", "dev_other_wer": "24.516", "dev_other_raw_wer": "24.516", "dev_other_wps": "5201.5", "dev_other_wpb": "272.4", "dev_other_bsz": "10.6", "dev_other_num_updates": "28936", "dev_other_best_wer": "24.516"}
[2023-07-04 12:53:09,152][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 50 @ 28936 updates
[2023-07-04 12:53:09,153][fairseq.trainer][INFO] - Saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt
[2023-07-04 12:53:13,163][fairseq.trainer][INFO] - Finished saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt
[2023-07-04 12:53:16,066][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt (epoch 50 @ 28936 updates, score 24.516) (writing took 6.913025686517358 seconds)
[2023-07-04 12:53:16,066][fairseq_cli.train][INFO] - end of epoch 50 (average epoch stats below)
[2023-07-04 12:53:16,079][train][INFO] - {"epoch": 50, "train_loss": "45.722", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.904", "train_wps": "5456.9", "train_ups": "2.19", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "28936", "train_lr": "3e-05", "train_gnorm": "105.326", "train_loss_scale": "16", "train_train_wall": "240.61", "train_gb_free": "20.8", "train_wall": "10830"}
[2023-07-04 12:53:16,093][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 12:53:16,097][fairseq.trainer][INFO] - begin training epoch 51
[2023-07-04 12:53:16,097][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 12:53:42,055][train_inner][INFO] - {"epoch": 51, "update": 50.111, "loss": "46.003", "ntokens": "2501.57", "nsentences": "49.655", "nll_loss": "0.913", "wps": "4784.8", "ups": "1.91", "wpb": "2501.6", "bsz": "49.7", "num_updates": "29000", "lr": "3e-05", "gnorm": "105.174", "loss_scale": "16", "train_wall": "82.05", "gb_free": "20.8", "wall": "10856"}
[2023-07-04 12:55:03,928][train_inner][INFO] - {"epoch": 51, "update": 50.456, "loss": "45.259", "ntokens": "2494.99", "nsentences": "49.015", "nll_loss": "0.889", "wps": "6095.6", "ups": "2.44", "wpb": "2495", "bsz": "49", "num_updates": "29200", "lr": "3e-05", "gnorm": "103.991", "loss_scale": "16", "train_wall": "81.06", "gb_free": "20.7", "wall": "10938"}
[2023-07-04 12:56:24,872][train_inner][INFO] - {"epoch": 51, "update": 50.801, "loss": "45.617", "ntokens": "2492.1", "nsentences": "49.385", "nll_loss": "0.904", "wps": "6158.3", "ups": "2.47", "wpb": "2492.1", "bsz": "49.4", "num_updates": "29400", "lr": "3e-05", "gnorm": "107.21", "loss_scale": "16", "train_wall": "80.18", "gb_free": "20.8", "wall": "11019"}
[2023-07-04 12:57:12,717][fairseq_cli.train][INFO] - end of epoch 51 (average epoch stats below)
[2023-07-04 12:57:12,728][train][INFO] - {"epoch": 51, "train_loss": "45.388", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.897", "train_wps": "6101.1", "train_ups": "2.45", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "29515", "train_lr": "3e-05", "train_gnorm": "105.456", "train_loss_scale": "16", "train_train_wall": "234.02", "train_gb_free": "20.7", "train_wall": "11067"}
[2023-07-04 12:57:12,749][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 12:57:12,754][fairseq.trainer][INFO] - begin training epoch 52
[2023-07-04 12:57:12,754][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 12:57:48,896][train_inner][INFO] - {"epoch": 52, "update": 51.147, "loss": "44.975", "ntokens": "2493.08", "nsentences": "49.01", "nll_loss": "0.884", "wps": "5934.9", "ups": "2.38", "wpb": "2493.1", "bsz": "49", "num_updates": "29600", "lr": "3e-05", "gnorm": "106.459", "loss_scale": "16", "train_wall": "82.93", "gb_free": "20.8", "wall": "11103"}
[2023-07-04 12:58:46,773][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2023-07-04 12:59:12,137][train_inner][INFO] - {"epoch": 52, "update": 51.494, "loss": "44.425", "ntokens": "2482.47", "nsentences": "49.275", "nll_loss": "0.882", "wps": "5965.3", "ups": "2.4", "wpb": "2482.5", "bsz": "49.3", "num_updates": "29800", "lr": "3e-05", "gnorm": "104.933", "loss_scale": "16", "train_wall": "82.47", "gb_free": "20.8", "wall": "11186"}
[2023-07-04 13:00:34,237][train_inner][INFO] - {"epoch": 52, "update": 51.839, "loss": "44.274", "ntokens": "2494.56", "nsentences": "50.065", "nll_loss": "0.889", "wps": "6077.6", "ups": "2.44", "wpb": "2494.6", "bsz": "50.1", "num_updates": "30000", "lr": "3e-05", "gnorm": "104.182", "loss_scale": "16", "train_wall": "81.35", "gb_free": "20.8", "wall": "11269"}
[2023-07-04 13:01:12,735][fairseq_cli.train][INFO] - end of epoch 52 (average epoch stats below)
[2023-07-04 13:01:12,744][train][INFO] - {"epoch": 52, "train_loss": "44.53", "train_ntokens": "2493.44", "train_nsentences": "49.2907", "train_nll_loss": "0.88", "train_wps": "6004.8", "train_ups": "2.41", "train_wpb": "2493.4", "train_bsz": "49.3", "train_num_updates": "30093", "train_lr": "3e-05", "train_gnorm": "105.086", "train_loss_scale": "16", "train_train_wall": "237.51", "train_gb_free": "20.8", "train_wall": "11307"}
[2023-07-04 13:01:12,763][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 13:01:12,769][fairseq.trainer][INFO] - begin training epoch 53
[2023-07-04 13:01:12,769][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 13:01:57,309][train_inner][INFO] - {"epoch": 53, "update": 52.185, "loss": "44.343", "ntokens": "2502.47", "nsentences": "48.96", "nll_loss": "0.868", "wps": "6025.5", "ups": "2.41", "wpb": "2502.5", "bsz": "49", "num_updates": "30200", "lr": "3e-05", "gnorm": "105.831", "loss_scale": "16", "train_wall": "81.98", "gb_free": "20.7", "wall": "11352"}
[2023-07-04 13:03:20,580][train_inner][INFO] - {"epoch": 53, "update": 52.53, "loss": "45.056", "ntokens": "2492.71", "nsentences": "48.89", "nll_loss": "0.884", "wps": "5987.7", "ups": "2.4", "wpb": "2492.7", "bsz": "48.9", "num_updates": "30400", "lr": "3e-05", "gnorm": "106.584", "loss_scale": "16", "train_wall": "82.48", "gb_free": "20.7", "wall": "11435"}
[2023-07-04 13:04:42,869][train_inner][INFO] - {"epoch": 53, "update": 52.876, "loss": "43.565", "ntokens": "2502.63", "nsentences": "49.075", "nll_loss": "0.854", "wps": "6083.3", "ups": "2.43", "wpb": "2502.6", "bsz": "49.1", "num_updates": "30600", "lr": "3e-05", "gnorm": "105.742", "loss_scale": "16", "train_wall": "81.55", "gb_free": "20.7", "wall": "11517"}
[2023-07-04 13:05:12,721][fairseq_cli.train][INFO] - end of epoch 53 (average epoch stats below)
[2023-07-04 13:05:12,732][train][INFO] - {"epoch": 53, "train_loss": "43.802", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.866", "train_wps": "6016.2", "train_ups": "2.41", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "30672", "train_lr": "3e-05", "train_gnorm": "105.548", "train_loss_scale": "16", "train_train_wall": "237.45", "train_gb_free": "20.8", "train_wall": "11547"}
[2023-07-04 13:05:12,750][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 13:05:12,756][fairseq.trainer][INFO] - begin training epoch 54
[2023-07-04 13:05:12,756][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 13:06:06,876][train_inner][INFO] - {"epoch": 54, "update": 53.221, "loss": "42.186", "ntokens": "2491.11", "nsentences": "49.02", "nll_loss": "0.83", "wps": "5931.4", "ups": "2.38", "wpb": "2491.1", "bsz": "49", "num_updates": "30800", "lr": "3e-05", "gnorm": "103.999", "loss_scale": "16", "train_wall": "82.94", "gb_free": "20.8", "wall": "11601"}
[2023-07-04 13:07:30,800][train_inner][INFO] - {"epoch": 54, "update": 53.566, "loss": "42.347", "ntokens": "2492.95", "nsentences": "49.135", "nll_loss": "0.835", "wps": "5941.7", "ups": "2.38", "wpb": "2493", "bsz": "49.1", "num_updates": "31000", "lr": "3e-05", "gnorm": "105.424", "loss_scale": "16", "train_wall": "83.16", "gb_free": "20.7", "wall": "11685"}
[2023-07-04 13:08:53,888][train_inner][INFO] - {"epoch": 54, "update": 53.912, "loss": "42.332", "ntokens": "2494.95", "nsentences": "49.765", "nll_loss": "0.844", "wps": "6006.3", "ups": "2.41", "wpb": "2494.9", "bsz": "49.8", "num_updates": "31200", "lr": "3e-05", "gnorm": "104.454", "loss_scale": "16", "train_wall": "82.32", "gb_free": "20.8", "wall": "11768"}
[2023-07-04 13:09:15,028][fairseq_cli.train][INFO] - end of epoch 54 (average epoch stats below)
[2023-07-04 13:09:15,038][train][INFO] - {"epoch": 54, "train_loss": "42.467", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.839", "train_wps": "5958.6", "train_ups": "2.39", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "31251", "train_lr": "3e-05", "train_gnorm": "104.909", "train_loss_scale": "16", "train_train_wall": "239.75", "train_gb_free": "20.8", "train_wall": "11789"}
[2023-07-04 13:09:15,059][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 13:09:15,064][fairseq.trainer][INFO] - begin training epoch 55
[2023-07-04 13:09:15,064][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 13:10:19,086][train_inner][INFO] - {"epoch": 55, "update": 54.257, "loss": "42.343", "ntokens": "2494.68", "nsentences": "49.625", "nll_loss": "0.842", "wps": "5858.9", "ups": "2.35", "wpb": "2494.7", "bsz": "49.6", "num_updates": "31400", "lr": "3e-05", "gnorm": "104.412", "loss_scale": "16", "train_wall": "84.04", "gb_free": "20.8", "wall": "11853"}
[2023-07-04 13:11:40,877][train_inner][INFO] - {"epoch": 55, "update": 54.603, "loss": "41.416", "ntokens": "2487.36", "nsentences": "49.43", "nll_loss": "0.823", "wps": "6083.2", "ups": "2.45", "wpb": "2487.4", "bsz": "49.4", "num_updates": "31600", "lr": "3e-05", "gnorm": "105.053", "loss_scale": "16", "train_wall": "81.02", "gb_free": "20.8", "wall": "11935"}
[2023-07-04 13:13:04,256][train_inner][INFO] - {"epoch": 55, "update": 54.948, "loss": "42.152", "ntokens": "2494.04", "nsentences": "48.965", "nll_loss": "0.828", "wps": "5983.2", "ups": "2.4", "wpb": "2494", "bsz": "49", "num_updates": "31800", "lr": "3e-05", "gnorm": "105.677", "loss_scale": "32", "train_wall": "82.4", "gb_free": "20.8", "wall": "12019"}
[2023-07-04 13:13:16,231][fairseq_cli.train][INFO] - begin validation on "dev_other" subset
[2023-07-04 13:13:31,494][dev_other][INFO] - {"epoch": 55, "dev_other_loss": "40.305", "dev_other_ntokens": "272.352", "dev_other_nsentences": "10.6074", "dev_other_nll_loss": "1.57", "dev_other_uer": "23.718", "dev_other_wer": "24.153", "dev_other_raw_wer": "24.153", "dev_other_wps": "5090.9", "dev_other_wpb": "272.4", "dev_other_bsz": "10.6", "dev_other_num_updates": "31830", "dev_other_best_wer": "24.153"}
[2023-07-04 13:13:31,516][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 55 @ 31830 updates
[2023-07-04 13:13:31,517][fairseq.trainer][INFO] - Saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt
[2023-07-04 13:13:36,284][fairseq.trainer][INFO] - Finished saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt
[2023-07-04 13:13:39,318][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt (epoch 55 @ 31830 updates, score 24.153) (writing took 7.801229264587164 seconds)
[2023-07-04 13:13:39,318][fairseq_cli.train][INFO] - end of epoch 55 (average epoch stats below)
[2023-07-04 13:13:39,679][train][INFO] - {"epoch": 55, "train_loss": "41.785", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.826", "train_wps": "5463", "train_ups": "2.19", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "31830", "train_lr": "3e-05", "train_gnorm": "104.891", "train_loss_scale": "32", "train_train_wall": "238.39", "train_gb_free": "20.8", "train_wall": "12054"}
[2023-07-04 13:13:41,139][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 13:13:41,156][fairseq.trainer][INFO] - begin training epoch 56
[2023-07-04 13:13:41,156][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 13:14:55,966][train_inner][INFO] - {"epoch": 56, "update": 55.294, "loss": "40.721", "ntokens": "2488.06", "nsentences": "49.795", "nll_loss": "0.815", "wps": "4455.1", "ups": "1.79", "wpb": "2488.1", "bsz": "49.8", "num_updates": "32000", "lr": "3e-05", "gnorm": "103.611", "loss_scale": "32", "train_wall": "84.84", "gb_free": "20.8", "wall": "12130"}
[2023-07-04 13:16:25,582][train_inner][INFO] - {"epoch": 56, "update": 55.639, "loss": "41.339", "ntokens": "2501.08", "nsentences": "48.96", "nll_loss": "0.809", "wps": "5582.7", "ups": "2.23", "wpb": "2501.1", "bsz": "49", "num_updates": "32200", "lr": "3e-05", "gnorm": "104.015", "loss_scale": "32", "train_wall": "88.76", "gb_free": "20.7", "wall": "12220"}
[2023-07-04 13:17:57,756][train_inner][INFO] - {"epoch": 56, "update": 55.984, "loss": "42.425", "ntokens": "2489.24", "nsentences": "49.36", "nll_loss": "0.841", "wps": "5413.4", "ups": "2.17", "wpb": "2489.2", "bsz": "49.4", "num_updates": "32400", "lr": "3e-05", "gnorm": "106.426", "loss_scale": "32", "train_wall": "90.97", "gb_free": "20.7", "wall": "12312"}
[2023-07-04 13:18:01,451][fairseq_cli.train][INFO] - end of epoch 56 (average epoch stats below)
[2023-07-04 13:18:01,475][train][INFO] - {"epoch": 56, "train_loss": "41.535", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.821", "train_wps": "5515.3", "train_ups": "2.21", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "32409", "train_lr": "3e-05", "train_gnorm": "104.834", "train_loss_scale": "32", "train_train_wall": "256.37", "train_gb_free": "20.8", "train_wall": "12316"}
[2023-07-04 13:18:01,535][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 13:18:01,547][fairseq.trainer][INFO] - begin training epoch 57
[2023-07-04 13:18:01,548][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 13:19:27,221][train_inner][INFO] - {"epoch": 57, "update": 56.33, "loss": "41.024", "ntokens": "2501.1", "nsentences": "49.105", "nll_loss": "0.805", "wps": "5592.4", "ups": "2.24", "wpb": "2501.1", "bsz": "49.1", "num_updates": "32600", "lr": "3e-05", "gnorm": "103.93", "loss_scale": "32", "train_wall": "88.09", "gb_free": "20.9", "wall": "12401"}
[2023-07-04 13:20:57,633][train_inner][INFO] - {"epoch": 57, "update": 56.675, "loss": "41.165", "ntokens": "2489.3", "nsentences": "50.065", "nll_loss": "0.828", "wps": "5509.1", "ups": "2.21", "wpb": "2489.3", "bsz": "50.1", "num_updates": "32800", "lr": "3e-05", "gnorm": "105.372", "loss_scale": "32", "train_wall": "89.43", "gb_free": "20.9", "wall": "12492"}
[2023-07-04 13:22:25,660][fairseq_cli.train][INFO] - end of epoch 57 (average epoch stats below)
[2023-07-04 13:22:25,673][train][INFO] - {"epoch": 57, "train_loss": "41.204", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.814", "train_wps": "5464.9", "train_ups": "2.19", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "32988", "train_lr": "3e-05", "train_gnorm": "105.283", "train_loss_scale": "32", "train_train_wall": "260.95", "train_gb_free": "20.7", "train_wall": "12580"}
[2023-07-04 13:22:25,699][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 13:22:25,705][fairseq.trainer][INFO] - begin training epoch 58
[2023-07-04 13:22:25,705][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 13:22:32,126][train_inner][INFO] - {"epoch": 58, "update": 57.021, "loss": "41.615", "ntokens": "2492.07", "nsentences": "48.475", "nll_loss": "0.809", "wps": "5275.6", "ups": "2.12", "wpb": "2492.1", "bsz": "48.5", "num_updates": "33000", "lr": "3e-05", "gnorm": "106.781", "loss_scale": "32", "train_wall": "93.14", "gb_free": "20.8", "wall": "12586"}
[2023-07-04 13:23:56,651][train_inner][INFO] - {"epoch": 58, "update": 57.366, "loss": "40.267", "ntokens": "2487.51", "nsentences": "49.25", "nll_loss": "0.797", "wps": "5887.1", "ups": "2.37", "wpb": "2487.5", "bsz": "49.2", "num_updates": "33200", "lr": "3e-05", "gnorm": "105.251", "loss_scale": "32", "train_wall": "83.71", "gb_free": "20.8", "wall": "12671"}
[2023-07-04 13:25:21,242][train_inner][INFO] - {"epoch": 58, "update": 57.712, "loss": "39.796", "ntokens": "2494.51", "nsentences": "49.89", "nll_loss": "0.796", "wps": "5899.1", "ups": "2.36", "wpb": "2494.5", "bsz": "49.9", "num_updates": "33400", "lr": "3e-05", "gnorm": "103.685", "loss_scale": "32", "train_wall": "83.6", "gb_free": "20.7", "wall": "12756"}
[2023-07-04 13:26:32,198][fairseq_cli.train][INFO] - end of epoch 58 (average epoch stats below)
[2023-07-04 13:26:32,215][train][INFO] - {"epoch": 58, "train_loss": "40.182", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.794", "train_wps": "5856.4", "train_ups": "2.35", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "33567", "train_lr": "3e-05", "train_gnorm": "105.123", "train_loss_scale": "32", "train_train_wall": "243.63", "train_gb_free": "20.7", "train_wall": "12826"}
[2023-07-04 13:26:32,240][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 13:26:32,246][fairseq.trainer][INFO] - begin training epoch 59
[2023-07-04 13:26:32,246][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 13:26:46,476][train_inner][INFO] - {"epoch": 59, "update": 58.057, "loss": "39.984", "ntokens": "2496.7", "nsentences": "49.16", "nll_loss": "0.787", "wps": "5859.7", "ups": "2.35", "wpb": "2496.7", "bsz": "49.2", "num_updates": "33600", "lr": "3e-05", "gnorm": "105.332", "loss_scale": "32", "train_wall": "84.06", "gb_free": "20.9", "wall": "12841"}
[2023-07-04 13:28:11,128][train_inner][INFO] - {"epoch": 59, "update": 58.402, "loss": "39.448", "ntokens": "2498.09", "nsentences": "49.59", "nll_loss": "0.783", "wps": "5903.3", "ups": "2.36", "wpb": "2498.1", "bsz": "49.6", "num_updates": "33800", "lr": "3e-05", "gnorm": "102.762", "loss_scale": "32", "train_wall": "83.85", "gb_free": "20.8", "wall": "12925"}
[2023-07-04 13:29:36,822][train_inner][INFO] - {"epoch": 59, "update": 58.748, "loss": "39.94", "ntokens": "2496.14", "nsentences": "48.575", "nll_loss": "0.777", "wps": "5826.9", "ups": "2.33", "wpb": "2496.1", "bsz": "48.6", "num_updates": "34000", "lr": "3e-05", "gnorm": "105.66", "loss_scale": "64", "train_wall": "84.86", "gb_free": "20.8", "wall": "13011"}
[2023-07-04 13:30:37,900][fairseq_cli.train][INFO] - end of epoch 59 (average epoch stats below)
[2023-07-04 13:30:37,911][train][INFO] - {"epoch": 59, "train_loss": "39.599", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.783", "train_wps": "5876.4", "train_ups": "2.36", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "34146", "train_lr": "3e-05", "train_gnorm": "104.556", "train_loss_scale": "64", "train_train_wall": "243.01", "train_gb_free": "20.7", "train_wall": "13072"}
[2023-07-04 13:30:37,941][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 13:30:37,948][fairseq.trainer][INFO] - begin training epoch 60
[2023-07-04 13:30:37,949][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 13:31:02,835][train_inner][INFO] - {"epoch": 60, "update": 59.093, "loss": "39.498", "ntokens": "2487.51", "nsentences": "48.995", "nll_loss": "0.778", "wps": "5785.1", "ups": "2.33", "wpb": "2487.5", "bsz": "49", "num_updates": "34200", "lr": "3e-05", "gnorm": "105.733", "loss_scale": "64", "train_wall": "84.86", "gb_free": "20.8", "wall": "13097"}
[2023-07-04 13:32:28,415][train_inner][INFO] - {"epoch": 60, "update": 59.439, "loss": "38.903", "ntokens": "2495.96", "nsentences": "50.165", "nll_loss": "0.782", "wps": "5835.6", "ups": "2.34", "wpb": "2496", "bsz": "50.2", "num_updates": "34400", "lr": "3e-05", "gnorm": "101.946", "loss_scale": "64", "train_wall": "84.76", "gb_free": "20.7", "wall": "13183"}
[2023-07-04 13:33:49,599][train_inner][INFO] - {"epoch": 60, "update": 59.784, "loss": "39.953", "ntokens": "2498.41", "nsentences": "49.125", "nll_loss": "0.786", "wps": "6168.4", "ups": "2.47", "wpb": "2498.4", "bsz": "49.1", "num_updates": "34600", "lr": "3e-05", "gnorm": "105.109", "loss_scale": "64", "train_wall": "80.29", "gb_free": "20.8", "wall": "13264"}
[2023-07-04 13:34:42,055][fairseq_cli.train][INFO] - begin validation on "dev_other" subset
[2023-07-04 13:34:57,122][dev_other][INFO] - {"epoch": 60, "dev_other_loss": "40.987", "dev_other_ntokens": "272.352", "dev_other_nsentences": "10.6074", "dev_other_nll_loss": "1.596", "dev_other_uer": "23.832", "dev_other_wer": "24.18", "dev_other_raw_wer": "24.18", "dev_other_wps": "5152.2", "dev_other_wpb": "272.4", "dev_other_bsz": "10.6", "dev_other_num_updates": "34725", "dev_other_best_wer": "24.153"}
[2023-07-04 13:34:57,125][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 60 @ 34725 updates
[2023-07-04 13:34:57,126][fairseq.trainer][INFO] - Saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_last.pt
[2023-07-04 13:35:00,330][fairseq.trainer][INFO] - Finished saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_last.pt
[2023-07-04 13:35:00,446][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_last.pt (epoch 60 @ 34725 updates, score 24.18) (writing took 3.3206191062927246 seconds)
[2023-07-04 13:35:00,446][fairseq_cli.train][INFO] - end of epoch 60 (average epoch stats below)
[2023-07-04 13:35:00,457][train][INFO] - {"epoch": 60, "train_loss": "39.501", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.781", "train_wps": "5499.3", "train_ups": "2.21", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "34725", "train_lr": "3e-05", "train_gnorm": "103.59", "train_loss_scale": "64", "train_train_wall": "241.04", "train_gb_free": "20.7", "train_wall": "13335"}
[2023-07-04 13:35:00,481][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 13:35:00,490][fairseq.trainer][INFO] - begin training epoch 61
[2023-07-04 13:35:00,491][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 13:35:32,334][train_inner][INFO] - {"epoch": 61, "update": 60.13, "loss": "38.777", "ntokens": "2476.35", "nsentences": "49.14", "nll_loss": "0.769", "wps": "4822.1", "ups": "1.95", "wpb": "2476.3", "bsz": "49.1", "num_updates": "34800", "lr": "3e-05", "gnorm": "102.296", "loss_scale": "64", "train_wall": "82.87", "gb_free": "20.8", "wall": "13367"}
[2023-07-04 13:36:56,961][train_inner][INFO] - {"epoch": 61, "update": 60.475, "loss": "38.934", "ntokens": "2510.43", "nsentences": "48.415", "nll_loss": "0.751", "wps": "5933.9", "ups": "2.36", "wpb": "2510.4", "bsz": "48.4", "num_updates": "35000", "lr": "3e-05", "gnorm": "106.786", "loss_scale": "64", "train_wall": "83.84", "gb_free": "20.8", "wall": "13451"}
[2023-07-04 13:38:16,376][train_inner][INFO] - {"epoch": 61, "update": 60.82, "loss": "38.852", "ntokens": "2487.78", "nsentences": "49.315", "nll_loss": "0.77", "wps": "6266.2", "ups": "2.52", "wpb": "2487.8", "bsz": "49.3", "num_updates": "35200", "lr": "3e-05", "gnorm": "103.843", "loss_scale": "64", "train_wall": "78.67", "gb_free": "20.7", "wall": "13531"}
[2023-07-04 13:38:57,640][fairseq_cli.train][INFO] - end of epoch 61 (average epoch stats below)
[2023-07-04 13:38:57,651][train][INFO] - {"epoch": 61, "train_loss": "38.597", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.763", "train_wps": "6087.1", "train_ups": "2.44", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "35304", "train_lr": "3e-05", "train_gnorm": "104.167", "train_loss_scale": "64", "train_train_wall": "234.61", "train_gb_free": "20.9", "train_wall": "13572"}
[2023-07-04 13:38:57,902][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 13:38:57,936][fairseq.trainer][INFO] - begin training epoch 62
[2023-07-04 13:38:57,937][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 13:39:39,226][train_inner][INFO] - {"epoch": 62, "update": 61.166, "loss": "38.186", "ntokens": "2490.45", "nsentences": "49.745", "nll_loss": "0.763", "wps": "6012.6", "ups": "2.41", "wpb": "2490.4", "bsz": "49.7", "num_updates": "35400", "lr": "3e-05", "gnorm": "103.047", "loss_scale": "64", "train_wall": "81.44", "gb_free": "20.8", "wall": "13614"}
[2023-07-04 13:41:01,982][train_inner][INFO] - {"epoch": 62, "update": 61.511, "loss": "38.425", "ntokens": "2495.84", "nsentences": "49.66", "nll_loss": "0.765", "wps": "6032.5", "ups": "2.42", "wpb": "2495.8", "bsz": "49.7", "num_updates": "35600", "lr": "3e-05", "gnorm": "103.283", "loss_scale": "64", "train_wall": "82", "gb_free": "20.7", "wall": "13696"}
[2023-07-04 13:42:25,288][train_inner][INFO] - {"epoch": 62, "update": 61.857, "loss": "38.766", "ntokens": "2493.26", "nsentences": "49.245", "nll_loss": "0.766", "wps": "5986.5", "ups": "2.4", "wpb": "2493.3", "bsz": "49.2", "num_updates": "35800", "lr": "3e-05", "gnorm": "104.538", "loss_scale": "64", "train_wall": "82.53", "gb_free": "20.7", "wall": "13780"}
[2023-07-04 13:42:59,554][fairseq_cli.train][INFO] - end of epoch 62 (average epoch stats below)
[2023-07-04 13:42:59,563][train][INFO] - {"epoch": 62, "train_loss": "38.455", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.76", "train_wps": "5968.3", "train_ups": "2.39", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "35883", "train_lr": "3e-05", "train_gnorm": "103.788", "train_loss_scale": "128", "train_train_wall": "239.03", "train_gb_free": "20.8", "train_wall": "13814"}
[2023-07-04 13:42:59,581][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 13:42:59,586][fairseq.trainer][INFO] - begin training epoch 63
[2023-07-04 13:42:59,586][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 13:43:48,916][train_inner][INFO] - {"epoch": 63, "update": 62.202, "loss": "38.242", "ntokens": "2490.93", "nsentences": "49.23", "nll_loss": "0.756", "wps": "5957.9", "ups": "2.39", "wpb": "2490.9", "bsz": "49.2", "num_updates": "36000", "lr": "3e-05", "gnorm": "103.877", "loss_scale": "128", "train_wall": "82.54", "gb_free": "20.9", "wall": "13863"}
[2023-07-04 13:45:12,675][train_inner][INFO] - {"epoch": 63, "update": 62.547, "loss": "38.515", "ntokens": "2493.47", "nsentences": "48.845", "nll_loss": "0.754", "wps": "5954.6", "ups": "2.39", "wpb": "2493.5", "bsz": "48.8", "num_updates": "36200", "lr": "3e-05", "gnorm": "105.265", "loss_scale": "128", "train_wall": "82.99", "gb_free": "20.7", "wall": "13947"}
[2023-07-04 13:46:34,388][train_inner][INFO] - {"epoch": 63, "update": 62.893, "loss": "37.302", "ntokens": "2495.78", "nsentences": "49.485", "nll_loss": "0.74", "wps": "6109.3", "ups": "2.45", "wpb": "2495.8", "bsz": "49.5", "num_updates": "36400", "lr": "3e-05", "gnorm": "103.661", "loss_scale": "128", "train_wall": "80.94", "gb_free": "20.8", "wall": "14029"}
[2023-07-04 13:47:00,527][fairseq_cli.train][INFO] - end of epoch 63 (average epoch stats below)
[2023-07-04 13:47:00,761][train][INFO] - {"epoch": 63, "train_loss": "37.791", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.747", "train_wps": "5991.6", "train_ups": "2.4", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "36462", "train_lr": "3e-05", "train_gnorm": "103.995", "train_loss_scale": "128", "train_train_wall": "238.44", "train_gb_free": "20.8", "train_wall": "14055"}
[2023-07-04 13:47:00,779][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 13:47:00,784][fairseq.trainer][INFO] - begin training epoch 64
[2023-07-04 13:47:00,785][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 13:47:05,515][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2023-07-04 13:47:59,830][train_inner][INFO] - {"epoch": 64, "update": 63.24, "loss": "37.306", "ntokens": "2495.07", "nsentences": "49.805", "nll_loss": "0.745", "wps": "5841.1", "ups": "2.34", "wpb": "2495.1", "bsz": "49.8", "num_updates": "36600", "lr": "3e-05", "gnorm": "102.149", "loss_scale": "64", "train_wall": "84.12", "gb_free": "20.7", "wall": "14114"}
[2023-07-04 13:49:22,574][train_inner][INFO] - {"epoch": 64, "update": 63.585, "loss": "37.103", "ntokens": "2491.22", "nsentences": "49.21", "nll_loss": "0.733", "wps": "6022.2", "ups": "2.42", "wpb": "2491.2", "bsz": "49.2", "num_updates": "36800", "lr": "3e-05", "gnorm": "106.727", "loss_scale": "64", "train_wall": "81.96", "gb_free": "20.7", "wall": "14197"}
[2023-07-04 13:50:45,126][train_inner][INFO] - {"epoch": 64, "update": 63.931, "loss": "36.973", "ntokens": "2489.47", "nsentences": "49.115", "nll_loss": "0.729", "wps": "6032", "ups": "2.42", "wpb": "2489.5", "bsz": "49.1", "num_updates": "37000", "lr": "3e-05", "gnorm": "106.092", "loss_scale": "64", "train_wall": "81.81", "gb_free": "20.8", "wall": "14279"}
[2023-07-04 13:51:01,889][fairseq_cli.train][INFO] - end of epoch 64 (average epoch stats below)
[2023-07-04 13:51:01,899][train][INFO] - {"epoch": 64, "train_loss": "37.316", "train_ntokens": "2493.72", "train_nsentences": "49.263", "train_nll_loss": "0.737", "train_wps": "5977.6", "train_ups": "2.4", "train_wpb": "2493.7", "train_bsz": "49.3", "train_num_updates": "37040", "train_lr": "3e-05", "train_gnorm": "105.832", "train_loss_scale": "64", "train_train_wall": "238.59", "train_gb_free": "20.8", "train_wall": "14296"}
[2023-07-04 13:51:01,918][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 13:51:01,924][fairseq.trainer][INFO] - begin training epoch 65
[2023-07-04 13:51:01,924][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 13:52:08,570][train_inner][INFO] - {"epoch": 65, "update": 64.276, "loss": "36.594", "ntokens": "2494.67", "nsentences": "49.545", "nll_loss": "0.727", "wps": "5980", "ups": "2.4", "wpb": "2494.7", "bsz": "49.5", "num_updates": "37200", "lr": "3e-05", "gnorm": "103.511", "loss_scale": "64", "train_wall": "82.37", "gb_free": "20.8", "wall": "14363"}
[2023-07-04 13:53:30,957][train_inner][INFO] - {"epoch": 65, "update": 64.622, "loss": "37.064", "ntokens": "2496.66", "nsentences": "49.16", "nll_loss": "0.73", "wps": "6061.5", "ups": "2.43", "wpb": "2496.7", "bsz": "49.2", "num_updates": "37400", "lr": "3e-05", "gnorm": "103.599", "loss_scale": "64", "train_wall": "81.63", "gb_free": "20.7", "wall": "14445"}
[2023-07-04 13:54:54,312][train_inner][INFO] - {"epoch": 65, "update": 64.967, "loss": "36.872", "ntokens": "2491.91", "nsentences": "49.095", "nll_loss": "0.726", "wps": "5979.5", "ups": "2.4", "wpb": "2491.9", "bsz": "49.1", "num_updates": "37600", "lr": "3e-05", "gnorm": "105.675", "loss_scale": "64", "train_wall": "82.61", "gb_free": "20.9", "wall": "14529"}
[2023-07-04 13:55:02,479][fairseq_cli.train][INFO] - begin validation on "dev_other" subset
[2023-07-04 13:55:17,226][dev_other][INFO] - {"epoch": 65, "dev_other_loss": "41.575", "dev_other_ntokens": "272.352", "dev_other_nsentences": "10.6074", "dev_other_nll_loss": "1.619", "dev_other_uer": "23.654", "dev_other_wer": "24.076", "dev_other_raw_wer": "24.076", "dev_other_wps": "5127.3", "dev_other_wpb": "272.4", "dev_other_bsz": "10.6", "dev_other_num_updates": "37619", "dev_other_best_wer": "24.076"}
[2023-07-04 13:55:17,242][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 65 @ 37619 updates
[2023-07-04 13:55:17,243][fairseq.trainer][INFO] - Saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt
[2023-07-04 13:55:24,348][fairseq.trainer][INFO] - Finished saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt
[2023-07-04 13:55:27,225][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt (epoch 65 @ 37619 updates, score 24.076) (writing took 9.982616188004613 seconds)
[2023-07-04 13:55:27,225][fairseq_cli.train][INFO] - end of epoch 65 (average epoch stats below)
[2023-07-04 13:55:27,235][train][INFO] - {"epoch": 65, "train_loss": "36.542", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.722", "train_wps": "5441.4", "train_ups": "2.18", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "37619", "train_lr": "3e-05", "train_gnorm": "103.621", "train_loss_scale": "64", "train_train_wall": "238.09", "train_gb_free": "20.8", "train_wall": "14562"}
[2023-07-04 13:55:27,248][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 13:55:27,252][fairseq.trainer][INFO] - begin training epoch 66
[2023-07-04 13:55:27,252][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 13:56:42,701][train_inner][INFO] - {"epoch": 66, "update": 65.313, "loss": "35.058", "ntokens": "2492.36", "nsentences": "49.01", "nll_loss": "0.689", "wps": "4599.3", "ups": "1.85", "wpb": "2492.4", "bsz": "49", "num_updates": "37800", "lr": "3e-05", "gnorm": "102.34", "loss_scale": "64", "train_wall": "82.53", "gb_free": "20.7", "wall": "14637"}
[2023-07-04 13:58:05,296][train_inner][INFO] - {"epoch": 66, "update": 65.658, "loss": "35.947", "ntokens": "2492.78", "nsentences": "49.41", "nll_loss": "0.713", "wps": "6036.9", "ups": "2.42", "wpb": "2492.8", "bsz": "49.4", "num_updates": "38000", "lr": "3e-05", "gnorm": "103.19", "loss_scale": "64", "train_wall": "81.82", "gb_free": "20.8", "wall": "14720"}
[2023-07-04 13:59:29,090][fairseq_cli.train][INFO] - end of epoch 66 (average epoch stats below)
[2023-07-04 13:59:29,100][train][INFO] - {"epoch": 66, "train_loss": "36.049", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.713", "train_wps": "5969.5", "train_ups": "2.39", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "38198", "train_lr": "3e-05", "train_gnorm": "103.514", "train_loss_scale": "64", "train_train_wall": "239.31", "train_gb_free": "20.8", "train_wall": "14803"}
[2023-07-04 13:59:29,120][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 13:59:29,125][fairseq.trainer][INFO] - begin training epoch 67
[2023-07-04 13:59:29,125][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 13:59:30,299][train_inner][INFO] - {"epoch": 67, "update": 66.003, "loss": "36.806", "ntokens": "2495.7", "nsentences": "49.555", "nll_loss": "0.731", "wps": "5872.7", "ups": "2.35", "wpb": "2495.7", "bsz": "49.6", "num_updates": "38200", "lr": "3e-05", "gnorm": "104.484", "loss_scale": "64", "train_wall": "83.94", "gb_free": "20.8", "wall": "14805"}
[2023-07-04 14:00:52,360][train_inner][INFO] - {"epoch": 67, "update": 66.349, "loss": "35.26", "ntokens": "2503.09", "nsentences": "49.3", "nll_loss": "0.694", "wps": "6101.3", "ups": "2.44", "wpb": "2503.1", "bsz": "49.3", "num_updates": "38400", "lr": "3e-05", "gnorm": "106.211", "loss_scale": "64", "train_wall": "81.29", "gb_free": "20.8", "wall": "14887"}
[2023-07-04 14:02:16,934][train_inner][INFO] - {"epoch": 67, "update": 66.694, "loss": "35.724", "ntokens": "2490.25", "nsentences": "49.545", "nll_loss": "0.711", "wps": "5889.6", "ups": "2.37", "wpb": "2490.2", "bsz": "49.5", "num_updates": "38600", "lr": "3e-05", "gnorm": "106.001", "loss_scale": "128", "train_wall": "83.78", "gb_free": "20.8", "wall": "14971"}
[2023-07-04 14:03:29,600][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2023-07-04 14:03:30,682][fairseq_cli.train][INFO] - end of epoch 67 (average epoch stats below)
[2023-07-04 14:03:30,691][train][INFO] - {"epoch": 67, "train_loss": "35.788", "train_ntokens": "2493.69", "train_nsentences": "49.2785", "train_nll_loss": "0.707", "train_wps": "5966.3", "train_ups": "2.39", "train_wpb": "2493.7", "train_bsz": "49.3", "train_num_updates": "38776", "train_lr": "3e-05", "train_gnorm": "105.358", "train_loss_scale": "64", "train_train_wall": "239.01", "train_gb_free": "20.7", "train_wall": "15045"}
[2023-07-04 14:03:30,707][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 14:03:30,711][fairseq.trainer][INFO] - begin training epoch 68
[2023-07-04 14:03:30,711][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 14:03:41,104][train_inner][INFO] - {"epoch": 68, "update": 67.041, "loss": "36.054", "ntokens": "2489.89", "nsentences": "48.96", "nll_loss": "0.709", "wps": "5917.1", "ups": "2.38", "wpb": "2489.9", "bsz": "49", "num_updates": "38800", "lr": "3e-05", "gnorm": "103.062", "loss_scale": "64", "train_wall": "83.07", "gb_free": "20.8", "wall": "15055"}
[2023-07-04 14:05:04,870][train_inner][INFO] - {"epoch": 68, "update": 67.387, "loss": "35.289", "ntokens": "2493.11", "nsentences": "50.205", "nll_loss": "0.711", "wps": "5953.3", "ups": "2.39", "wpb": "2493.1", "bsz": "50.2", "num_updates": "39000", "lr": "3e-05", "gnorm": "102.217", "loss_scale": "64", "train_wall": "82.98", "gb_free": "20.7", "wall": "15139"}
[2023-07-04 14:06:36,578][train_inner][INFO] - {"epoch": 68, "update": 67.732, "loss": "35.427", "ntokens": "2491.93", "nsentences": "48.41", "nll_loss": "0.688", "wps": "5435.1", "ups": "2.18", "wpb": "2491.9", "bsz": "48.4", "num_updates": "39200", "lr": "3e-05", "gnorm": "103.307", "loss_scale": "64", "train_wall": "90.27", "gb_free": "20.8", "wall": "15231"}
[2023-07-04 14:07:42,730][fairseq_cli.train][INFO] - end of epoch 68 (average epoch stats below)
[2023-07-04 14:07:42,920][train][INFO] - {"epoch": 68, "train_loss": "35.348", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.699", "train_wps": "5728.2", "train_ups": "2.3", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "39355", "train_lr": "3e-05", "train_gnorm": "102.214", "train_loss_scale": "64", "train_train_wall": "248.82", "train_gb_free": "20.9", "train_wall": "15297"}
[2023-07-04 14:07:42,945][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 14:07:42,950][fairseq.trainer][INFO] - begin training epoch 69
[2023-07-04 14:07:42,950][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 14:08:01,963][train_inner][INFO] - {"epoch": 69, "update": 68.078, "loss": "35.413", "ntokens": "2492.57", "nsentences": "49.45", "nll_loss": "0.703", "wps": "5839.1", "ups": "2.34", "wpb": "2492.6", "bsz": "49.5", "num_updates": "39400", "lr": "3e-05", "gnorm": "101.133", "loss_scale": "64", "train_wall": "83.87", "gb_free": "20.8", "wall": "15316"}
[2023-07-04 14:09:27,546][train_inner][INFO] - {"epoch": 69, "update": 68.423, "loss": "33.743", "ntokens": "2492.86", "nsentences": "49.325", "nll_loss": "0.668", "wps": "5826.4", "ups": "2.34", "wpb": "2492.9", "bsz": "49.3", "num_updates": "39600", "lr": "3e-05", "gnorm": "101.336", "loss_scale": "64", "train_wall": "84.76", "gb_free": "20.8", "wall": "15402"}
[2023-07-04 14:10:53,239][train_inner][INFO] - {"epoch": 69, "update": 68.769, "loss": "34.949", "ntokens": "2499.8", "nsentences": "48.98", "nll_loss": "0.685", "wps": "5835.2", "ups": "2.33", "wpb": "2499.8", "bsz": "49", "num_updates": "39800", "lr": "3e-05", "gnorm": "105.844", "loss_scale": "64", "train_wall": "84.89", "gb_free": "20.7", "wall": "15488"}
[2023-07-04 14:11:27,047][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
[2023-07-04 14:11:49,359][fairseq_cli.train][INFO] - end of epoch 69 (average epoch stats below)
[2023-07-04 14:11:49,381][train][INFO] - {"epoch": 69, "train_loss": "34.668", "train_ntokens": "2493.48", "train_nsentences": "49.301", "train_nll_loss": "0.685", "train_wps": "5848.2", "train_ups": "2.35", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "39933", "train_lr": "3e-05", "train_gnorm": "103.279", "train_loss_scale": "32", "train_train_wall": "243.59", "train_gb_free": "20.8", "train_wall": "15544"}
[2023-07-04 14:11:49,401][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 14:11:49,406][fairseq.trainer][INFO] - begin training epoch 70
[2023-07-04 14:11:49,406][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 14:12:18,104][train_inner][INFO] - {"epoch": 70, "update": 69.116, "loss": "34.818", "ntokens": "2485.28", "nsentences": "49.405", "nll_loss": "0.692", "wps": "5857.6", "ups": "2.36", "wpb": "2485.3", "bsz": "49.4", "num_updates": "40000", "lr": "3e-05", "gnorm": "103.34", "loss_scale": "32", "train_wall": "83.8", "gb_free": "20.8", "wall": "15572"}
[2023-07-04 14:13:42,665][train_inner][INFO] - {"epoch": 70, "update": 69.461, "loss": "34.328", "ntokens": "2504.43", "nsentences": "48.97", "nll_loss": "0.671", "wps": "5924.1", "ups": "2.37", "wpb": "2504.4", "bsz": "49", "num_updates": "40200", "lr": "2.9554e-05", "gnorm": "101.782", "loss_scale": "32", "train_wall": "83.78", "gb_free": "20.8", "wall": "15657"}
[2023-07-04 14:15:05,365][train_inner][INFO] - {"epoch": 70, "update": 69.807, "loss": "34.697", "ntokens": "2496.11", "nsentences": "48.68", "nll_loss": "0.677", "wps": "6037.3", "ups": "2.42", "wpb": "2496.1", "bsz": "48.7", "num_updates": "40400", "lr": "2.91146e-05", "gnorm": "102.342", "loss_scale": "32", "train_wall": "81.94", "gb_free": "20.8", "wall": "15740"}
[2023-07-04 14:15:51,693][fairseq_cli.train][INFO] - begin validation on "dev_other" subset
[2023-07-04 14:16:06,300][dev_other][INFO] - {"epoch": 70, "dev_other_loss": "41.944", "dev_other_ntokens": "272.352", "dev_other_nsentences": "10.6074", "dev_other_nll_loss": "1.634", "dev_other_uer": "23.522", "dev_other_wer": "24.141", "dev_other_raw_wer": "24.141", "dev_other_wps": "5233", "dev_other_wpb": "272.4", "dev_other_bsz": "10.6", "dev_other_num_updates": "40512", "dev_other_best_wer": "24.076"}
[2023-07-04 14:16:06,301][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 70 @ 40512 updates
[2023-07-04 14:16:06,302][fairseq.trainer][INFO] - Saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_last.pt
[2023-07-04 14:16:09,113][fairseq.trainer][INFO] - Finished saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_last.pt
[2023-07-04 14:16:09,237][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_last.pt (epoch 70 @ 40512 updates, score 24.141) (writing took 2.9354822766035795 seconds)
[2023-07-04 14:16:09,237][fairseq_cli.train][INFO] - end of epoch 70 (average epoch stats below)
[2023-07-04 14:16:09,246][train][INFO] - {"epoch": 70, "train_loss": "34.34", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.679", "train_wps": "5556", "train_ups": "2.23", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "40512", "train_lr": "2.88714e-05", "train_gnorm": "101.913", "train_loss_scale": "32", "train_train_wall": "239.82", "train_gb_free": "20.8", "train_wall": "15804"}
[2023-07-04 14:16:09,258][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 14:16:09,262][fairseq.trainer][INFO] - begin training epoch 71
[2023-07-04 14:16:09,263][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 14:16:46,521][train_inner][INFO] - {"epoch": 71, "update": 70.152, "loss": "34.212", "ntokens": "2483.3", "nsentences": "50.13", "nll_loss": "0.691", "wps": "4910.3", "ups": "1.98", "wpb": "2483.3", "bsz": "50.1", "num_updates": "40600", "lr": "2.86818e-05", "gnorm": "102.778", "loss_scale": "32", "train_wall": "82.51", "gb_free": "20.8", "wall": "15841"}
[2023-07-04 14:18:07,455][train_inner][INFO] - {"epoch": 71, "update": 70.497, "loss": "33.523", "ntokens": "2500.16", "nsentences": "49.51", "nll_loss": "0.664", "wps": "6179", "ups": "2.47", "wpb": "2500.2", "bsz": "49.5", "num_updates": "40800", "lr": "2.82553e-05", "gnorm": "102.623", "loss_scale": "32", "train_wall": "80.17", "gb_free": "20.8", "wall": "15922"}
[2023-07-04 14:19:30,866][train_inner][INFO] - {"epoch": 71, "update": 70.843, "loss": "34.307", "ntokens": "2485.07", "nsentences": "49.37", "nll_loss": "0.682", "wps": "5959.3", "ups": "2.4", "wpb": "2485.1", "bsz": "49.4", "num_updates": "41000", "lr": "2.78353e-05", "gnorm": "105.064", "loss_scale": "32", "train_wall": "82.63", "gb_free": "20.7", "wall": "16005"}
[2023-07-04 14:20:09,640][fairseq_cli.train][INFO] - end of epoch 71 (average epoch stats below)
[2023-07-04 14:20:09,650][train][INFO] - {"epoch": 71, "train_loss": "33.864", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.669", "train_wps": "6005.8", "train_ups": "2.41", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "41091", "train_lr": "2.76462e-05", "train_gnorm": "104.03", "train_loss_scale": "32", "train_train_wall": "237.83", "train_gb_free": "20.8", "train_wall": "16044"}
[2023-07-04 14:20:09,669][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 14:20:09,675][fairseq.trainer][INFO] - begin training epoch 72
[2023-07-04 14:20:09,675][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 14:20:55,052][train_inner][INFO] - {"epoch": 72, "update": 71.188, "loss": "33.684", "ntokens": "2495.37", "nsentences": "49.04", "nll_loss": "0.662", "wps": "5929", "ups": "2.38", "wpb": "2495.4", "bsz": "49", "num_updates": "41200", "lr": "2.74214e-05", "gnorm": "102.39", "loss_scale": "32", "train_wall": "83.11", "gb_free": "20.7", "wall": "16089"}
[2023-07-04 14:22:18,325][train_inner][INFO] - {"epoch": 72, "update": 71.534, "loss": "33.84", "ntokens": "2490.52", "nsentences": "48.97", "nll_loss": "0.665", "wps": "5982.3", "ups": "2.4", "wpb": "2490.5", "bsz": "49", "num_updates": "41400", "lr": "2.70138e-05", "gnorm": "101.373", "loss_scale": "32", "train_wall": "82.5", "gb_free": "20.8", "wall": "16173"}
[2023-07-04 14:23:40,472][train_inner][INFO] - {"epoch": 72, "update": 71.879, "loss": "33.541", "ntokens": "2500.35", "nsentences": "49.61", "nll_loss": "0.665", "wps": "6088.3", "ups": "2.43", "wpb": "2500.3", "bsz": "49.6", "num_updates": "41600", "lr": "2.66122e-05", "gnorm": "101.375", "loss_scale": "32", "train_wall": "81.42", "gb_free": "20.7", "wall": "16255"}
[2023-07-04 14:24:09,996][fairseq_cli.train][INFO] - end of epoch 72 (average epoch stats below)
[2023-07-04 14:24:10,007][train][INFO] - {"epoch": 72, "train_loss": "33.715", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.666", "train_wps": "6007", "train_ups": "2.41", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "41670", "train_lr": "2.6473e-05", "train_gnorm": "101.355", "train_loss_scale": "32", "train_train_wall": "237.85", "train_gb_free": "20.8", "train_wall": "16284"}
[2023-07-04 14:24:10,025][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 14:24:10,031][fairseq.trainer][INFO] - begin training epoch 73
[2023-07-04 14:24:10,031][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 14:25:04,357][train_inner][INFO] - {"epoch": 73, "update": 72.225, "loss": "33.434", "ntokens": "2488.86", "nsentences": "49.14", "nll_loss": "0.66", "wps": "5934.7", "ups": "2.38", "wpb": "2488.9", "bsz": "49.1", "num_updates": "41800", "lr": "2.62165e-05", "gnorm": "99.624", "loss_scale": "32", "train_wall": "82.81", "gb_free": "20.8", "wall": "16339"}
[2023-07-04 14:26:29,114][train_inner][INFO] - {"epoch": 73, "update": 72.57, "loss": "32.141", "ntokens": "2498.04", "nsentences": "49.91", "nll_loss": "0.642", "wps": "5895.2", "ups": "2.36", "wpb": "2498", "bsz": "49.9", "num_updates": "42000", "lr": "2.58267e-05", "gnorm": "99.371", "loss_scale": "64", "train_wall": "83.98", "gb_free": "20.8", "wall": "16423"}
[2023-07-04 14:27:50,538][train_inner][INFO] - {"epoch": 73, "update": 72.915, "loss": "34.008", "ntokens": "2487.61", "nsentences": "49.05", "nll_loss": "0.671", "wps": "6111.1", "ups": "2.46", "wpb": "2487.6", "bsz": "49", "num_updates": "42200", "lr": "2.54428e-05", "gnorm": "102.184", "loss_scale": "64", "train_wall": "80.7", "gb_free": "20.8", "wall": "16505"}
[2023-07-04 14:28:11,402][fairseq_cli.train][INFO] - end of epoch 73 (average epoch stats below)
[2023-07-04 14:28:11,411][train][INFO] - {"epoch": 73, "train_loss": "33.125", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.655", "train_wps": "5980.9", "train_ups": "2.4", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "42249", "train_lr": "2.53496e-05", "train_gnorm": "100.455", "train_loss_scale": "64", "train_train_wall": "238.9", "train_gb_free": "20.7", "train_wall": "16526"}
[2023-07-04 14:28:11,427][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 14:28:11,432][fairseq.trainer][INFO] - begin training epoch 74
[2023-07-04 14:28:11,432][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 14:29:22,097][train_inner][INFO] - {"epoch": 74, "update": 73.261, "loss": "32.956", "ntokens": "2500.6", "nsentences": "48.755", "nll_loss": "0.643", "wps": "5464.6", "ups": "2.19", "wpb": "2500.6", "bsz": "48.8", "num_updates": "42400", "lr": "2.50645e-05", "gnorm": "101.721", "loss_scale": "64", "train_wall": "90.04", "gb_free": "20.8", "wall": "16596"}
[2023-07-04 14:30:45,679][train_inner][INFO] - {"epoch": 74, "update": 73.606, "loss": "32.339", "ntokens": "2494.84", "nsentences": "48.615", "nll_loss": "0.63", "wps": "5970.8", "ups": "2.39", "wpb": "2494.8", "bsz": "48.6", "num_updates": "42600", "lr": "2.46919e-05", "gnorm": "104.93", "loss_scale": "64", "train_wall": "82.79", "gb_free": "20.8", "wall": "16680"}
[2023-07-04 14:32:07,979][train_inner][INFO] - {"epoch": 74, "update": 73.952, "loss": "31.83", "ntokens": "2484.39", "nsentences": "50.395", "nll_loss": "0.646", "wps": "6038.1", "ups": "2.43", "wpb": "2484.4", "bsz": "50.4", "num_updates": "42800", "lr": "2.43248e-05", "gnorm": "99.892", "loss_scale": "64", "train_wall": "81.53", "gb_free": "20.8", "wall": "16762"}
[2023-07-04 14:32:19,469][fairseq_cli.train][INFO] - end of epoch 74 (average epoch stats below)
[2023-07-04 14:32:19,480][train][INFO] - {"epoch": 74, "train_loss": "32.451", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.641", "train_wps": "5820.2", "train_ups": "2.33", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "42828", "train_lr": "2.42738e-05", "train_gnorm": "102.344", "train_loss_scale": "64", "train_train_wall": "245.06", "train_gb_free": "20.8", "train_wall": "16774"}
[2023-07-04 14:32:19,566][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 14:32:19,572][fairseq.trainer][INFO] - begin training epoch 75
[2023-07-04 14:32:19,573][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 14:33:32,248][train_inner][INFO] - {"epoch": 75, "update": 74.297, "loss": "31.904", "ntokens": "2497.61", "nsentences": "49.815", "nll_loss": "0.636", "wps": "5928.4", "ups": "2.37", "wpb": "2497.6", "bsz": "49.8", "num_updates": "43000", "lr": "2.39632e-05", "gnorm": "100.185", "loss_scale": "64", "train_wall": "82.62", "gb_free": "20.8", "wall": "16847"}
[2023-07-04 14:34:54,927][train_inner][INFO] - {"epoch": 75, "update": 74.642, "loss": "31.87", "ntokens": "2500.36", "nsentences": "48.8", "nll_loss": "0.622", "wps": "6049", "ups": "2.42", "wpb": "2500.4", "bsz": "48.8", "num_updates": "43200", "lr": "2.36069e-05", "gnorm": "101.068", "loss_scale": "64", "train_wall": "81.94", "gb_free": "20.8", "wall": "16929"}
[2023-07-04 14:36:16,669][train_inner][INFO] - {"epoch": 75, "update": 74.988, "loss": "32.395", "ntokens": "2486.25", "nsentences": "49.1", "nll_loss": "0.64", "wps": "6083.8", "ups": "2.45", "wpb": "2486.2", "bsz": "49.1", "num_updates": "43400", "lr": "2.32559e-05", "gnorm": "100.861", "loss_scale": "64", "train_wall": "80.92", "gb_free": "20.7", "wall": "17011"}
[2023-07-04 14:36:19,384][fairseq_cli.train][INFO] - begin validation on "dev_other" subset
[2023-07-04 14:36:34,530][dev_other][INFO] - {"epoch": 75, "dev_other_loss": "41.607", "dev_other_ntokens": "272.352", "dev_other_nsentences": "10.6074", "dev_other_nll_loss": "1.62", "dev_other_uer": "23.246", "dev_other_wer": "23.821", "dev_other_raw_wer": "23.821", "dev_other_wps": "5152.2", "dev_other_wpb": "272.4", "dev_other_bsz": "10.6", "dev_other_num_updates": "43407", "dev_other_best_wer": "23.821"}
[2023-07-04 14:36:34,544][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 75 @ 43407 updates
[2023-07-04 14:36:34,545][fairseq.trainer][INFO] - Saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt
[2023-07-04 14:36:39,226][fairseq.trainer][INFO] - Finished saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt
[2023-07-04 14:36:41,772][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt (epoch 75 @ 43407 updates, score 23.821) (writing took 7.227969767525792 seconds)
[2023-07-04 14:36:41,773][fairseq_cli.train][INFO] - end of epoch 75 (average epoch stats below)
[2023-07-04 14:36:41,782][train][INFO] - {"epoch": 75, "train_loss": "31.873", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.63", "train_wps": "5504.3", "train_ups": "2.21", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "43407", "train_lr": "2.32437e-05", "train_gnorm": "100.581", "train_loss_scale": "64", "train_train_wall": "236.8", "train_gb_free": "20.8", "train_wall": "17036"}
[2023-07-04 14:36:41,798][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 14:36:41,802][fairseq.trainer][INFO] - begin training epoch 76
[2023-07-04 14:36:41,803][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 14:38:00,898][train_inner][INFO] - {"epoch": 76, "update": 75.333, "loss": "31.972", "ntokens": "2492.36", "nsentences": "49.215", "nll_loss": "0.631", "wps": "4786.4", "ups": "1.92", "wpb": "2492.4", "bsz": "49.2", "num_updates": "43600", "lr": "2.29102e-05", "gnorm": "102.378", "loss_scale": "64", "train_wall": "80.75", "gb_free": "20.8", "wall": "17115"}
[2023-07-04 14:39:24,763][train_inner][INFO] - {"epoch": 76, "update": 75.679, "loss": "32.43", "ntokens": "2498.89", "nsentences": "49.31", "nll_loss": "0.64", "wps": "5960", "ups": "2.39", "wpb": "2498.9", "bsz": "49.3", "num_updates": "43800", "lr": "2.25696e-05", "gnorm": "100.985", "loss_scale": "64", "train_wall": "83.08", "gb_free": "20.9", "wall": "17199"}
[2023-07-04 14:40:38,185][fairseq_cli.train][INFO] - end of epoch 76 (average epoch stats below)
[2023-07-04 14:40:38,195][train][INFO] - {"epoch": 76, "train_loss": "32.006", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.633", "train_wps": "6107.2", "train_ups": "2.45", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "43986", "train_lr": "2.22574e-05", "train_gnorm": "101.167", "train_loss_scale": "128", "train_train_wall": "233.89", "train_gb_free": "20.8", "train_wall": "17272"}
[2023-07-04 14:40:38,210][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 14:40:38,215][fairseq.trainer][INFO] - begin training epoch 77
[2023-07-04 14:40:38,215][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 14:40:41,211][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2023-07-04 14:40:44,650][train_inner][INFO] - {"epoch": 77, "update": 76.026, "loss": "31.442", "ntokens": "2486.61", "nsentences": "49.2", "nll_loss": "0.622", "wps": "6226.1", "ups": "2.5", "wpb": "2486.6", "bsz": "49.2", "num_updates": "44000", "lr": "2.2234e-05", "gnorm": "101.297", "loss_scale": "64", "train_wall": "78.86", "gb_free": "20.7", "wall": "17279"}
[2023-07-04 14:42:09,366][train_inner][INFO] - {"epoch": 77, "update": 76.371, "loss": "31.817", "ntokens": "2503.93", "nsentences": "49.62", "nll_loss": "0.631", "wps": "5911.9", "ups": "2.36", "wpb": "2503.9", "bsz": "49.6", "num_updates": "44200", "lr": "2.19035e-05", "gnorm": "101.043", "loss_scale": "64", "train_wall": "83.9", "gb_free": "20.7", "wall": "17364"}
[2023-07-04 14:42:39,903][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
[2023-07-04 14:43:30,945][train_inner][INFO] - {"epoch": 77, "update": 76.718, "loss": "31.595", "ntokens": "2489.07", "nsentences": "49.565", "nll_loss": "0.629", "wps": "6102.9", "ups": "2.45", "wpb": "2489.1", "bsz": "49.6", "num_updates": "44400", "lr": "2.15778e-05", "gnorm": "102.3", "loss_scale": "32", "train_wall": "80.83", "gb_free": "20.8", "wall": "17445"}
[2023-07-04 14:45:07,439][fairseq_cli.train][INFO] - end of epoch 77 (average epoch stats below)
[2023-07-04 14:45:07,478][train][INFO] - {"epoch": 77, "train_loss": "31.496", "train_ntokens": "2493.07", "train_nsentences": "49.2825", "train_nll_loss": "0.623", "train_wps": "5342.7", "train_ups": "2.14", "train_wpb": "2493.1", "train_bsz": "49.3", "train_num_updates": "44563", "train_lr": "2.1316e-05", "train_gnorm": "101.161", "train_loss_scale": "32", "train_train_wall": "266.7", "train_gb_free": "20.8", "train_wall": "17542"}
[2023-07-04 14:45:07,492][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 14:45:07,497][fairseq.trainer][INFO] - begin training epoch 78
[2023-07-04 14:45:07,497][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 14:45:23,231][train_inner][INFO] - {"epoch": 78, "update": 77.064, "loss": "30.947", "ntokens": "2486.86", "nsentences": "49.005", "nll_loss": "0.61", "wps": "4429.9", "ups": "1.78", "wpb": "2486.9", "bsz": "49", "num_updates": "44600", "lr": "2.1257e-05", "gnorm": "98.173", "loss_scale": "32", "train_wall": "111.19", "gb_free": "20.8", "wall": "17558"}
[2023-07-04 14:46:46,605][train_inner][INFO] - {"epoch": 78, "update": 77.409, "loss": "30.47", "ntokens": "2497.5", "nsentences": "48.79", "nll_loss": "0.595", "wps": "5991.6", "ups": "2.4", "wpb": "2497.5", "bsz": "48.8", "num_updates": "44800", "lr": "2.0941e-05", "gnorm": "100.443", "loss_scale": "32", "train_wall": "82.62", "gb_free": "20.8", "wall": "17641"}
[2023-07-04 14:48:09,230][train_inner][INFO] - {"epoch": 78, "update": 77.755, "loss": "30.387", "ntokens": "2492.64", "nsentences": "49.97", "nll_loss": "0.609", "wps": "6034.4", "ups": "2.42", "wpb": "2492.6", "bsz": "50", "num_updates": "45000", "lr": "2.06297e-05", "gnorm": "98.498", "loss_scale": "32", "train_wall": "81.87", "gb_free": "20.7", "wall": "17724"}
[2023-07-04 14:49:07,418][fairseq_cli.train][INFO] - end of epoch 78 (average epoch stats below)
[2023-07-04 14:49:07,428][train][INFO] - {"epoch": 78, "train_loss": "30.799", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.609", "train_wps": "6017.1", "train_ups": "2.41", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "45142", "train_lr": "2.04114e-05", "train_gnorm": "99.164", "train_loss_scale": "32", "train_train_wall": "237.45", "train_gb_free": "20.7", "train_wall": "17782"}
[2023-07-04 14:49:07,447][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 14:49:07,451][fairseq.trainer][INFO] - begin training epoch 79
[2023-07-04 14:49:07,452][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 14:49:32,496][train_inner][INFO] - {"epoch": 79, "update": 78.1, "loss": "31.636", "ntokens": "2494.91", "nsentences": "48.635", "nll_loss": "0.617", "wps": "5993.4", "ups": "2.4", "wpb": "2494.9", "bsz": "48.6", "num_updates": "45200", "lr": "2.0323e-05", "gnorm": "99.464", "loss_scale": "32", "train_wall": "82.19", "gb_free": "20.8", "wall": "17807"}
[2023-07-04 14:50:52,802][train_inner][INFO] - {"epoch": 79, "update": 78.446, "loss": "30.343", "ntokens": "2498.21", "nsentences": "49.49", "nll_loss": "0.601", "wps": "6222.5", "ups": "2.49", "wpb": "2498.2", "bsz": "49.5", "num_updates": "45400", "lr": "2.00208e-05", "gnorm": "98.033", "loss_scale": "32", "train_wall": "79.57", "gb_free": "20.7", "wall": "17887"}
[2023-07-04 14:52:15,355][train_inner][INFO] - {"epoch": 79, "update": 78.791, "loss": "30.119", "ntokens": "2487.31", "nsentences": "49.46", "nll_loss": "0.599", "wps": "6026.7", "ups": "2.42", "wpb": "2487.3", "bsz": "49.5", "num_updates": "45600", "lr": "1.97232e-05", "gnorm": "98.613", "loss_scale": "32", "train_wall": "81.82", "gb_free": "20.8", "wall": "17970"}
[2023-07-04 14:53:03,893][fairseq_cli.train][INFO] - end of epoch 79 (average epoch stats below)
[2023-07-04 14:53:03,903][train][INFO] - {"epoch": 79, "train_loss": "30.359", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.6", "train_wps": "6105.6", "train_ups": "2.45", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "45721", "train_lr": "1.95453e-05", "train_gnorm": "99.039", "train_loss_scale": "32", "train_train_wall": "234.03", "train_gb_free": "20.8", "train_wall": "18018"}
[2023-07-04 14:53:03,921][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 14:53:03,925][fairseq.trainer][INFO] - begin training epoch 80
[2023-07-04 14:53:03,926][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 14:53:37,313][train_inner][INFO] - {"epoch": 80, "update": 79.136, "loss": "30.624", "ntokens": "2497.38", "nsentences": "49.57", "nll_loss": "0.608", "wps": "6094.9", "ups": "2.44", "wpb": "2497.4", "bsz": "49.6", "num_updates": "45800", "lr": "1.943e-05", "gnorm": "99.247", "loss_scale": "32", "train_wall": "80.92", "gb_free": "20.8", "wall": "18052"}
[2023-07-04 14:55:00,804][train_inner][INFO] - {"epoch": 80, "update": 79.482, "loss": "29.997", "ntokens": "2486.77", "nsentences": "49.085", "nll_loss": "0.592", "wps": "5957.7", "ups": "2.4", "wpb": "2486.8", "bsz": "49.1", "num_updates": "46000", "lr": "1.91411e-05", "gnorm": "99.332", "loss_scale": "32", "train_wall": "82.71", "gb_free": "20.9", "wall": "18135"}
[2023-07-04 14:56:20,985][train_inner][INFO] - {"epoch": 80, "update": 79.827, "loss": "30.397", "ntokens": "2498.97", "nsentences": "49.07", "nll_loss": "0.597", "wps": "6234.2", "ups": "2.49", "wpb": "2499", "bsz": "49.1", "num_updates": "46200", "lr": "1.88565e-05", "gnorm": "98.394", "loss_scale": "32", "train_wall": "79.43", "gb_free": "20.7", "wall": "18215"}
[2023-07-04 14:56:45,314][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 16.0
[2023-07-04 14:57:03,221][fairseq_cli.train][INFO] - begin validation on "dev_other" subset
[2023-07-04 14:57:17,612][dev_other][INFO] - {"epoch": 80, "dev_other_loss": "42.26", "dev_other_ntokens": "272.352", "dev_other_nsentences": "10.6074", "dev_other_nll_loss": "1.646", "dev_other_uer": "23.107", "dev_other_wer": "23.627", "dev_other_raw_wer": "23.627", "dev_other_wps": "5339", "dev_other_wpb": "272.4", "dev_other_bsz": "10.6", "dev_other_num_updates": "46299", "dev_other_best_wer": "23.627"}
[2023-07-04 14:57:17,614][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 80 @ 46299 updates
[2023-07-04 14:57:17,614][fairseq.trainer][INFO] - Saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt
[2023-07-04 14:57:21,745][fairseq.trainer][INFO] - Finished saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt
[2023-07-04 14:57:24,187][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt (epoch 80 @ 46299 updates, score 23.627) (writing took 6.573091875761747 seconds)
[2023-07-04 14:57:24,187][fairseq_cli.train][INFO] - end of epoch 80 (average epoch stats below)
[2023-07-04 14:57:24,197][train][INFO] - {"epoch": 80, "train_loss": "30.37", "train_ntokens": "2493.56", "train_nsentences": "49.2941", "train_nll_loss": "0.6", "train_wps": "5537.3", "train_ups": "2.22", "train_wpb": "2493.6", "train_bsz": "49.3", "train_num_updates": "46299", "train_lr": "1.87172e-05", "train_gnorm": "98.638", "train_loss_scale": "16", "train_train_wall": "236.81", "train_gb_free": "20.7", "train_wall": "18278"}
[2023-07-04 14:57:24,211][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 14:57:24,215][fairseq.trainer][INFO] - begin training epoch 81
[2023-07-04 14:57:24,215][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 14:58:06,526][train_inner][INFO] - {"epoch": 81, "update": 80.174, "loss": "31.181", "ntokens": "2496.86", "nsentences": "49.205", "nll_loss": "0.614", "wps": "4732", "ups": "1.9", "wpb": "2496.9", "bsz": "49.2", "num_updates": "46400", "lr": "1.85762e-05", "gnorm": "101.254", "loss_scale": "16", "train_wall": "83.48", "gb_free": "20.8", "wall": "18321"}
[2023-07-04 14:59:28,526][train_inner][INFO] - {"epoch": 81, "update": 80.52, "loss": "29.791", "ntokens": "2493.74", "nsentences": "49.11", "nll_loss": "0.587", "wps": "6083.1", "ups": "2.44", "wpb": "2493.7", "bsz": "49.1", "num_updates": "46600", "lr": "1.83e-05", "gnorm": "99.159", "loss_scale": "16", "train_wall": "81.24", "gb_free": "20.8", "wall": "18403"}
[2023-07-04 15:00:50,066][train_inner][INFO] - {"epoch": 81, "update": 80.865, "loss": "30.709", "ntokens": "2487.57", "nsentences": "49.62", "nll_loss": "0.613", "wps": "6102.1", "ups": "2.45", "wpb": "2487.6", "bsz": "49.6", "num_updates": "46800", "lr": "1.80279e-05", "gnorm": "100.89", "loss_scale": "16", "train_wall": "80.81", "gb_free": "20.7", "wall": "18484"}
[2023-07-04 15:01:22,678][fairseq_cli.train][INFO] - end of epoch 81 (average epoch stats below)
[2023-07-04 15:01:22,687][train][INFO] - {"epoch": 81, "train_loss": "30.525", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.603", "train_wps": "6053.9", "train_ups": "2.43", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "46878", "train_lr": "1.79229e-05", "train_gnorm": "100.456", "train_loss_scale": "16", "train_train_wall": "235.99", "train_gb_free": "20.8", "train_wall": "18517"}
[2023-07-04 15:01:22,706][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 15:01:22,711][fairseq.trainer][INFO] - begin training epoch 82
[2023-07-04 15:01:22,711][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 15:02:13,481][train_inner][INFO] - {"epoch": 82, "update": 81.211, "loss": "29.72", "ntokens": "2498.41", "nsentences": "48.86", "nll_loss": "0.581", "wps": "5991.4", "ups": "2.4", "wpb": "2498.4", "bsz": "48.9", "num_updates": "47000", "lr": "1.77599e-05", "gnorm": "98.273", "loss_scale": "16", "train_wall": "82.35", "gb_free": "20.8", "wall": "18568"}
[2023-07-04 15:03:34,543][train_inner][INFO] - {"epoch": 82, "update": 81.556, "loss": "29.11", "ntokens": "2489.12", "nsentences": "49.105", "nll_loss": "0.574", "wps": "6142", "ups": "2.47", "wpb": "2489.1", "bsz": "49.1", "num_updates": "47200", "lr": "1.74959e-05", "gnorm": "99.643", "loss_scale": "16", "train_wall": "80.35", "gb_free": "20.8", "wall": "18649"}
[2023-07-04 15:04:58,641][train_inner][INFO] - {"epoch": 82, "update": 81.902, "loss": "29.243", "ntokens": "2491.76", "nsentences": "49.85", "nll_loss": "0.585", "wps": "5926.4", "ups": "2.38", "wpb": "2491.8", "bsz": "49.9", "num_updates": "47400", "lr": "1.72358e-05", "gnorm": "97.992", "loss_scale": "16", "train_wall": "83.33", "gb_free": "20.8", "wall": "18733"}
[2023-07-04 15:05:22,558][fairseq_cli.train][INFO] - end of epoch 82 (average epoch stats below)
[2023-07-04 15:05:22,566][train][INFO] - {"epoch": 82, "train_loss": "29.254", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.578", "train_wps": "6018.9", "train_ups": "2.41", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "47457", "train_lr": "1.71623e-05", "train_gnorm": "98.98", "train_loss_scale": "16", "train_train_wall": "237.41", "train_gb_free": "20.9", "train_wall": "18757"}
[2023-07-04 15:05:22,583][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 15:05:22,588][fairseq.trainer][INFO] - begin training epoch 83
[2023-07-04 15:05:22,589][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 15:06:20,275][train_inner][INFO] - {"epoch": 83, "update": 82.247, "loss": "29.468", "ntokens": "2489.97", "nsentences": "48.65", "nll_loss": "0.576", "wps": "6101.1", "ups": "2.45", "wpb": "2490", "bsz": "48.6", "num_updates": "47600", "lr": "1.69795e-05", "gnorm": "100.954", "loss_scale": "16", "train_wall": "80.59", "gb_free": "20.8", "wall": "18815"}
[2023-07-04 15:07:41,693][train_inner][INFO] - {"epoch": 83, "update": 82.592, "loss": "29.213", "ntokens": "2496.64", "nsentences": "49.835", "nll_loss": "0.583", "wps": "6133.6", "ups": "2.46", "wpb": "2496.6", "bsz": "49.8", "num_updates": "47800", "lr": "1.67271e-05", "gnorm": "96.632", "loss_scale": "16", "train_wall": "80.69", "gb_free": "20.8", "wall": "18896"}
[2023-07-04 15:09:03,554][train_inner][INFO] - {"epoch": 83, "update": 82.938, "loss": "28.78", "ntokens": "2498.1", "nsentences": "49.365", "nll_loss": "0.569", "wps": "6104.1", "ups": "2.44", "wpb": "2498.1", "bsz": "49.4", "num_updates": "48000", "lr": "1.64784e-05", "gnorm": "97.009", "loss_scale": "16", "train_wall": "81.08", "gb_free": "20.7", "wall": "18978"}
[2023-07-04 15:09:18,681][fairseq_cli.train][INFO] - end of epoch 83 (average epoch stats below)
[2023-07-04 15:09:18,690][train][INFO] - {"epoch": 83, "train_loss": "28.949", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.572", "train_wps": "6114.6", "train_ups": "2.45", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "48036", "train_lr": "1.6434e-05", "train_gnorm": "97.682", "train_loss_scale": "16", "train_train_wall": "233.65", "train_gb_free": "20.8", "train_wall": "18993"}
[2023-07-04 15:09:18,706][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 15:09:18,711][fairseq.trainer][INFO] - begin training epoch 84
[2023-07-04 15:09:18,711][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 15:10:28,624][train_inner][INFO] - {"epoch": 84, "update": 83.283, "loss": "28.664", "ntokens": "2488.74", "nsentences": "49.37", "nll_loss": "0.569", "wps": "5852", "ups": "2.35", "wpb": "2488.7", "bsz": "49.4", "num_updates": "48200", "lr": "1.62334e-05", "gnorm": "99.275", "loss_scale": "16", "train_wall": "83.99", "gb_free": "20.8", "wall": "19063"}
[2023-07-04 15:11:48,946][train_inner][INFO] - {"epoch": 84, "update": 83.629, "loss": "29.999", "ntokens": "2498.28", "nsentences": "49.09", "nll_loss": "0.589", "wps": "6221.4", "ups": "2.49", "wpb": "2498.3", "bsz": "49.1", "num_updates": "48400", "lr": "1.59921e-05", "gnorm": "100.855", "loss_scale": "32", "train_wall": "79.59", "gb_free": "20.8", "wall": "19143"}
[2023-07-04 15:13:08,764][train_inner][INFO] - {"epoch": 84, "update": 83.974, "loss": "29.089", "ntokens": "2488.32", "nsentences": "49.43", "nll_loss": "0.578", "wps": "6235.8", "ups": "2.51", "wpb": "2488.3", "bsz": "49.4", "num_updates": "48600", "lr": "1.57543e-05", "gnorm": "98.257", "loss_scale": "32", "train_wall": "79.08", "gb_free": "20.8", "wall": "19223"}
[2023-07-04 15:13:14,832][fairseq_cli.train][INFO] - end of epoch 84 (average epoch stats below)
[2023-07-04 15:13:14,841][train][INFO] - {"epoch": 84, "train_loss": "29.318", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.58", "train_wps": "6113.9", "train_ups": "2.45", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "48615", "train_lr": "1.57366e-05", "train_gnorm": "99.515", "train_loss_scale": "32", "train_train_wall": "233.69", "train_gb_free": "20.8", "train_wall": "19229"}
[2023-07-04 15:13:14,858][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 15:13:14,863][fairseq.trainer][INFO] - begin training epoch 85
[2023-07-04 15:13:14,864][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 15:14:31,823][train_inner][INFO] - {"epoch": 85, "update": 84.32, "loss": "28.696", "ntokens": "2488.84", "nsentences": "49.675", "nll_loss": "0.573", "wps": "5993.7", "ups": "2.41", "wpb": "2488.8", "bsz": "49.7", "num_updates": "48800", "lr": "1.55201e-05", "gnorm": "97.37", "loss_scale": "32", "train_wall": "81.96", "gb_free": "20.8", "wall": "19306"}
[2023-07-04 15:15:55,607][train_inner][INFO] - {"epoch": 85, "update": 84.665, "loss": "29.098", "ntokens": "2500.99", "nsentences": "49.245", "nll_loss": "0.573", "wps": "5970.7", "ups": "2.39", "wpb": "2501", "bsz": "49.2", "num_updates": "49000", "lr": "1.52894e-05", "gnorm": "100.061", "loss_scale": "32", "train_wall": "83", "gb_free": "20.8", "wall": "19390"}
[2023-07-04 15:17:17,281][fairseq_cli.train][INFO] - begin validation on "dev_other" subset
[2023-07-04 15:17:31,614][dev_other][INFO] - {"epoch": 85, "dev_other_loss": "42.223", "dev_other_ntokens": "272.352", "dev_other_nsentences": "10.6074", "dev_other_nll_loss": "1.644", "dev_other_uer": "22.952", "dev_other_wer": "23.513", "dev_other_raw_wer": "23.513", "dev_other_wps": "5227", "dev_other_wpb": "272.4", "dev_other_bsz": "10.6", "dev_other_num_updates": "49194", "dev_other_best_wer": "23.513"}
[2023-07-04 15:17:31,616][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 85 @ 49194 updates
[2023-07-04 15:17:31,617][fairseq.trainer][INFO] - Saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt
[2023-07-04 15:17:34,435][fairseq.trainer][INFO] - Finished saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt
[2023-07-04 15:17:38,507][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt (epoch 85 @ 49194 updates, score 23.513) (writing took 6.891367247328162 seconds)
[2023-07-04 15:17:38,508][fairseq_cli.train][INFO] - end of epoch 85 (average epoch stats below)
[2023-07-04 15:17:38,517][train][INFO] - {"epoch": 85, "train_loss": "29.059", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.574", "train_wps": "5475.7", "train_ups": "2.2", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "49194", "train_lr": "1.50688e-05", "train_gnorm": "98.914", "train_loss_scale": "32", "train_train_wall": "239.88", "train_gb_free": "20.9", "train_wall": "19493"}
[2023-07-04 15:17:38,533][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 15:17:38,538][fairseq.trainer][INFO] - begin training epoch 86
[2023-07-04 15:17:38,539][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 15:17:41,350][train_inner][INFO] - {"epoch": 86, "update": 85.01, "loss": "29.437", "ntokens": "2492.32", "nsentences": "48.9", "nll_loss": "0.578", "wps": "4714.4", "ups": "1.89", "wpb": "2492.3", "bsz": "48.9", "num_updates": "49200", "lr": "1.50621e-05", "gnorm": "99.416", "loss_scale": "32", "train_wall": "83.45", "gb_free": "20.8", "wall": "19496"}
[2023-07-04 15:19:05,001][train_inner][INFO] - {"epoch": 86, "update": 85.356, "loss": "29.083", "ntokens": "2502.39", "nsentences": "49.56", "nll_loss": "0.576", "wps": "5983.6", "ups": "2.39", "wpb": "2502.4", "bsz": "49.6", "num_updates": "49400", "lr": "1.48381e-05", "gnorm": "98.193", "loss_scale": "32", "train_wall": "82.88", "gb_free": "20.8", "wall": "19579"}
[2023-07-04 15:20:26,081][train_inner][INFO] - {"epoch": 86, "update": 85.701, "loss": "28.944", "ntokens": "2491.86", "nsentences": "49.02", "nll_loss": "0.569", "wps": "6147.5", "ups": "2.47", "wpb": "2491.9", "bsz": "49", "num_updates": "49600", "lr": "1.46175e-05", "gnorm": "98.246", "loss_scale": "32", "train_wall": "80.34", "gb_free": "20.8", "wall": "19660"}
[2023-07-04 15:21:37,162][fairseq_cli.train][INFO] - end of epoch 86 (average epoch stats below)
[2023-07-04 15:21:37,175][train][INFO] - {"epoch": 86, "train_loss": "28.988", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.573", "train_wps": "6049.8", "train_ups": "2.43", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "49773", "train_lr": "1.44294e-05", "train_gnorm": "98.476", "train_loss_scale": "32", "train_train_wall": "236.16", "train_gb_free": "20.8", "train_wall": "19731"}
[2023-07-04 15:21:37,195][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 15:21:37,200][fairseq.trainer][INFO] - begin training epoch 87
[2023-07-04 15:21:37,201][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 15:21:48,085][train_inner][INFO] - {"epoch": 87, "update": 86.047, "loss": "28.783", "ntokens": "2483.88", "nsentences": "49.175", "nll_loss": "0.57", "wps": "6058.9", "ups": "2.44", "wpb": "2483.9", "bsz": "49.2", "num_updates": "49800", "lr": "1.44002e-05", "gnorm": "100.184", "loss_scale": "32", "train_wall": "80.93", "gb_free": "20.8", "wall": "19742"}
[2023-07-04 15:23:09,191][train_inner][INFO] - {"epoch": 87, "update": 86.392, "loss": "28.438", "ntokens": "2503.57", "nsentences": "48.84", "nll_loss": "0.555", "wps": "6174.3", "ups": "2.47", "wpb": "2503.6", "bsz": "48.8", "num_updates": "50000", "lr": "1.41861e-05", "gnorm": "99.129", "loss_scale": "32", "train_wall": "80.32", "gb_free": "20.9", "wall": "19823"}
[2023-07-04 15:24:30,231][train_inner][INFO] - {"epoch": 87, "update": 86.737, "loss": "29.055", "ntokens": "2490.43", "nsentences": "49.41", "nll_loss": "0.576", "wps": "6146.9", "ups": "2.47", "wpb": "2490.4", "bsz": "49.4", "num_updates": "50200", "lr": "1.39752e-05", "gnorm": "95.775", "loss_scale": "32", "train_wall": "80.31", "gb_free": "20.8", "wall": "19905"}
[2023-07-04 15:25:33,000][fairseq_cli.train][INFO] - end of epoch 87 (average epoch stats below)
[2023-07-04 15:25:33,026][train][INFO] - {"epoch": 87, "train_loss": "28.405", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.561", "train_wps": "6122.1", "train_ups": "2.46", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "50352", "train_lr": "1.3817e-05", "train_gnorm": "98.514", "train_loss_scale": "64", "train_train_wall": "233.32", "train_gb_free": "20.8", "train_wall": "19967"}
[2023-07-04 15:25:33,060][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 15:25:33,066][fairseq.trainer][INFO] - begin training epoch 88
[2023-07-04 15:25:33,066][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 15:25:46,373][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
[2023-07-04 15:25:52,649][train_inner][INFO] - {"epoch": 88, "update": 87.085, "loss": "27.516", "ntokens": "2487.7", "nsentences": "49.505", "nll_loss": "0.548", "wps": "6037.6", "ups": "2.43", "wpb": "2487.7", "bsz": "49.5", "num_updates": "50400", "lr": "1.37674e-05", "gnorm": "99.411", "loss_scale": "32", "train_wall": "81.31", "gb_free": "20.7", "wall": "19987"}
[2023-07-04 15:27:15,472][train_inner][INFO] - {"epoch": 88, "update": 87.43, "loss": "27.759", "ntokens": "2490.32", "nsentences": "49.125", "nll_loss": "0.548", "wps": "6014.3", "ups": "2.42", "wpb": "2490.3", "bsz": "49.1", "num_updates": "50600", "lr": "1.35628e-05", "gnorm": "98.695", "loss_scale": "32", "train_wall": "82.1", "gb_free": "20.8", "wall": "20070"}
[2023-07-04 15:28:38,704][train_inner][INFO] - {"epoch": 88, "update": 87.775, "loss": "28.753", "ntokens": "2497.24", "nsentences": "49.625", "nll_loss": "0.571", "wps": "6001.5", "ups": "2.4", "wpb": "2497.2", "bsz": "49.6", "num_updates": "50800", "lr": "1.33611e-05", "gnorm": "98.443", "loss_scale": "32", "train_wall": "82.46", "gb_free": "20.8", "wall": "20153"}
[2023-07-04 15:29:34,026][fairseq_cli.train][INFO] - end of epoch 88 (average epoch stats below)
[2023-07-04 15:29:34,035][train][INFO] - {"epoch": 88, "train_loss": "28.093", "train_ntokens": "2493.58", "train_nsentences": "49.2889", "train_nll_loss": "0.555", "train_wps": "5980.5", "train_ups": "2.4", "train_wpb": "2493.6", "train_bsz": "49.3", "train_num_updates": "50930", "train_lr": "1.32317e-05", "train_gnorm": "98.83", "train_loss_scale": "32", "train_train_wall": "238.48", "train_gb_free": "20.8", "train_wall": "20208"}
[2023-07-04 15:29:34,053][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 15:29:34,058][fairseq.trainer][INFO] - begin training epoch 89
[2023-07-04 15:29:34,059][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 15:30:03,026][train_inner][INFO] - {"epoch": 89, "update": 88.121, "loss": "27.835", "ntokens": "2499.08", "nsentences": "48.935", "nll_loss": "0.545", "wps": "5928.1", "ups": "2.37", "wpb": "2499.1", "bsz": "48.9", "num_updates": "51000", "lr": "1.31625e-05", "gnorm": "101.008", "loss_scale": "32", "train_wall": "83.24", "gb_free": "20.8", "wall": "20237"}
[2023-07-04 15:31:26,681][train_inner][INFO] - {"epoch": 89, "update": 88.466, "loss": "28.039", "ntokens": "2489.14", "nsentences": "50.07", "nll_loss": "0.564", "wps": "5951.7", "ups": "2.39", "wpb": "2489.1", "bsz": "50.1", "num_updates": "51200", "lr": "1.29668e-05", "gnorm": "96.52", "loss_scale": "32", "train_wall": "82.88", "gb_free": "20.8", "wall": "20321"}
[2023-07-04 15:32:51,705][train_inner][INFO] - {"epoch": 89, "update": 88.812, "loss": "27.342", "ntokens": "2495.82", "nsentences": "49.945", "nll_loss": "0.547", "wps": "5871.5", "ups": "2.35", "wpb": "2495.8", "bsz": "49.9", "num_updates": "51400", "lr": "1.2774e-05", "gnorm": "96.455", "loss_scale": "32", "train_wall": "84.25", "gb_free": "20.8", "wall": "20406"}
[2023-07-04 15:33:37,178][fairseq_cli.train][INFO] - end of epoch 89 (average epoch stats below)
[2023-07-04 15:33:37,187][train][INFO] - {"epoch": 89, "train_loss": "27.926", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.552", "train_wps": "5937.9", "train_ups": "2.38", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "51509", "train_lr": "1.26702e-05", "train_gnorm": "97.922", "train_loss_scale": "32", "train_train_wall": "240.62", "train_gb_free": "20.7", "train_wall": "20451"}
[2023-07-04 15:33:37,201][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 15:33:37,205][fairseq.trainer][INFO] - begin training epoch 90
[2023-07-04 15:33:37,205][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 15:34:15,440][train_inner][INFO] - {"epoch": 90, "update": 89.157, "loss": "27.919", "ntokens": "2484.2", "nsentences": "49.105", "nll_loss": "0.552", "wps": "5934.2", "ups": "2.39", "wpb": "2484.2", "bsz": "49.1", "num_updates": "51600", "lr": "1.25841e-05", "gnorm": "97.713", "loss_scale": "32", "train_wall": "82.67", "gb_free": "20.8", "wall": "20490"}
[2023-07-04 15:35:35,063][train_inner][INFO] - {"epoch": 90, "update": 89.503, "loss": "27.846", "ntokens": "2491.47", "nsentences": "48.97", "nll_loss": "0.547", "wps": "6258.8", "ups": "2.51", "wpb": "2491.5", "bsz": "49", "num_updates": "51800", "lr": "1.2397e-05", "gnorm": "99.159", "loss_scale": "32", "train_wall": "78.89", "gb_free": "20.8", "wall": "20569"}
[2023-07-04 15:36:57,369][train_inner][INFO] - {"epoch": 90, "update": 89.848, "loss": "28.068", "ntokens": "2495.97", "nsentences": "49.04", "nll_loss": "0.551", "wps": "6065.7", "ups": "2.43", "wpb": "2496", "bsz": "49", "num_updates": "52000", "lr": "1.22127e-05", "gnorm": "99.688", "loss_scale": "32", "train_wall": "81.56", "gb_free": "20.7", "wall": "20652"}
[2023-07-04 15:37:33,240][fairseq_cli.train][INFO] - begin validation on "dev_other" subset
[2023-07-04 15:37:47,693][dev_other][INFO] - {"epoch": 90, "dev_other_loss": "42.221", "dev_other_ntokens": "272.352", "dev_other_nsentences": "10.6074", "dev_other_nll_loss": "1.644", "dev_other_uer": "22.886", "dev_other_wer": "23.405", "dev_other_raw_wer": "23.405", "dev_other_wps": "5197", "dev_other_wpb": "272.4", "dev_other_bsz": "10.6", "dev_other_num_updates": "52088", "dev_other_best_wer": "23.405"}
[2023-07-04 15:37:47,695][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 90 @ 52088 updates
[2023-07-04 15:37:47,696][fairseq.trainer][INFO] - Saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt
[2023-07-04 15:37:50,940][fairseq.trainer][INFO] - Finished saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt
[2023-07-04 15:37:53,875][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt (epoch 90 @ 52088 updates, score 23.405) (writing took 6.180011218413711 seconds)
[2023-07-04 15:37:53,876][fairseq_cli.train][INFO] - end of epoch 90 (average epoch stats below)
[2023-07-04 15:37:53,886][train][INFO] - {"epoch": 90, "train_loss": "27.827", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.55", "train_wps": "5624.5", "train_ups": "2.26", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "52088", "train_lr": "1.21325e-05", "train_gnorm": "98.454", "train_loss_scale": "32", "train_train_wall": "233.62", "train_gb_free": "20.8", "train_wall": "20708"}
[2023-07-04 15:37:53,900][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 15:37:53,905][fairseq.trainer][INFO] - begin training epoch 91
[2023-07-04 15:37:53,905][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 15:38:37,837][train_inner][INFO] - {"epoch": 91, "update": 90.193, "loss": "28.034", "ntokens": "2508.08", "nsentences": "48.635", "nll_loss": "0.544", "wps": "4993.2", "ups": "1.99", "wpb": "2508.1", "bsz": "48.6", "num_updates": "52200", "lr": "1.20311e-05", "gnorm": "97.689", "loss_scale": "32", "train_wall": "78.81", "gb_free": "20.8", "wall": "20752"}
[2023-07-04 15:40:00,319][train_inner][INFO] - {"epoch": 91, "update": 90.539, "loss": "28.596", "ntokens": "2487.74", "nsentences": "48.265", "nll_loss": "0.555", "wps": "6032.9", "ups": "2.43", "wpb": "2487.7", "bsz": "48.3", "num_updates": "52400", "lr": "1.18523e-05", "gnorm": "99.35", "loss_scale": "32", "train_wall": "81.7", "gb_free": "20.7", "wall": "20835"}
[2023-07-04 15:41:24,311][train_inner][INFO] - {"epoch": 91, "update": 90.884, "loss": "27.929", "ntokens": "2497.84", "nsentences": "50.77", "nll_loss": "0.568", "wps": "5948.4", "ups": "2.38", "wpb": "2497.8", "bsz": "50.8", "num_updates": "52600", "lr": "1.16761e-05", "gnorm": "99.669", "loss_scale": "64", "train_wall": "83.21", "gb_free": "20.8", "wall": "20919"}
[2023-07-04 15:41:52,717][fairseq_cli.train][INFO] - end of epoch 91 (average epoch stats below)
[2023-07-04 15:41:52,727][train][INFO] - {"epoch": 91, "train_loss": "28.128", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.556", "train_wps": "6045.1", "train_ups": "2.42", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "52667", "train_lr": "1.16176e-05", "train_gnorm": "99.135", "train_loss_scale": "64", "train_train_wall": "236.31", "train_gb_free": "20.8", "train_wall": "20947"}
[2023-07-04 15:41:52,746][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 15:41:52,751][fairseq.trainer][INFO] - begin training epoch 92
[2023-07-04 15:41:52,752][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 15:42:47,600][train_inner][INFO] - {"epoch": 92, "update": 91.23, "loss": "27.42", "ntokens": "2486.16", "nsentences": "50.28", "nll_loss": "0.555", "wps": "5970.7", "ups": "2.4", "wpb": "2486.2", "bsz": "50.3", "num_updates": "52800", "lr": "1.15025e-05", "gnorm": "97.469", "loss_scale": "64", "train_wall": "82.22", "gb_free": "20.9", "wall": "21002"}
[2023-07-04 15:44:10,211][train_inner][INFO] - {"epoch": 92, "update": 91.575, "loss": "28.07", "ntokens": "2498.83", "nsentences": "48.285", "nll_loss": "0.542", "wps": "6050.3", "ups": "2.42", "wpb": "2498.8", "bsz": "48.3", "num_updates": "53000", "lr": "1.13315e-05", "gnorm": "98.829", "loss_scale": "64", "train_wall": "81.82", "gb_free": "20.8", "wall": "21084"}
[2023-07-04 15:45:33,465][train_inner][INFO] - {"epoch": 92, "update": 91.921, "loss": "27.393", "ntokens": "2493.49", "nsentences": "49.41", "nll_loss": "0.543", "wps": "5990.8", "ups": "2.4", "wpb": "2493.5", "bsz": "49.4", "num_updates": "53200", "lr": "1.1163e-05", "gnorm": "97.136", "loss_scale": "64", "train_wall": "82.47", "gb_free": "20.8", "wall": "21168"}
[2023-07-04 15:45:53,095][fairseq_cli.train][INFO] - end of epoch 92 (average epoch stats below)
[2023-07-04 15:45:53,106][train][INFO] - {"epoch": 92, "train_loss": "27.546", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.545", "train_wps": "6006.4", "train_ups": "2.41", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "53246", "train_lr": "1.11246e-05", "train_gnorm": "97.896", "train_loss_scale": "64", "train_train_wall": "237.81", "train_gb_free": "20.7", "train_wall": "21187"}
[2023-07-04 15:45:53,123][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 15:45:53,129][fairseq.trainer][INFO] - begin training epoch 93
[2023-07-04 15:45:53,129][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 15:47:01,655][train_inner][INFO] - {"epoch": 93, "update": 92.266, "loss": "26.661", "ntokens": "2483.84", "nsentences": "49.39", "nll_loss": "0.53", "wps": "5633.8", "ups": "2.27", "wpb": "2483.8", "bsz": "49.4", "num_updates": "53400", "lr": "1.09971e-05", "gnorm": "97.166", "loss_scale": "64", "train_wall": "87.03", "gb_free": "20.8", "wall": "21256"}
[2023-07-04 15:48:28,221][train_inner][INFO] - {"epoch": 93, "update": 92.611, "loss": "26.659", "ntokens": "2493.5", "nsentences": "49.28", "nll_loss": "0.527", "wps": "5761.5", "ups": "2.31", "wpb": "2493.5", "bsz": "49.3", "num_updates": "53600", "lr": "1.08336e-05", "gnorm": "95.411", "loss_scale": "64", "train_wall": "85.76", "gb_free": "20.7", "wall": "21342"}
[2023-07-04 15:49:52,630][train_inner][INFO] - {"epoch": 93, "update": 92.957, "loss": "27.568", "ntokens": "2497.39", "nsentences": "49.315", "nll_loss": "0.544", "wps": "5918.1", "ups": "2.37", "wpb": "2497.4", "bsz": "49.3", "num_updates": "53800", "lr": "1.06725e-05", "gnorm": "96.54", "loss_scale": "64", "train_wall": "83.64", "gb_free": "20.8", "wall": "21427"}
[2023-07-04 15:50:03,060][fairseq_cli.train][INFO] - end of epoch 93 (average epoch stats below)
[2023-07-04 15:50:03,070][train][INFO] - {"epoch": 93, "train_loss": "26.928", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.532", "train_wps": "5776.1", "train_ups": "2.32", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "53825", "train_lr": "1.06525e-05", "train_gnorm": "96.672", "train_loss_scale": "64", "train_train_wall": "247.32", "train_gb_free": "20.8", "train_wall": "21437"}
[2023-07-04 15:50:03,088][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 15:50:03,095][fairseq.trainer][INFO] - begin training epoch 94
[2023-07-04 15:50:03,095][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 15:51:17,101][train_inner][INFO] - {"epoch": 94, "update": 93.302, "loss": "26.278", "ntokens": "2488.86", "nsentences": "48.785", "nll_loss": "0.515", "wps": "5893.6", "ups": "2.37", "wpb": "2488.9", "bsz": "48.8", "num_updates": "54000", "lr": "1.05138e-05", "gnorm": "97.239", "loss_scale": "64", "train_wall": "83.38", "gb_free": "20.8", "wall": "21511"}
[2023-07-04 15:52:40,365][train_inner][INFO] - {"epoch": 94, "update": 93.648, "loss": "26.392", "ntokens": "2501.88", "nsentences": "49.595", "nll_loss": "0.523", "wps": "6010.4", "ups": "2.4", "wpb": "2501.9", "bsz": "49.6", "num_updates": "54200", "lr": "1.03575e-05", "gnorm": "97.27", "loss_scale": "64", "train_wall": "82.51", "gb_free": "20.8", "wall": "21595"}
[2023-07-04 15:54:04,029][train_inner][INFO] - {"epoch": 94, "update": 93.993, "loss": "27.974", "ntokens": "2490.12", "nsentences": "49.28", "nll_loss": "0.554", "wps": "5953.4", "ups": "2.39", "wpb": "2490.1", "bsz": "49.3", "num_updates": "54400", "lr": "1.02035e-05", "gnorm": "97.854", "loss_scale": "64", "train_wall": "82.88", "gb_free": "20.8", "wall": "21678"}
[2023-07-04 15:54:05,689][fairseq_cli.train][INFO] - end of epoch 94 (average epoch stats below)
[2023-07-04 15:54:05,699][train][INFO] - {"epoch": 94, "train_loss": "26.954", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.533", "train_wps": "5950.7", "train_ups": "2.39", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "54404", "train_lr": "1.02005e-05", "train_gnorm": "96.987", "train_loss_scale": "64", "train_train_wall": "240.09", "train_gb_free": "20.8", "train_wall": "21680"}
[2023-07-04 15:54:05,714][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 15:54:05,719][fairseq.trainer][INFO] - begin training epoch 95
[2023-07-04 15:54:05,720][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 15:55:28,408][train_inner][INFO] - {"epoch": 95, "update": 94.339, "loss": "26.681", "ntokens": "2501.46", "nsentences": "49.785", "nll_loss": "0.531", "wps": "5929.8", "ups": "2.37", "wpb": "2501.5", "bsz": "49.8", "num_updates": "54600", "lr": "1.00518e-05", "gnorm": "95.981", "loss_scale": "128", "train_wall": "83.25", "gb_free": "20.8", "wall": "21763"}
[2023-07-04 15:55:44,765][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2023-07-04 15:56:47,463][train_inner][INFO] - {"epoch": 95, "update": 94.686, "loss": "27.422", "ntokens": "2489.09", "nsentences": "49.43", "nll_loss": "0.545", "wps": "6298", "ups": "2.53", "wpb": "2489.1", "bsz": "49.4", "num_updates": "54800", "lr": "9.90239e-06", "gnorm": "95.976", "loss_scale": "64", "train_wall": "78.36", "gb_free": "20.8", "wall": "21842"}
[2023-07-04 15:57:26,847][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
[2023-07-04 15:58:03,334][fairseq_cli.train][INFO] - begin validation on "dev_other" subset
[2023-07-04 15:58:18,279][dev_other][INFO] - {"epoch": 95, "dev_other_loss": "42.842", "dev_other_ntokens": "272.352", "dev_other_nsentences": "10.6074", "dev_other_nll_loss": "1.669", "dev_other_uer": "22.691", "dev_other_wer": "23.23", "dev_other_raw_wer": "23.23", "dev_other_wps": "5023.1", "dev_other_wpb": "272.4", "dev_other_bsz": "10.6", "dev_other_num_updates": "54981", "dev_other_best_wer": "23.23"}
[2023-07-04 15:58:18,281][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 95 @ 54981 updates
[2023-07-04 15:58:18,281][fairseq.trainer][INFO] - Saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt
[2023-07-04 15:58:22,520][fairseq.trainer][INFO] - Finished saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt
[2023-07-04 15:58:26,900][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt (epoch 95 @ 54981 updates, score 23.23) (writing took 8.619517121464014 seconds)
[2023-07-04 15:58:26,901][fairseq_cli.train][INFO] - end of epoch 95 (average epoch stats below)
[2023-07-04 15:58:26,909][train][INFO] - {"epoch": 95, "train_loss": "27.145", "train_ntokens": "2493.3", "train_nsentences": "49.3016", "train_nll_loss": "0.537", "train_wps": "5507.8", "train_ups": "2.21", "train_wpb": "2493.3", "train_bsz": "49.3", "train_num_updates": "54981", "train_lr": "9.76906e-06", "train_gnorm": "96.283", "train_loss_scale": "32", "train_train_wall": "235.15", "train_gb_free": "20.8", "train_wall": "21941"}
[2023-07-04 15:58:26,924][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 15:58:26,928][fairseq.trainer][INFO] - begin training epoch 96
[2023-07-04 15:58:26,928][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 15:58:35,082][train_inner][INFO] - {"epoch": 96, "update": 95.033, "loss": "27.254", "ntokens": "2488.65", "nsentences": "48.58", "nll_loss": "0.532", "wps": "4625.5", "ups": "1.86", "wpb": "2488.7", "bsz": "48.6", "num_updates": "55000", "lr": "9.75517e-06", "gnorm": "97.343", "loss_scale": "32", "train_wall": "82.85", "gb_free": "20.8", "wall": "21949"}
[2023-07-04 15:59:56,479][train_inner][INFO] - {"epoch": 96, "update": 95.378, "loss": "26.72", "ntokens": "2497.86", "nsentences": "49.3", "nll_loss": "0.527", "wps": "6138.2", "ups": "2.46", "wpb": "2497.9", "bsz": "49.3", "num_updates": "55200", "lr": "9.61014e-06", "gnorm": "99.139", "loss_scale": "32", "train_wall": "80.65", "gb_free": "20.8", "wall": "22031"}
[2023-07-04 16:01:17,803][train_inner][INFO] - {"epoch": 96, "update": 95.724, "loss": "27.576", "ntokens": "2496.93", "nsentences": "49.46", "nll_loss": "0.546", "wps": "6141.4", "ups": "2.46", "wpb": "2496.9", "bsz": "49.5", "num_updates": "55400", "lr": "9.46727e-06", "gnorm": "96.667", "loss_scale": "32", "train_wall": "80.58", "gb_free": "20.8", "wall": "22112"}
[2023-07-04 16:02:23,891][fairseq_cli.train][INFO] - end of epoch 96 (average epoch stats below)
[2023-07-04 16:02:23,901][train][INFO] - {"epoch": 96, "train_loss": "27.109", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.536", "train_wps": "6092.2", "train_ups": "2.44", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "55560", "train_lr": "9.3545e-06", "train_gnorm": "97.987", "train_loss_scale": "32", "train_train_wall": "234.4", "train_gb_free": "20.8", "train_wall": "22178"}
[2023-07-04 16:02:23,919][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 16:02:23,925][fairseq.trainer][INFO] - begin training epoch 97
[2023-07-04 16:02:23,925][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 16:02:41,133][train_inner][INFO] - {"epoch": 97, "update": 96.069, "loss": "26.827", "ntokens": "2489.32", "nsentences": "49.28", "nll_loss": "0.531", "wps": "5975.3", "ups": "2.4", "wpb": "2489.3", "bsz": "49.3", "num_updates": "55600", "lr": "9.32652e-06", "gnorm": "97.226", "loss_scale": "32", "train_wall": "82.26", "gb_free": "20.8", "wall": "22195"}
[2023-07-04 16:04:04,054][train_inner][INFO] - {"epoch": 97, "update": 96.415, "loss": "26.778", "ntokens": "2487.14", "nsentences": "49.055", "nll_loss": "0.528", "wps": "5999.6", "ups": "2.41", "wpb": "2487.1", "bsz": "49.1", "num_updates": "55800", "lr": "9.18786e-06", "gnorm": "97.771", "loss_scale": "32", "train_wall": "82.13", "gb_free": "20.8", "wall": "22278"}
[2023-07-04 16:05:25,918][train_inner][INFO] - {"epoch": 97, "update": 96.76, "loss": "26.811", "ntokens": "2494.72", "nsentences": "49.45", "nll_loss": "0.531", "wps": "6095.5", "ups": "2.44", "wpb": "2494.7", "bsz": "49.5", "num_updates": "56000", "lr": "9.05126e-06", "gnorm": "97.084", "loss_scale": "32", "train_wall": "81.11", "gb_free": "20.8", "wall": "22360"}
[2023-07-04 16:06:23,292][fairseq_cli.train][INFO] - end of epoch 97 (average epoch stats below)
[2023-07-04 16:06:23,301][train][INFO] - {"epoch": 97, "train_loss": "26.733", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.528", "train_wps": "6030.9", "train_ups": "2.42", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "56139", "train_lr": "8.95753e-06", "train_gnorm": "97.049", "train_loss_scale": "32", "train_train_wall": "236.85", "train_gb_free": "20.7", "train_wall": "22418"}
[2023-07-04 16:06:23,319][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 16:06:23,324][fairseq.trainer][INFO] - begin training epoch 98
[2023-07-04 16:06:23,324][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 16:06:48,338][train_inner][INFO] - {"epoch": 98, "update": 97.105, "loss": "26.945", "ntokens": "2493.82", "nsentences": "49.035", "nll_loss": "0.53", "wps": "6052.2", "ups": "2.43", "wpb": "2493.8", "bsz": "49", "num_updates": "56200", "lr": "8.9167e-06", "gnorm": "95.972", "loss_scale": "32", "train_wall": "81.36", "gb_free": "20.8", "wall": "22443"}
[2023-07-04 16:08:16,375][train_inner][INFO] - {"epoch": 98, "update": 97.451, "loss": "26.269", "ntokens": "2488.83", "nsentences": "48.53", "nll_loss": "0.512", "wps": "5654.7", "ups": "2.27", "wpb": "2488.8", "bsz": "48.5", "num_updates": "56400", "lr": "8.78413e-06", "gnorm": "96.886", "loss_scale": "32", "train_wall": "87.17", "gb_free": "20.8", "wall": "22531"}
[2023-07-04 16:09:37,888][train_inner][INFO] - {"epoch": 98, "update": 97.796, "loss": "26.686", "ntokens": "2504.42", "nsentences": "49.6", "nll_loss": "0.529", "wps": "6145.8", "ups": "2.45", "wpb": "2504.4", "bsz": "49.6", "num_updates": "56600", "lr": "8.65354e-06", "gnorm": "97.002", "loss_scale": "32", "train_wall": "80.75", "gb_free": "20.8", "wall": "22612"}
[2023-07-04 16:10:26,219][fairseq_cli.train][INFO] - end of epoch 98 (average epoch stats below)
[2023-07-04 16:10:26,229][train][INFO] - {"epoch": 98, "train_loss": "26.563", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.525", "train_wps": "5943.4", "train_ups": "2.38", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "56718", "train_lr": "8.5774e-06", "train_gnorm": "96.401", "train_loss_scale": "32", "train_train_wall": "240.32", "train_gb_free": "20.8", "train_wall": "22661"}
[2023-07-04 16:10:26,524][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 16:10:26,535][fairseq.trainer][INFO] - begin training epoch 99
[2023-07-04 16:10:26,536][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 16:11:02,101][train_inner][INFO] - {"epoch": 99, "update": 98.142, "loss": "26.643", "ntokens": "2487.42", "nsentences": "49.92", "nll_loss": "0.535", "wps": "5908.2", "ups": "2.38", "wpb": "2487.4", "bsz": "49.9", "num_updates": "56800", "lr": "8.52489e-06", "gnorm": "95.835", "loss_scale": "32", "train_wall": "82.47", "gb_free": "20.7", "wall": "22696"}
[2023-07-04 16:12:25,682][train_inner][INFO] - {"epoch": 99, "update": 98.487, "loss": "26.784", "ntokens": "2497.07", "nsentences": "49.555", "nll_loss": "0.532", "wps": "5975.9", "ups": "2.39", "wpb": "2497.1", "bsz": "49.6", "num_updates": "57000", "lr": "8.39815e-06", "gnorm": "95.827", "loss_scale": "64", "train_wall": "82.79", "gb_free": "20.8", "wall": "22780"}
[2023-07-04 16:13:48,314][train_inner][INFO] - {"epoch": 99, "update": 98.832, "loss": "26.248", "ntokens": "2489.18", "nsentences": "49.335", "nll_loss": "0.52", "wps": "6025.5", "ups": "2.42", "wpb": "2489.2", "bsz": "49.3", "num_updates": "57200", "lr": "8.27329e-06", "gnorm": "95.863", "loss_scale": "64", "train_wall": "81.89", "gb_free": "20.7", "wall": "22863"}
[2023-07-04 16:14:27,979][fairseq_cli.train][INFO] - end of epoch 99 (average epoch stats below)
[2023-07-04 16:14:27,989][train][INFO] - {"epoch": 99, "train_loss": "26.592", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.526", "train_wps": "5972.1", "train_ups": "2.4", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "57297", "train_lr": "8.21341e-06", "train_gnorm": "96.014", "train_loss_scale": "64", "train_train_wall": "238.56", "train_gb_free": "20.8", "train_wall": "22902"}
[2023-07-04 16:14:28,006][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 16:14:28,011][fairseq.trainer][INFO] - begin training epoch 100
[2023-07-04 16:14:28,012][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 16:15:10,045][train_inner][INFO] - {"epoch": 100, "update": 99.178, "loss": "26.934", "ntokens": "2493.41", "nsentences": "48.905", "nll_loss": "0.528", "wps": "6102.2", "ups": "2.45", "wpb": "2493.4", "bsz": "48.9", "num_updates": "57400", "lr": "8.15029e-06", "gnorm": "97.296", "loss_scale": "64", "train_wall": "80.67", "gb_free": "20.7", "wall": "22944"}
[2023-07-04 16:16:32,062][train_inner][INFO] - {"epoch": 100, "update": 99.523, "loss": "26.528", "ntokens": "2492.07", "nsentences": "49.895", "nll_loss": "0.531", "wps": "6077.7", "ups": "2.44", "wpb": "2492.1", "bsz": "49.9", "num_updates": "57600", "lr": "8.02912e-06", "gnorm": "98.583", "loss_scale": "64", "train_wall": "81.27", "gb_free": "20.8", "wall": "23026"}
[2023-07-04 16:17:55,589][train_inner][INFO] - {"epoch": 100, "update": 99.869, "loss": "26.619", "ntokens": "2493.87", "nsentences": "49.175", "nll_loss": "0.525", "wps": "5971.9", "ups": "2.39", "wpb": "2493.9", "bsz": "49.2", "num_updates": "57800", "lr": "7.90975e-06", "gnorm": "96.566", "loss_scale": "64", "train_wall": "82.77", "gb_free": "20.8", "wall": "23110"}
[2023-07-04 16:18:25,768][fairseq_cli.train][INFO] - begin validation on "dev_other" subset
[2023-07-04 16:18:40,359][dev_other][INFO] - {"epoch": 100, "dev_other_loss": "42.675", "dev_other_ntokens": "272.352", "dev_other_nsentences": "10.6074", "dev_other_nll_loss": "1.662", "dev_other_uer": "22.776", "dev_other_wer": "23.248", "dev_other_raw_wer": "23.248", "dev_other_wps": "5256.8", "dev_other_wpb": "272.4", "dev_other_bsz": "10.6", "dev_other_num_updates": "57876", "dev_other_best_wer": "23.23"}
[2023-07-04 16:18:40,361][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 100 @ 57876 updates
[2023-07-04 16:18:40,362][fairseq.trainer][INFO] - Saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_last.pt
[2023-07-04 16:18:45,178][fairseq.trainer][INFO] - Finished saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_last.pt
[2023-07-04 16:18:45,294][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_last.pt (epoch 100 @ 57876 updates, score 23.248) (writing took 4.933097390457988 seconds)
[2023-07-04 16:18:45,295][fairseq_cli.train][INFO] - end of epoch 100 (average epoch stats below)
[2023-07-04 16:18:45,305][train][INFO] - {"epoch": 100, "train_loss": "26.813", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.53", "train_wps": "5611", "train_ups": "2.25", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "57876", "train_lr": "7.86486e-06", "train_gnorm": "98.073", "train_loss_scale": "64", "train_train_wall": "235.32", "train_gb_free": "20.8", "train_wall": "23160"}
[2023-07-04 16:18:45,321][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 16:18:45,326][fairseq.trainer][INFO] - begin training epoch 101
[2023-07-04 16:18:45,326][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 16:19:36,199][train_inner][INFO] - {"epoch": 101, "update": 100.214, "loss": "27.418", "ntokens": "2503.66", "nsentences": "48.76", "nll_loss": "0.534", "wps": "4977.5", "ups": "1.99", "wpb": "2503.7", "bsz": "48.8", "num_updates": "58000", "lr": "7.79216e-06", "gnorm": "97.639", "loss_scale": "64", "train_wall": "80.01", "gb_free": "20.7", "wall": "23210"}
[2023-07-04 16:20:56,571][train_inner][INFO] - {"epoch": 101, "update": 100.56, "loss": "25.77", "ntokens": "2486.38", "nsentences": "49.85", "nll_loss": "0.517", "wps": "6187.9", "ups": "2.49", "wpb": "2486.4", "bsz": "49.9", "num_updates": "58200", "lr": "7.67631e-06", "gnorm": "96.052", "loss_scale": "64", "train_wall": "79.65", "gb_free": "20.9", "wall": "23291"}
[2023-07-04 16:22:18,942][train_inner][INFO] - {"epoch": 101, "update": 100.905, "loss": "26.329", "ntokens": "2491.62", "nsentences": "48.895", "nll_loss": "0.517", "wps": "6050.5", "ups": "2.43", "wpb": "2491.6", "bsz": "48.9", "num_updates": "58400", "lr": "7.56219e-06", "gnorm": "99.851", "loss_scale": "64", "train_wall": "81.61", "gb_free": "20.8", "wall": "23373"}
[2023-07-04 16:22:41,582][fairseq_cli.train][INFO] - end of epoch 101 (average epoch stats below)
[2023-07-04 16:22:41,592][train][INFO] - {"epoch": 101, "train_loss": "26.507", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.524", "train_wps": "6110.4", "train_ups": "2.45", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "58455", "train_lr": "7.5311e-06", "train_gnorm": "97.882", "train_loss_scale": "64", "train_train_wall": "233.79", "train_gb_free": "20.9", "train_wall": "23396"}
[2023-07-04 16:22:41,617][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 16:22:41,623][fairseq.trainer][INFO] - begin training epoch 102
[2023-07-04 16:22:41,623][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 16:23:41,801][train_inner][INFO] - {"epoch": 102, "update": 101.25, "loss": "26.376", "ntokens": "2490.96", "nsentences": "49.71", "nll_loss": "0.526", "wps": "6013.3", "ups": "2.41", "wpb": "2491", "bsz": "49.7", "num_updates": "58600", "lr": "7.44976e-06", "gnorm": "97.425", "loss_scale": "64", "train_wall": "81.72", "gb_free": "20.7", "wall": "23456"}
[2023-07-04 16:25:05,349][train_inner][INFO] - {"epoch": 102, "update": 101.596, "loss": "26.343", "ntokens": "2499.07", "nsentences": "49.79", "nll_loss": "0.525", "wps": "5983.1", "ups": "2.39", "wpb": "2499.1", "bsz": "49.8", "num_updates": "58800", "lr": "7.339e-06", "gnorm": "97.09", "loss_scale": "64", "train_wall": "82.7", "gb_free": "20.8", "wall": "23540"}
[2023-07-04 16:26:27,245][train_inner][INFO] - {"epoch": 102, "update": 101.941, "loss": "25.623", "ntokens": "2493.03", "nsentences": "48.41", "nll_loss": "0.498", "wps": "6089", "ups": "2.44", "wpb": "2493", "bsz": "48.4", "num_updates": "59000", "lr": "7.2299e-06", "gnorm": "97.474", "loss_scale": "128", "train_wall": "81.16", "gb_free": "20.8", "wall": "23622"}
[2023-07-04 16:26:41,286][fairseq_cli.train][INFO] - end of epoch 102 (average epoch stats below)
[2023-07-04 16:26:41,297][train][INFO] - {"epoch": 102, "train_loss": "25.942", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.513", "train_wps": "6023.3", "train_ups": "2.42", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "59034", "train_lr": "7.21151e-06", "train_gnorm": "96.894", "train_loss_scale": "128", "train_train_wall": "237.06", "train_gb_free": "20.8", "train_wall": "23636"}
[2023-07-04 16:26:41,317][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 16:26:41,323][fairseq.trainer][INFO] - begin training epoch 103
[2023-07-04 16:26:41,323][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 16:27:56,824][train_inner][INFO] - {"epoch": 103, "update": 102.287, "loss": "26.127", "ntokens": "2496.36", "nsentences": "49.48", "nll_loss": "0.518", "wps": "5582.4", "ups": "2.24", "wpb": "2496.4", "bsz": "49.5", "num_updates": "59200", "lr": "7.12241e-06", "gnorm": "94.436", "loss_scale": "128", "train_wall": "88.18", "gb_free": "20.8", "wall": "23711"}
[2023-07-04 16:29:08,738][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2023-07-04 16:29:27,605][train_inner][INFO] - {"epoch": 103, "update": 102.634, "loss": "25.82", "ntokens": "2492.22", "nsentences": "49.27", "nll_loss": "0.51", "wps": "5492", "ups": "2.2", "wpb": "2492.2", "bsz": "49.3", "num_updates": "59400", "lr": "7.01652e-06", "gnorm": "95.388", "loss_scale": "64", "train_wall": "89.91", "gb_free": "20.7", "wall": "23802"}
[2023-07-04 16:31:19,806][train_inner][INFO] - {"epoch": 103, "update": 102.979, "loss": "26.034", "ntokens": "2494.51", "nsentences": "49.23", "nll_loss": "0.514", "wps": "4447.1", "ups": "1.78", "wpb": "2494.5", "bsz": "49.2", "num_updates": "59600", "lr": "6.9122e-06", "gnorm": "95.878", "loss_scale": "64", "train_wall": "111.06", "gb_free": "20.8", "wall": "23914"}
[2023-07-04 16:31:24,460][fairseq_cli.train][INFO] - end of epoch 103 (average epoch stats below)
[2023-07-04 16:31:24,470][train][INFO] - {"epoch": 103, "train_loss": "25.935", "train_ntokens": "2493.53", "train_nsentences": "49.2993", "train_nll_loss": "0.513", "train_wps": "5089.9", "train_ups": "2.04", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "59612", "train_lr": "6.90599e-06", "train_gnorm": "95.128", "train_loss_scale": "64", "train_train_wall": "279.86", "train_gb_free": "20.8", "train_wall": "23919"}
[2023-07-04 16:31:24,536][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 16:31:24,578][fairseq.trainer][INFO] - begin training epoch 104
[2023-07-04 16:31:24,579][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 16:32:47,555][train_inner][INFO] - {"epoch": 104, "update": 103.325, "loss": "25.806", "ntokens": "2480.27", "nsentences": "48.975", "nll_loss": "0.51", "wps": "5653.9", "ups": "2.28", "wpb": "2480.3", "bsz": "49", "num_updates": "59800", "lr": "6.80944e-06", "gnorm": "95.771", "loss_scale": "64", "train_wall": "86.27", "gb_free": "20.8", "wall": "24002"}
[2023-07-04 16:33:30,986][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
[2023-07-04 16:34:15,878][train_inner][INFO] - {"epoch": 104, "update": 103.672, "loss": "25.799", "ntokens": "2506.47", "nsentences": "49.755", "nll_loss": "0.512", "wps": "5676.5", "ups": "2.26", "wpb": "2506.5", "bsz": "49.8", "num_updates": "60000", "lr": "6.7082e-06", "gnorm": "97.854", "loss_scale": "32", "train_wall": "87.34", "gb_free": "20.8", "wall": "24090"}
[2023-07-04 16:35:42,397][fairseq_cli.train][INFO] - end of epoch 104 (average epoch stats below)
[2023-07-04 16:35:42,413][train][INFO] - {"epoch": 104, "train_loss": "25.797", "train_ntokens": "2493.58", "train_nsentences": "49.3028", "train_nll_loss": "0.51", "train_wps": "5587.9", "train_ups": "2.24", "train_wpb": "2493.6", "train_bsz": "49.3", "train_num_updates": "60190", "train_lr": "6.61342e-06", "train_gnorm": "97.596", "train_loss_scale": "32", "train_train_wall": "254.67", "train_gb_free": "20.7", "train_wall": "24177"}
[2023-07-04 16:35:42,501][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 16:35:42,515][fairseq.trainer][INFO] - begin training epoch 105
[2023-07-04 16:35:42,515][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 16:35:47,285][train_inner][INFO] - {"epoch": 105, "update": 104.017, "loss": "26.132", "ntokens": "2493.66", "nsentences": "48.975", "nll_loss": "0.513", "wps": "5456.9", "ups": "2.19", "wpb": "2493.7", "bsz": "49", "num_updates": "60200", "lr": "6.60847e-06", "gnorm": "100.195", "loss_scale": "32", "train_wall": "89.78", "gb_free": "20.8", "wall": "24182"}
[2023-07-04 16:37:12,168][train_inner][INFO] - {"epoch": 105, "update": 104.363, "loss": "25.595", "ntokens": "2495.36", "nsentences": "50.6", "nll_loss": "0.519", "wps": "5880.5", "ups": "2.36", "wpb": "2495.4", "bsz": "50.6", "num_updates": "60400", "lr": "6.51022e-06", "gnorm": "94.504", "loss_scale": "32", "train_wall": "84.08", "gb_free": "20.8", "wall": "24266"}
[2023-07-04 16:38:34,133][train_inner][INFO] - {"epoch": 105, "update": 104.708, "loss": "26.541", "ntokens": "2490.18", "nsentences": "48.365", "nll_loss": "0.515", "wps": "6079.2", "ups": "2.44", "wpb": "2490.2", "bsz": "48.4", "num_updates": "60600", "lr": "6.41344e-06", "gnorm": "97.254", "loss_scale": "32", "train_wall": "81.15", "gb_free": "20.8", "wall": "24348"}
[2023-07-04 16:39:47,284][fairseq_cli.train][INFO] - begin validation on "dev_other" subset
[2023-07-04 16:40:03,996][dev_other][INFO] - {"epoch": 105, "dev_other_loss": "43.036", "dev_other_ntokens": "272.352", "dev_other_nsentences": "10.6074", "dev_other_nll_loss": "1.676", "dev_other_uer": "22.767", "dev_other_wer": "23.287", "dev_other_raw_wer": "23.287", "dev_other_wps": "4822.4", "dev_other_wpb": "272.4", "dev_other_bsz": "10.6", "dev_other_num_updates": "60769", "dev_other_best_wer": "23.23"}
[2023-07-04 16:40:04,017][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 105 @ 60769 updates
[2023-07-04 16:40:04,018][fairseq.trainer][INFO] - Saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_last.pt
[2023-07-04 16:40:08,140][fairseq.trainer][INFO] - Finished saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_last.pt
[2023-07-04 16:40:08,282][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_last.pt (epoch 105 @ 60769 updates, score 23.287) (writing took 4.265452215448022 seconds)
[2023-07-04 16:40:08,283][fairseq_cli.train][INFO] - end of epoch 105 (average epoch stats below)
[2023-07-04 16:40:08,294][train][INFO] - {"epoch": 105, "train_loss": "26.175", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.517", "train_wps": "5430.3", "train_ups": "2.18", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "60769", "train_lr": "6.33277e-06", "train_gnorm": "96.558", "train_loss_scale": "32", "train_train_wall": "240.95", "train_gb_free": "20.8", "train_wall": "24443"}
[2023-07-04 16:40:08,372][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 16:40:08,378][fairseq.trainer][INFO] - begin training epoch 106
[2023-07-04 16:40:08,378][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 16:40:23,368][train_inner][INFO] - {"epoch": 106, "update": 105.054, "loss": "25.929", "ntokens": "2492.43", "nsentences": "49.1", "nll_loss": "0.511", "wps": "4564.2", "ups": "1.83", "wpb": "2492.4", "bsz": "49.1", "num_updates": "60800", "lr": "6.31809e-06", "gnorm": "96.041", "loss_scale": "32", "train_wall": "86.07", "gb_free": "20.9", "wall": "24458"}
[2023-07-04 16:41:53,871][train_inner][INFO] - {"epoch": 106, "update": 105.399, "loss": "26.38", "ntokens": "2503.56", "nsentences": "48.415", "nll_loss": "0.51", "wps": "5533.4", "ups": "2.21", "wpb": "2503.6", "bsz": "48.4", "num_updates": "61000", "lr": "6.22416e-06", "gnorm": "100.716", "loss_scale": "32", "train_wall": "87.37", "gb_free": "20.8", "wall": "24548"}
[2023-07-04 16:43:17,788][train_inner][INFO] - {"epoch": 106, "update": 105.744, "loss": "25.403", "ntokens": "2492.26", "nsentences": "49.53", "nll_loss": "0.505", "wps": "5940.7", "ups": "2.38", "wpb": "2492.3", "bsz": "49.5", "num_updates": "61200", "lr": "6.13162e-06", "gnorm": "94.422", "loss_scale": "32", "train_wall": "82.7", "gb_free": "20.8", "wall": "24632"}
[2023-07-04 16:44:22,470][fairseq_cli.train][INFO] - end of epoch 106 (average epoch stats below)
[2023-07-04 16:44:22,482][train][INFO] - {"epoch": 106, "train_loss": "25.694", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.508", "train_wps": "5680.1", "train_ups": "2.28", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "61348", "train_lr": "6.06403e-06", "train_gnorm": "96.311", "train_loss_scale": "32", "train_train_wall": "245.41", "train_gb_free": "20.8", "train_wall": "24697"}
[2023-07-04 16:44:22,509][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 16:44:22,520][fairseq.trainer][INFO] - begin training epoch 107
[2023-07-04 16:44:22,521][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 16:44:45,104][train_inner][INFO] - {"epoch": 107, "update": 106.09, "loss": "25.216", "ntokens": "2486.41", "nsentences": "50.105", "nll_loss": "0.508", "wps": "5741.2", "ups": "2.31", "wpb": "2486.4", "bsz": "50.1", "num_updates": "61400", "lr": "6.04046e-06", "gnorm": "94.015", "loss_scale": "32", "train_wall": "82.26", "gb_free": "20.7", "wall": "24719"}
[2023-07-04 16:46:12,222][train_inner][INFO] - {"epoch": 107, "update": 106.435, "loss": "25.506", "ntokens": "2501.57", "nsentences": "48.96", "nll_loss": "0.499", "wps": "5743.6", "ups": "2.3", "wpb": "2501.6", "bsz": "49", "num_updates": "61600", "lr": "5.95066e-06", "gnorm": "97.116", "loss_scale": "32", "train_wall": "83.03", "gb_free": "20.8", "wall": "24806"}
[2023-07-04 16:47:39,024][train_inner][INFO] - {"epoch": 107, "update": 106.781, "loss": "25.626", "ntokens": "2484.95", "nsentences": "48.97", "nll_loss": "0.505", "wps": "5726.2", "ups": "2.3", "wpb": "2485", "bsz": "49", "num_updates": "61800", "lr": "5.86219e-06", "gnorm": "95.689", "loss_scale": "32", "train_wall": "84.36", "gb_free": "20.9", "wall": "24893"}
[2023-07-04 16:48:34,124][fairseq_cli.train][INFO] - end of epoch 107 (average epoch stats below)
[2023-07-04 16:48:34,134][train][INFO] - {"epoch": 107, "train_loss": "25.608", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.506", "train_wps": "5737.3", "train_ups": "2.3", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "61927", "train_lr": "5.8067e-06", "train_gnorm": "96.126", "train_loss_scale": "32", "train_train_wall": "242.8", "train_gb_free": "20.7", "train_wall": "24948"}
[2023-07-04 16:48:34,151][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 16:48:34,156][fairseq.trainer][INFO] - begin training epoch 108
[2023-07-04 16:48:34,156][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 16:49:07,555][train_inner][INFO] - {"epoch": 108, "update": 107.126, "loss": "25.865", "ntokens": "2495.73", "nsentences": "49.76", "nll_loss": "0.516", "wps": "5638.8", "ups": "2.26", "wpb": "2495.7", "bsz": "49.8", "num_updates": "62000", "lr": "5.77504e-06", "gnorm": "96.346", "loss_scale": "64", "train_wall": "86.2", "gb_free": "20.8", "wall": "24982"}
[2023-07-04 16:50:33,517][train_inner][INFO] - {"epoch": 108, "update": 107.472, "loss": "25.664", "ntokens": "2500.57", "nsentences": "49.13", "nll_loss": "0.504", "wps": "5818.6", "ups": "2.33", "wpb": "2500.6", "bsz": "49.1", "num_updates": "62200", "lr": "5.68918e-06", "gnorm": "97.418", "loss_scale": "64", "train_wall": "83.73", "gb_free": "20.9", "wall": "25068"}
[2023-07-04 16:52:00,584][train_inner][INFO] - {"epoch": 108, "update": 107.817, "loss": "25.786", "ntokens": "2492.28", "nsentences": "49.12", "nll_loss": "0.508", "wps": "5725.6", "ups": "2.3", "wpb": "2492.3", "bsz": "49.1", "num_updates": "62400", "lr": "5.6046e-06", "gnorm": "97.264", "loss_scale": "64", "train_wall": "83.87", "gb_free": "20.7", "wall": "25155"}
[2023-07-04 16:52:46,382][fairseq_cli.train][INFO] - end of epoch 108 (average epoch stats below)
[2023-07-04 16:52:46,392][train][INFO] - {"epoch": 108, "train_loss": "25.53", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.505", "train_wps": "5723.5", "train_ups": "2.3", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "62506", "train_lr": "5.56028e-06", "train_gnorm": "96.68", "train_loss_scale": "64", "train_train_wall": "243.51", "train_gb_free": "20.8", "train_wall": "25201"}
[2023-07-04 16:52:46,409][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 16:52:46,413][fairseq.trainer][INFO] - begin training epoch 109
[2023-07-04 16:52:46,414][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 16:53:26,769][train_inner][INFO] - {"epoch": 109, "update": 108.162, "loss": "25.202", "ntokens": "2486.43", "nsentences": "49.18", "nll_loss": "0.498", "wps": "5770.6", "ups": "2.32", "wpb": "2486.4", "bsz": "49.2", "num_updates": "62600", "lr": "5.52127e-06", "gnorm": "95.382", "loss_scale": "64", "train_wall": "83.17", "gb_free": "20.8", "wall": "25241"}
[2023-07-04 16:54:52,485][train_inner][INFO] - {"epoch": 109, "update": 108.508, "loss": "25.14", "ntokens": "2503.33", "nsentences": "49.01", "nll_loss": "0.492", "wps": "5841.7", "ups": "2.33", "wpb": "2503.3", "bsz": "49", "num_updates": "62800", "lr": "5.43919e-06", "gnorm": "94.73", "loss_scale": "64", "train_wall": "82.79", "gb_free": "20.7", "wall": "25327"}
[2023-07-04 16:56:19,314][train_inner][INFO] - {"epoch": 109, "update": 108.853, "loss": "25.387", "ntokens": "2482.28", "nsentences": "50.1", "nll_loss": "0.512", "wps": "5718.1", "ups": "2.3", "wpb": "2482.3", "bsz": "50.1", "num_updates": "63000", "lr": "5.35832e-06", "gnorm": "94.122", "loss_scale": "64", "train_wall": "83.13", "gb_free": "20.8", "wall": "25414"}
[2023-07-04 16:56:55,491][fairseq_cli.train][INFO] - end of epoch 109 (average epoch stats below)
[2023-07-04 16:56:55,500][train][INFO] - {"epoch": 109, "train_loss": "25.31", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.5", "train_wps": "5795.9", "train_ups": "2.32", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "63085", "train_lr": "5.32432e-06", "train_gnorm": "95.189", "train_loss_scale": "64", "train_train_wall": "240.18", "train_gb_free": "20.7", "train_wall": "25450"}
[2023-07-04 16:56:55,516][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 16:56:55,520][fairseq.trainer][INFO] - begin training epoch 110
[2023-07-04 16:56:55,520][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 16:57:45,173][train_inner][INFO] - {"epoch": 110, "update": 109.199, "loss": "25.469", "ntokens": "2500.49", "nsentences": "49.235", "nll_loss": "0.501", "wps": "5825.4", "ups": "2.33", "wpb": "2500.5", "bsz": "49.2", "num_updates": "63200", "lr": "5.27866e-06", "gnorm": "96.107", "loss_scale": "64", "train_wall": "82.65", "gb_free": "20.8", "wall": "25499"}
[2023-07-04 16:59:10,958][train_inner][INFO] - {"epoch": 110, "update": 109.544, "loss": "24.698", "ntokens": "2489.47", "nsentences": "49.165", "nll_loss": "0.488", "wps": "5804.6", "ups": "2.33", "wpb": "2489.5", "bsz": "49.2", "num_updates": "63400", "lr": "5.20018e-06", "gnorm": "93.187", "loss_scale": "64", "train_wall": "83.81", "gb_free": "20.8", "wall": "25585"}
[2023-07-04 17:00:34,973][train_inner][INFO] - {"epoch": 110, "update": 109.889, "loss": "25.609", "ntokens": "2491.51", "nsentences": "49.15", "nll_loss": "0.505", "wps": "5931.8", "ups": "2.38", "wpb": "2491.5", "bsz": "49.1", "num_updates": "63600", "lr": "5.12287e-06", "gnorm": "96.146", "loss_scale": "64", "train_wall": "82.49", "gb_free": "20.8", "wall": "25669"}
[2023-07-04 17:01:03,258][fairseq_cli.train][INFO] - begin validation on "dev_other" subset
[2023-07-04 17:01:19,539][dev_other][INFO] - {"epoch": 110, "dev_other_loss": "42.789", "dev_other_ntokens": "272.352", "dev_other_nsentences": "10.6074", "dev_other_nll_loss": "1.667", "dev_other_uer": "22.637", "dev_other_wer": "23.093", "dev_other_raw_wer": "23.093", "dev_other_wps": "4905.7", "dev_other_wpb": "272.4", "dev_other_bsz": "10.6", "dev_other_num_updates": "63664", "dev_other_best_wer": "23.093"}
[2023-07-04 17:01:19,548][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 110 @ 63664 updates
[2023-07-04 17:01:19,549][fairseq.trainer][INFO] - Saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt
[2023-07-04 17:01:23,114][fairseq.trainer][INFO] - Finished saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt
[2023-07-04 17:01:26,180][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt (epoch 110 @ 63664 updates, score 23.093) (writing took 6.631246527656913 seconds)
[2023-07-04 17:01:26,180][fairseq_cli.train][INFO] - end of epoch 110 (average epoch stats below)
[2023-07-04 17:01:26,190][train][INFO] - {"epoch": 110, "train_loss": "25.24", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.499", "train_wps": "5333.8", "train_ups": "2.14", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "63664", "train_lr": "5.09838e-06", "train_gnorm": "94.826", "train_loss_scale": "64", "train_train_wall": "241.31", "train_gb_free": "20.7", "train_wall": "25720"}
[2023-07-04 17:01:26,213][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 17:01:26,221][fairseq.trainer][INFO] - begin training epoch 111
[2023-07-04 17:01:26,222][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 17:02:26,386][train_inner][INFO] - {"epoch": 111, "update": 110.235, "loss": "24.936", "ntokens": "2497.5", "nsentences": "49.595", "nll_loss": "0.495", "wps": "4483.6", "ups": "1.8", "wpb": "2497.5", "bsz": "49.6", "num_updates": "63800", "lr": "5.04671e-06", "gnorm": "95.594", "loss_scale": "64", "train_wall": "84.15", "gb_free": "20.8", "wall": "25781"}
[2023-07-04 17:03:53,813][train_inner][INFO] - {"epoch": 111, "update": 110.58, "loss": "25.316", "ntokens": "2490.11", "nsentences": "49.62", "nll_loss": "0.504", "wps": "5697.1", "ups": "2.29", "wpb": "2490.1", "bsz": "49.6", "num_updates": "64000", "lr": "4.97168e-06", "gnorm": "95.417", "loss_scale": "128", "train_wall": "82.7", "gb_free": "20.7", "wall": "25868"}
[2023-07-04 17:05:20,242][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2023-07-04 17:05:25,112][train_inner][INFO] - {"epoch": 111, "update": 110.927, "loss": "24.993", "ntokens": "2494.67", "nsentences": "48.905", "nll_loss": "0.49", "wps": "5465.5", "ups": "2.19", "wpb": "2494.7", "bsz": "48.9", "num_updates": "64200", "lr": "4.89777e-06", "gnorm": "95.106", "loss_scale": "64", "train_wall": "84.38", "gb_free": "20.8", "wall": "25959"}
[2023-07-04 17:05:44,193][fairseq_cli.train][INFO] - end of epoch 111 (average epoch stats below)
[2023-07-04 17:05:44,203][train][INFO] - {"epoch": 111, "train_loss": "25.178", "train_ntokens": "2493.68", "train_nsentences": "49.2941", "train_nll_loss": "0.498", "train_wps": "5586.6", "train_ups": "2.24", "train_wpb": "2493.7", "train_bsz": "49.3", "train_num_updates": "64242", "train_lr": "4.88239e-06", "train_gnorm": "95.447", "train_loss_scale": "64", "train_train_wall": "241.84", "train_gb_free": "20.8", "train_wall": "25978"}
[2023-07-04 17:05:44,222][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 17:05:44,227][fairseq.trainer][INFO] - begin training epoch 112
[2023-07-04 17:05:44,227][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 17:06:55,638][train_inner][INFO] - {"epoch": 112, "update": 111.273, "loss": "24.873", "ntokens": "2490.93", "nsentences": "48.835", "nll_loss": "0.488", "wps": "5503.9", "ups": "2.21", "wpb": "2490.9", "bsz": "48.8", "num_updates": "64400", "lr": "4.82495e-06", "gnorm": "93.287", "loss_scale": "64", "train_wall": "84.24", "gb_free": "20.7", "wall": "26050"}
[2023-07-04 17:08:19,096][train_inner][INFO] - {"epoch": 112, "update": 111.618, "loss": "25.87", "ntokens": "2495.2", "nsentences": "49.705", "nll_loss": "0.515", "wps": "5980.3", "ups": "2.4", "wpb": "2495.2", "bsz": "49.7", "num_updates": "64600", "lr": "4.75322e-06", "gnorm": "96.326", "loss_scale": "64", "train_wall": "82.66", "gb_free": "20.8", "wall": "26133"}
[2023-07-04 17:09:42,355][train_inner][INFO] - {"epoch": 112, "update": 111.964, "loss": "25.167", "ntokens": "2492.86", "nsentences": "49.355", "nll_loss": "0.498", "wps": "5988.8", "ups": "2.4", "wpb": "2492.9", "bsz": "49.4", "num_updates": "64800", "lr": "4.68255e-06", "gnorm": "95.87", "loss_scale": "64", "train_wall": "82.49", "gb_free": "20.9", "wall": "26217"}
[2023-07-04 17:09:50,796][fairseq_cli.train][INFO] - end of epoch 112 (average epoch stats below)
[2023-07-04 17:09:50,806][train][INFO] - {"epoch": 112, "train_loss": "25.266", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.499", "train_wps": "5854.8", "train_ups": "2.35", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "64821", "train_lr": "4.67519e-06", "train_gnorm": "95.17", "train_loss_scale": "64", "train_train_wall": "239.94", "train_gb_free": "20.8", "train_wall": "26225"}
[2023-07-04 17:09:50,825][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 17:09:50,830][fairseq.trainer][INFO] - begin training epoch 113
[2023-07-04 17:09:50,830][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 17:11:06,377][train_inner][INFO] - {"epoch": 113, "update": 112.309, "loss": "24.757", "ntokens": "2489.97", "nsentences": "48.495", "nll_loss": "0.482", "wps": "5928", "ups": "2.38", "wpb": "2490", "bsz": "48.5", "num_updates": "65000", "lr": "4.61294e-06", "gnorm": "95.024", "loss_scale": "64", "train_wall": "82.92", "gb_free": "20.8", "wall": "26301"}
[2023-07-04 17:12:30,777][train_inner][INFO] - {"epoch": 113, "update": 112.655, "loss": "25.398", "ntokens": "2496.74", "nsentences": "49.635", "nll_loss": "0.505", "wps": "5917.1", "ups": "2.37", "wpb": "2496.7", "bsz": "49.6", "num_updates": "65200", "lr": "4.54436e-06", "gnorm": "95.926", "loss_scale": "64", "train_wall": "83.61", "gb_free": "20.7", "wall": "26385"}
[2023-07-04 17:13:53,540][train_inner][INFO] - {"epoch": 113, "update": 113.0, "loss": "25.082", "ntokens": "2494.08", "nsentences": "49.63", "nll_loss": "0.499", "wps": "6027.8", "ups": "2.42", "wpb": "2494.1", "bsz": "49.6", "num_updates": "65400", "lr": "4.47679e-06", "gnorm": "94.171", "loss_scale": "64", "train_wall": "82.02", "gb_free": "20.8", "wall": "26468"}
[2023-07-04 17:13:53,542][fairseq_cli.train][INFO] - end of epoch 113 (average epoch stats below)
[2023-07-04 17:13:53,551][train][INFO] - {"epoch": 113, "train_loss": "25.082", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.496", "train_wps": "5947.8", "train_ups": "2.39", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "65400", "train_lr": "4.47679e-06", "train_gnorm": "95.041", "train_loss_scale": "64", "train_train_wall": "240.2", "train_gb_free": "20.8", "train_wall": "26468"}
[2023-07-04 17:13:53,568][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 17:13:53,573][fairseq.trainer][INFO] - begin training epoch 114
[2023-07-04 17:13:53,573][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 17:15:17,627][train_inner][INFO] - {"epoch": 114, "update": 113.345, "loss": "25.043", "ntokens": "2493.68", "nsentences": "49.56", "nll_loss": "0.498", "wps": "5932.1", "ups": "2.38", "wpb": "2493.7", "bsz": "49.6", "num_updates": "65600", "lr": "4.41024e-06", "gnorm": "94.469", "loss_scale": "64", "train_wall": "81.5", "gb_free": "20.9", "wall": "26552"}
[2023-07-04 17:15:37,302][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
[2023-07-04 17:16:40,997][train_inner][INFO] - {"epoch": 114, "update": 113.693, "loss": "25.352", "ntokens": "2497.08", "nsentences": "48.885", "nll_loss": "0.496", "wps": "5990.9", "ups": "2.4", "wpb": "2497.1", "bsz": "48.9", "num_updates": "65800", "lr": "4.34467e-06", "gnorm": "98.123", "loss_scale": "32", "train_wall": "82.4", "gb_free": "20.8", "wall": "26635"}
[2023-07-04 17:17:54,992][fairseq_cli.train][INFO] - end of epoch 114 (average epoch stats below)
[2023-07-04 17:17:55,001][train][INFO] - {"epoch": 114, "train_loss": "25.173", "train_ntokens": "2493.61", "train_nsentences": "49.2439", "train_nll_loss": "0.497", "train_wps": "5969.6", "train_ups": "2.39", "train_wpb": "2493.6", "train_bsz": "49.2", "train_num_updates": "65978", "train_lr": "4.28714e-06", "train_gnorm": "95.659", "train_loss_scale": "32", "train_train_wall": "236.6", "train_gb_free": "20.8", "train_wall": "26709"}
[2023-07-04 17:17:55,015][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 17:17:55,020][fairseq.trainer][INFO] - begin training epoch 115
[2023-07-04 17:17:55,020][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 17:18:04,501][train_inner][INFO] - {"epoch": 115, "update": 114.038, "loss": "24.892", "ntokens": "2489.88", "nsentences": "49.415", "nll_loss": "0.494", "wps": "5964.3", "ups": "2.4", "wpb": "2489.9", "bsz": "49.4", "num_updates": "66000", "lr": "4.28008e-06", "gnorm": "93.923", "loss_scale": "32", "train_wall": "81.81", "gb_free": "20.7", "wall": "26719"}
[2023-07-04 17:19:30,818][train_inner][INFO] - {"epoch": 115, "update": 114.383, "loss": "24.795", "ntokens": "2494.57", "nsentences": "49.37", "nll_loss": "0.491", "wps": "5780.6", "ups": "2.32", "wpb": "2494.6", "bsz": "49.4", "num_updates": "66200", "lr": "4.21645e-06", "gnorm": "96.591", "loss_scale": "32", "train_wall": "84.95", "gb_free": "20.7", "wall": "26805"}
[2023-07-04 17:20:57,096][train_inner][INFO] - {"epoch": 115, "update": 114.729, "loss": "25.065", "ntokens": "2501.44", "nsentences": "49.345", "nll_loss": "0.494", "wps": "5799.3", "ups": "2.32", "wpb": "2501.4", "bsz": "49.3", "num_updates": "66400", "lr": "4.15376e-06", "gnorm": "96.104", "loss_scale": "32", "train_wall": "83.94", "gb_free": "20.7", "wall": "26891"}
[2023-07-04 17:22:07,007][fairseq_cli.train][INFO] - begin validation on "dev_other" subset
[2023-07-04 17:22:22,056][dev_other][INFO] - {"epoch": 115, "dev_other_loss": "42.869", "dev_other_ntokens": "272.352", "dev_other_nsentences": "10.6074", "dev_other_nll_loss": "1.67", "dev_other_uer": "22.645", "dev_other_wer": "23.1", "dev_other_raw_wer": "23.1", "dev_other_wps": "4991", "dev_other_wpb": "272.4", "dev_other_bsz": "10.6", "dev_other_num_updates": "66557", "dev_other_best_wer": "23.093"}
[2023-07-04 17:22:22,058][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 115 @ 66557 updates
[2023-07-04 17:22:22,059][fairseq.trainer][INFO] - Saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_last.pt
[2023-07-04 17:22:24,886][fairseq.trainer][INFO] - Finished saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_last.pt
[2023-07-04 17:22:24,952][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_last.pt (epoch 115 @ 66557 updates, score 23.1) (writing took 2.8940265364944935 seconds)
[2023-07-04 17:22:24,953][fairseq_cli.train][INFO] - end of epoch 115 (average epoch stats below)
[2023-07-04 17:22:24,962][train][INFO] - {"epoch": 115, "train_loss": "24.975", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.494", "train_wps": "5348.2", "train_ups": "2.14", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "66557", "train_lr": "4.10521e-06", "train_gnorm": "95.906", "train_loss_scale": "32", "train_train_wall": "243.65", "train_gb_free": "20.8", "train_wall": "26979"}
[2023-07-04 17:22:24,975][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 17:22:24,982][fairseq.trainer][INFO] - begin training epoch 116
[2023-07-04 17:22:24,982][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 17:22:44,405][train_inner][INFO] - {"epoch": 116, "update": 115.074, "loss": "24.828", "ntokens": "2483.57", "nsentences": "49.06", "nll_loss": "0.49", "wps": "4670.8", "ups": "1.88", "wpb": "2483.6", "bsz": "49.1", "num_updates": "66600", "lr": "4.09201e-06", "gnorm": "95.022", "loss_scale": "32", "train_wall": "82.96", "gb_free": "20.8", "wall": "26998"}
[2023-07-04 17:24:13,619][train_inner][INFO] - {"epoch": 116, "update": 115.42, "loss": "23.856", "ntokens": "2490.76", "nsentences": "49.815", "nll_loss": "0.477", "wps": "5584.5", "ups": "2.24", "wpb": "2490.8", "bsz": "49.8", "num_updates": "66800", "lr": "4.03117e-06", "gnorm": "93.07", "loss_scale": "32", "train_wall": "83.52", "gb_free": "20.8", "wall": "27088"}
[2023-07-04 17:25:41,552][train_inner][INFO] - {"epoch": 116, "update": 115.765, "loss": "25.054", "ntokens": "2493.88", "nsentences": "49.245", "nll_loss": "0.495", "wps": "5672.8", "ups": "2.27", "wpb": "2493.9", "bsz": "49.2", "num_updates": "67000", "lr": "3.97124e-06", "gnorm": "95.688", "loss_scale": "32", "train_wall": "83.24", "gb_free": "20.8", "wall": "27176"}
[2023-07-04 17:26:40,670][fairseq_cli.train][INFO] - end of epoch 116 (average epoch stats below)
[2023-07-04 17:26:40,680][train][INFO] - {"epoch": 116, "train_loss": "24.319", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.481", "train_wps": "5646.1", "train_ups": "2.26", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "67136", "train_lr": "3.931e-06", "train_gnorm": "95.188", "train_loss_scale": "32", "train_train_wall": "239.52", "train_gb_free": "20.8", "train_wall": "27235"}
[2023-07-04 17:26:40,698][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 17:26:40,704][fairseq.trainer][INFO] - begin training epoch 117
[2023-07-04 17:26:40,704][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 17:27:11,293][train_inner][INFO] - {"epoch": 117, "update": 116.111, "loss": "24.838", "ntokens": "2497.34", "nsentences": "48.685", "nll_loss": "0.484", "wps": "5566.3", "ups": "2.23", "wpb": "2497.3", "bsz": "48.7", "num_updates": "67200", "lr": "3.9122e-06", "gnorm": "98.16", "loss_scale": "32", "train_wall": "82.81", "gb_free": "20.8", "wall": "27266"}
[2023-07-04 17:28:38,993][train_inner][INFO] - {"epoch": 117, "update": 116.456, "loss": "25.095", "ntokens": "2487.6", "nsentences": "49.355", "nll_loss": "0.498", "wps": "5673.7", "ups": "2.28", "wpb": "2487.6", "bsz": "49.4", "num_updates": "67400", "lr": "3.85404e-06", "gnorm": "94.656", "loss_scale": "32", "train_wall": "84.06", "gb_free": "20.8", "wall": "27353"}
[2023-07-04 17:30:07,055][train_inner][INFO] - {"epoch": 117, "update": 116.801, "loss": "25.133", "ntokens": "2501.89", "nsentences": "49.28", "nll_loss": "0.495", "wps": "5682.7", "ups": "2.27", "wpb": "2501.9", "bsz": "49.3", "num_updates": "67600", "lr": "3.79674e-06", "gnorm": "97.475", "loss_scale": "32", "train_wall": "82.43", "gb_free": "20.8", "wall": "27441"}
[2023-07-04 17:30:54,912][fairseq_cli.train][INFO] - end of epoch 117 (average epoch stats below)
[2023-07-04 17:30:54,922][train][INFO] - {"epoch": 117, "train_loss": "25.264", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.499", "train_wps": "5678.9", "train_ups": "2.28", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "67715", "train_lr": "3.76418e-06", "train_gnorm": "95.941", "train_loss_scale": "64", "train_train_wall": "239.64", "train_gb_free": "20.7", "train_wall": "27489"}
[2023-07-04 17:30:54,937][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 17:30:54,941][fairseq.trainer][INFO] - begin training epoch 118
[2023-07-04 17:30:54,941][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 17:31:33,300][train_inner][INFO] - {"epoch": 118, "update": 117.147, "loss": "25.507", "ntokens": "2497.21", "nsentences": "48.905", "nll_loss": "0.5", "wps": "5822.3", "ups": "2.33", "wpb": "2497.2", "bsz": "48.9", "num_updates": "67800", "lr": "3.74029e-06", "gnorm": "95.826", "loss_scale": "64", "train_wall": "80.59", "gb_free": "20.7", "wall": "27527"}
[2023-07-04 17:33:04,659][train_inner][INFO] - {"epoch": 118, "update": 117.492, "loss": "25.124", "ntokens": "2496.14", "nsentences": "49.665", "nll_loss": "0.5", "wps": "5498", "ups": "2.2", "wpb": "2496.1", "bsz": "49.7", "num_updates": "68000", "lr": "3.68468e-06", "gnorm": "94.022", "loss_scale": "64", "train_wall": "84.05", "gb_free": "20.7", "wall": "27618"}
[2023-07-04 17:34:33,476][train_inner][INFO] - {"epoch": 118, "update": 117.838, "loss": "23.992", "ntokens": "2491.74", "nsentences": "49.2", "nll_loss": "0.474", "wps": "5611.7", "ups": "2.25", "wpb": "2491.7", "bsz": "49.2", "num_updates": "68200", "lr": "3.6299e-06", "gnorm": "93.978", "loss_scale": "64", "train_wall": "84.32", "gb_free": "20.9", "wall": "27708"}
[2023-07-04 17:35:14,251][fairseq_cli.train][INFO] - end of epoch 118 (average epoch stats below)
[2023-07-04 17:35:14,261][train][INFO] - {"epoch": 118, "train_loss": "24.749", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.489", "train_wps": "5567.2", "train_ups": "2.23", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "68294", "train_lr": "3.60444e-06", "train_gnorm": "94.521", "train_loss_scale": "64", "train_train_wall": "241.88", "train_gb_free": "20.8", "train_wall": "27749"}
[2023-07-04 17:35:14,282][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 17:35:14,287][fairseq.trainer][INFO] - begin training epoch 119
[2023-07-04 17:35:14,287][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 17:36:02,363][train_inner][INFO] - {"epoch": 119, "update": 118.183, "loss": "24.883", "ntokens": "2482.35", "nsentences": "49.505", "nll_loss": "0.496", "wps": "5586.1", "ups": "2.25", "wpb": "2482.3", "bsz": "49.5", "num_updates": "68400", "lr": "3.57594e-06", "gnorm": "94.489", "loss_scale": "64", "train_wall": "83.79", "gb_free": "20.8", "wall": "27797"}
[2023-07-04 17:37:31,078][train_inner][INFO] - {"epoch": 119, "update": 118.528, "loss": "24.543", "ntokens": "2498.93", "nsentences": "49.2", "nll_loss": "0.483", "wps": "5634.2", "ups": "2.25", "wpb": "2498.9", "bsz": "49.2", "num_updates": "68600", "lr": "3.52277e-06", "gnorm": "95.884", "loss_scale": "64", "train_wall": "83.98", "gb_free": "20.8", "wall": "27885"}
[2023-07-04 17:38:58,011][train_inner][INFO] - {"epoch": 119, "update": 118.874, "loss": "25.334", "ntokens": "2497.78", "nsentences": "49.36", "nll_loss": "0.501", "wps": "5747.2", "ups": "2.3", "wpb": "2497.8", "bsz": "49.4", "num_updates": "68800", "lr": "3.4704e-06", "gnorm": "96.399", "loss_scale": "64", "train_wall": "83.84", "gb_free": "20.8", "wall": "27972"}
[2023-07-04 17:39:29,712][fairseq_cli.train][INFO] - end of epoch 119 (average epoch stats below)
[2023-07-04 17:39:29,721][train][INFO] - {"epoch": 119, "train_loss": "24.978", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.494", "train_wps": "5651.8", "train_ups": "2.27", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "68873", "train_lr": "3.45148e-06", "train_gnorm": "95.816", "train_loss_scale": "64", "train_train_wall": "242.99", "train_gb_free": "20.9", "train_wall": "28004"}
[2023-07-04 17:39:29,737][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 17:39:29,742][fairseq.trainer][INFO] - begin training epoch 120
[2023-07-04 17:39:29,742][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 17:40:27,078][train_inner][INFO] - {"epoch": 120, "update": 119.219, "loss": "24.743", "ntokens": "2504.83", "nsentences": "49.075", "nll_loss": "0.485", "wps": "5625.3", "ups": "2.25", "wpb": "2504.8", "bsz": "49.1", "num_updates": "69000", "lr": "3.41881e-06", "gnorm": "94.857", "loss_scale": "64", "train_wall": "82.98", "gb_free": "20.7", "wall": "28061"}
[2023-07-04 17:41:58,894][train_inner][INFO] - {"epoch": 120, "update": 119.565, "loss": "25.049", "ntokens": "2487.8", "nsentences": "49.26", "nll_loss": "0.496", "wps": "5419.7", "ups": "2.18", "wpb": "2487.8", "bsz": "49.3", "num_updates": "69200", "lr": "3.36798e-06", "gnorm": "97.257", "loss_scale": "64", "train_wall": "83.34", "gb_free": "20.9", "wall": "28153"}
[2023-07-04 17:43:31,285][train_inner][INFO] - {"epoch": 120, "update": 119.91, "loss": "24.645", "ntokens": "2484.86", "nsentences": "49.56", "nll_loss": "0.492", "wps": "5379.5", "ups": "2.16", "wpb": "2484.9", "bsz": "49.6", "num_updates": "69400", "lr": "3.31791e-06", "gnorm": "93.623", "loss_scale": "64", "train_wall": "83.64", "gb_free": "20.7", "wall": "28246"}
[2023-07-04 17:43:54,133][fairseq_cli.train][INFO] - begin validation on "dev_other" subset
[2023-07-04 17:44:09,935][dev_other][INFO] - {"epoch": 120, "dev_other_loss": "43.037", "dev_other_ntokens": "272.352", "dev_other_nsentences": "10.6074", "dev_other_nll_loss": "1.676", "dev_other_uer": "22.616", "dev_other_wer": "23.11", "dev_other_raw_wer": "23.11", "dev_other_wps": "4900.8", "dev_other_wpb": "272.4", "dev_other_bsz": "10.6", "dev_other_num_updates": "69452", "dev_other_best_wer": "23.093"}
[2023-07-04 17:44:09,936][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 120 @ 69452 updates
[2023-07-04 17:44:09,937][fairseq.trainer][INFO] - Saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_last.pt
[2023-07-04 17:44:14,468][fairseq.trainer][INFO] - Finished saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_last.pt
[2023-07-04 17:44:14,582][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_last.pt (epoch 120 @ 69452 updates, score 23.11) (writing took 4.645846303552389 seconds)
[2023-07-04 17:44:14,583][fairseq_cli.train][INFO] - end of epoch 120 (average epoch stats below)
[2023-07-04 17:44:14,592][train][INFO] - {"epoch": 120, "train_loss": "24.792", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.49", "train_wps": "5068.3", "train_ups": "2.03", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "69452", "train_lr": "3.30501e-06", "train_gnorm": "95.36", "train_loss_scale": "64", "train_train_wall": "241", "train_gb_free": "20.7", "train_wall": "28289"}
[2023-07-04 17:44:14,608][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 17:44:14,613][fairseq.trainer][INFO] - begin training epoch 121
[2023-07-04 17:44:14,613][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 17:45:31,848][train_inner][INFO] - {"epoch": 121, "update": 120.256, "loss": "23.965", "ntokens": "2495.91", "nsentences": "50.53", "nll_loss": "0.485", "wps": "4140.7", "ups": "1.66", "wpb": "2495.9", "bsz": "50.5", "num_updates": "69600", "lr": "3.26858e-06", "gnorm": "93.392", "loss_scale": "64", "train_wall": "82.83", "gb_free": "20.8", "wall": "28366"}
[2023-07-04 17:47:05,023][train_inner][INFO] - {"epoch": 121, "update": 120.601, "loss": "24.779", "ntokens": "2494.93", "nsentences": "48.7", "nll_loss": "0.484", "wps": "5360.1", "ups": "2.15", "wpb": "2494.9", "bsz": "48.7", "num_updates": "69800", "lr": "3.21999e-06", "gnorm": "97.277", "loss_scale": "128", "train_wall": "84.67", "gb_free": "20.9", "wall": "28459"}
[2023-07-04 17:47:13,644][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2023-07-04 17:48:37,845][train_inner][INFO] - {"epoch": 121, "update": 120.948, "loss": "25.27", "ntokens": "2491.53", "nsentences": "48.68", "nll_loss": "0.494", "wps": "5368.9", "ups": "2.15", "wpb": "2491.5", "bsz": "48.7", "num_updates": "70000", "lr": "3.17211e-06", "gnorm": "97.432", "loss_scale": "64", "train_wall": "84.54", "gb_free": "20.8", "wall": "28552"}
[2023-07-04 17:48:50,316][fairseq_cli.train][INFO] - end of epoch 121 (average epoch stats below)
[2023-07-04 17:48:50,326][train][INFO] - {"epoch": 121, "train_loss": "24.636", "train_ntokens": "2493.43", "train_nsentences": "49.2958", "train_nll_loss": "0.487", "train_wps": "5227", "train_ups": "2.1", "train_wpb": "2493.4", "train_bsz": "49.3", "train_num_updates": "70030", "train_lr": "3.16499e-06", "train_gnorm": "95.917", "train_loss_scale": "64", "train_train_wall": "242.92", "train_gb_free": "20.7", "train_wall": "28565"}
[2023-07-04 17:48:50,346][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 17:48:50,350][fairseq.trainer][INFO] - begin training epoch 122
[2023-07-04 17:48:50,350][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 17:50:06,495][train_inner][INFO] - {"epoch": 122, "update": 121.294, "loss": "24.749", "ntokens": "2485.05", "nsentences": "49.24", "nll_loss": "0.49", "wps": "5610.1", "ups": "2.26", "wpb": "2485.1", "bsz": "49.2", "num_updates": "70200", "lr": "3.12495e-06", "gnorm": "98.335", "loss_scale": "64", "train_wall": "86.32", "gb_free": "20.8", "wall": "28641"}
[2023-07-04 17:51:30,557][train_inner][INFO] - {"epoch": 122, "update": 121.639, "loss": "25.047", "ntokens": "2500.7", "nsentences": "49.435", "nll_loss": "0.495", "wps": "5950.4", "ups": "2.38", "wpb": "2500.7", "bsz": "49.4", "num_updates": "70400", "lr": "3.0785e-06", "gnorm": "95.433", "loss_scale": "64", "train_wall": "81.76", "gb_free": "20.8", "wall": "28725"}
[2023-07-04 17:53:00,276][train_inner][INFO] - {"epoch": 122, "update": 121.984, "loss": "24.656", "ntokens": "2492.09", "nsentences": "49.2", "nll_loss": "0.487", "wps": "5555.8", "ups": "2.23", "wpb": "2492.1", "bsz": "49.2", "num_updates": "70600", "lr": "3.03273e-06", "gnorm": "94.253", "loss_scale": "64", "train_wall": "83.69", "gb_free": "20.7", "wall": "28815"}
[2023-07-04 17:53:03,786][fairseq_cli.train][INFO] - end of epoch 122 (average epoch stats below)
[2023-07-04 17:53:03,796][train][INFO] - {"epoch": 122, "train_loss": "24.743", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.489", "train_wps": "5696.2", "train_ups": "2.28", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "70609", "train_lr": "3.03068e-06", "train_gnorm": "96.039", "train_loss_scale": "64", "train_train_wall": "243.24", "train_gb_free": "20.8", "train_wall": "28818"}
[2023-07-04 17:53:03,970][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 17:53:04,017][fairseq.trainer][INFO] - begin training epoch 123
[2023-07-04 17:53:04,017][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 17:53:30,931][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
[2023-07-04 17:54:31,214][train_inner][INFO] - {"epoch": 123, "update": 122.332, "loss": "24.633", "ntokens": "2488.82", "nsentences": "48.74", "nll_loss": "0.482", "wps": "5474.5", "ups": "2.2", "wpb": "2488.8", "bsz": "48.7", "num_updates": "70800", "lr": "2.98764e-06", "gnorm": "95.166", "loss_scale": "32", "train_wall": "83.56", "gb_free": "20.8", "wall": "28905"}
[2023-07-04 17:55:58,605][train_inner][INFO] - {"epoch": 123, "update": 122.677, "loss": "24.838", "ntokens": "2488.59", "nsentences": "49.415", "nll_loss": "0.493", "wps": "5696.3", "ups": "2.29", "wpb": "2488.6", "bsz": "49.4", "num_updates": "71000", "lr": "2.94322e-06", "gnorm": "93.807", "loss_scale": "32", "train_wall": "82.95", "gb_free": "20.8", "wall": "28993"}
[2023-07-04 17:57:23,178][fairseq_cli.train][INFO] - end of epoch 123 (average epoch stats below)
[2023-07-04 17:57:23,212][train][INFO] - {"epoch": 123, "train_loss": "25.019", "train_ntokens": "2493.66", "train_nsentences": "49.2716", "train_nll_loss": "0.494", "train_wps": "5556.8", "train_ups": "2.23", "train_wpb": "2493.7", "train_bsz": "49.3", "train_num_updates": "71187", "train_lr": "2.90229e-06", "train_gnorm": "95.251", "train_loss_scale": "32", "train_train_wall": "244.03", "train_gb_free": "20.8", "train_wall": "29077"}
[2023-07-04 17:57:23,240][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 17:57:23,248][fairseq.trainer][INFO] - begin training epoch 124
[2023-07-04 17:57:23,249][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 17:57:28,657][train_inner][INFO] - {"epoch": 124, "update": 123.022, "loss": "25.545", "ntokens": "2501.13", "nsentences": "49.39", "nll_loss": "0.504", "wps": "5555.6", "ups": "2.22", "wpb": "2501.1", "bsz": "49.4", "num_updates": "71200", "lr": "2.89946e-06", "gnorm": "97.345", "loss_scale": "32", "train_wall": "86.07", "gb_free": "20.8", "wall": "29083"}
[2023-07-04 17:59:04,077][train_inner][INFO] - {"epoch": 124, "update": 123.368, "loss": "24.634", "ntokens": "2493.59", "nsentences": "49.395", "nll_loss": "0.488", "wps": "5228.2", "ups": "2.1", "wpb": "2493.6", "bsz": "49.4", "num_updates": "71400", "lr": "2.85636e-06", "gnorm": "94.911", "loss_scale": "32", "train_wall": "86.39", "gb_free": "20.7", "wall": "29178"}
[2023-07-04 18:00:40,119][train_inner][INFO] - {"epoch": 124, "update": 123.713, "loss": "24.232", "ntokens": "2499.94", "nsentences": "49.4", "nll_loss": "0.479", "wps": "5206.8", "ups": "2.08", "wpb": "2499.9", "bsz": "49.4", "num_updates": "71600", "lr": "2.81389e-06", "gnorm": "93.194", "loss_scale": "32", "train_wall": "88.85", "gb_free": "20.7", "wall": "29274"}
[2023-07-04 18:02:05,785][fairseq_cli.train][INFO] - end of epoch 124 (average epoch stats below)
[2023-07-04 18:02:05,802][train][INFO] - {"epoch": 124, "train_loss": "24.66", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.487", "train_wps": "5109.3", "train_ups": "2.05", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "71766", "train_lr": "2.77913e-06", "train_gnorm": "95.29", "train_loss_scale": "32", "train_train_wall": "256.97", "train_gb_free": "20.8", "train_wall": "29360"}
[2023-07-04 18:02:05,830][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 18:02:05,839][fairseq.trainer][INFO] - begin training epoch 125
[2023-07-04 18:02:05,839][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 18:02:23,398][train_inner][INFO] - {"epoch": 125, "update": 124.059, "loss": "24.825", "ntokens": "2482.33", "nsentences": "49.335", "nll_loss": "0.493", "wps": "4807.8", "ups": "1.94", "wpb": "2482.3", "bsz": "49.3", "num_updates": "71800", "lr": "2.77206e-06", "gnorm": "95.648", "loss_scale": "32", "train_wall": "91.97", "gb_free": "20.8", "wall": "29378"}
[2023-07-04 18:03:57,648][train_inner][INFO] - {"epoch": 125, "update": 124.404, "loss": "25.008", "ntokens": "2502.88", "nsentences": "49.885", "nll_loss": "0.498", "wps": "5313.9", "ups": "2.12", "wpb": "2502.9", "bsz": "49.9", "num_updates": "72000", "lr": "2.73085e-06", "gnorm": "96.633", "loss_scale": "32", "train_wall": "87.85", "gb_free": "20.8", "wall": "29472"}
[2023-07-04 18:05:30,673][train_inner][INFO] - {"epoch": 125, "update": 124.75, "loss": "24.406", "ntokens": "2497.14", "nsentences": "48.965", "nll_loss": "0.479", "wps": "5369.7", "ups": "2.15", "wpb": "2497.1", "bsz": "49", "num_updates": "72200", "lr": "2.69025e-06", "gnorm": "96.544", "loss_scale": "32", "train_wall": "88.19", "gb_free": "20.8", "wall": "29565"}
[2023-07-04 18:06:39,258][fairseq_cli.train][INFO] - begin validation on "dev_other" subset
[2023-07-04 18:06:55,955][dev_other][INFO] - {"epoch": 125, "dev_other_loss": "43.032", "dev_other_ntokens": "272.352", "dev_other_nsentences": "10.6074", "dev_other_nll_loss": "1.676", "dev_other_uer": "22.626", "dev_other_wer": "23.089", "dev_other_raw_wer": "23.089", "dev_other_wps": "4775.4", "dev_other_wpb": "272.4", "dev_other_bsz": "10.6", "dev_other_num_updates": "72345", "dev_other_best_wer": "23.089"}
[2023-07-04 18:06:55,960][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 125 @ 72345 updates
[2023-07-04 18:06:55,961][fairseq.trainer][INFO] - Saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt
[2023-07-04 18:07:00,602][fairseq.trainer][INFO] - Finished saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt
[2023-07-04 18:07:04,291][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt (epoch 125 @ 72345 updates, score 23.089) (writing took 8.33147456496954 seconds)
[2023-07-04 18:07:04,292][fairseq_cli.train][INFO] - end of epoch 125 (average epoch stats below)
[2023-07-04 18:07:04,387][train][INFO] - {"epoch": 125, "train_loss": "24.719", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.489", "train_wps": "4836.9", "train_ups": "1.94", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "72345", "train_lr": "2.66119e-06", "train_gnorm": "95.676", "train_loss_scale": "32", "train_train_wall": "255.19", "train_gb_free": "20.9", "train_wall": "29659"}
[2023-07-04 18:07:04,531][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 18:07:04,537][fairseq.trainer][INFO] - begin training epoch 126
[2023-07-04 18:07:04,537][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 18:07:34,998][train_inner][INFO] - {"epoch": 126, "update": 125.095, "loss": "24.796", "ntokens": "2486.45", "nsentences": "48.93", "nll_loss": "0.488", "wps": "4001.2", "ups": "1.61", "wpb": "2486.4", "bsz": "48.9", "num_updates": "72400", "lr": "2.65025e-06", "gnorm": "95.318", "loss_scale": "32", "train_wall": "91.03", "gb_free": "20.8", "wall": "29689"}
[2023-07-04 18:09:51,538][train_inner][INFO] - {"epoch": 126, "update": 125.44, "loss": "24.54", "ntokens": "2499.01", "nsentences": "49.11", "nll_loss": "0.482", "wps": "3679.7", "ups": "1.47", "wpb": "2499", "bsz": "49.1", "num_updates": "72600", "lr": "2.61085e-06", "gnorm": "93.795", "loss_scale": "32", "train_wall": "125.47", "gb_free": "20.8", "wall": "29825"}
[2023-07-04 18:11:56,377][train_inner][INFO] - {"epoch": 126, "update": 125.786, "loss": "24.322", "ntokens": "2494.47", "nsentences": "49.31", "nll_loss": "0.481", "wps": "4005.1", "ups": "1.61", "wpb": "2494.5", "bsz": "49.3", "num_updates": "72800", "lr": "2.57203e-06", "gnorm": "93.032", "loss_scale": "64", "train_wall": "116.57", "gb_free": "20.8", "wall": "29950"}
[2023-07-04 18:13:08,870][fairseq_cli.train][INFO] - end of epoch 126 (average epoch stats below)
[2023-07-04 18:13:08,996][train][INFO] - {"epoch": 126, "train_loss": "24.447", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.483", "train_wps": "3961.1", "train_ups": "1.59", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "72924", "train_lr": "2.54826e-06", "train_gnorm": "93.91", "train_loss_scale": "64", "train_train_wall": "339.95", "train_gb_free": "20.8", "train_wall": "30023"}
[2023-07-04 18:13:09,143][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 18:13:09,196][fairseq.trainer][INFO] - begin training epoch 127
[2023-07-04 18:13:09,197][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 18:13:47,254][train_inner][INFO] - {"epoch": 127, "update": 126.131, "loss": "24.66", "ntokens": "2488.98", "nsentences": "49.465", "nll_loss": "0.49", "wps": "4490.3", "ups": "1.8", "wpb": "2489", "bsz": "49.5", "num_updates": "73000", "lr": "2.5338e-06", "gnorm": "94.772", "loss_scale": "64", "train_wall": "106.95", "gb_free": "20.8", "wall": "30062"}
[2023-07-04 18:15:30,479][train_inner][INFO] - {"epoch": 127, "update": 126.477, "loss": "24.306", "ntokens": "2501.02", "nsentences": "49.22", "nll_loss": "0.478", "wps": "4846.6", "ups": "1.94", "wpb": "2501", "bsz": "49.2", "num_updates": "73200", "lr": "2.49613e-06", "gnorm": "94.955", "loss_scale": "64", "train_wall": "100.48", "gb_free": "20.7", "wall": "30165"}
[2023-07-04 18:17:05,815][train_inner][INFO] - {"epoch": 127, "update": 126.822, "loss": "24.02", "ntokens": "2482.12", "nsentences": "48.9", "nll_loss": "0.473", "wps": "5208", "ups": "2.1", "wpb": "2482.1", "bsz": "48.9", "num_updates": "73400", "lr": "2.45902e-06", "gnorm": "97.603", "loss_scale": "64", "train_wall": "91.62", "gb_free": "20.7", "wall": "30260"}
[2023-07-04 18:17:53,741][fairseq_cli.train][INFO] - end of epoch 127 (average epoch stats below)
[2023-07-04 18:17:53,752][train][INFO] - {"epoch": 127, "train_loss": "24.435", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.483", "train_wps": "5070.3", "train_ups": "2.03", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "73503", "train_lr": "2.44012e-06", "train_gnorm": "95.263", "train_loss_scale": "64", "train_train_wall": "274.68", "train_gb_free": "20.8", "train_wall": "30308"}
[2023-07-04 18:17:53,825][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 18:17:53,837][fairseq.trainer][INFO] - begin training epoch 128
[2023-07-04 18:17:53,838][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 18:18:37,842][train_inner][INFO] - {"epoch": 128, "update": 127.168, "loss": "24.752", "ntokens": "2484.98", "nsentences": "49.955", "nll_loss": "0.498", "wps": "5401.2", "ups": "2.17", "wpb": "2485", "bsz": "50", "num_updates": "73600", "lr": "2.42246e-06", "gnorm": "92.038", "loss_scale": "64", "train_wall": "88.7", "gb_free": "20.8", "wall": "30352"}
[2023-07-04 18:20:17,330][train_inner][INFO] - {"epoch": 128, "update": 127.513, "loss": "24.31", "ntokens": "2505.12", "nsentences": "49.195", "nll_loss": "0.477", "wps": "5037", "ups": "2.01", "wpb": "2505.1", "bsz": "49.2", "num_updates": "73800", "lr": "2.38644e-06", "gnorm": "95.135", "loss_scale": "64", "train_wall": "94.94", "gb_free": "20.8", "wall": "30452"}
[2023-07-04 18:22:03,606][train_inner][INFO] - {"epoch": 128, "update": 127.858, "loss": "24.871", "ntokens": "2491.88", "nsentences": "49.295", "nll_loss": "0.492", "wps": "4690.1", "ups": "1.88", "wpb": "2491.9", "bsz": "49.3", "num_updates": "74000", "lr": "2.35096e-06", "gnorm": "94.979", "loss_scale": "64", "train_wall": "101.34", "gb_free": "20.8", "wall": "30558"}
[2023-07-04 18:22:45,572][fairseq_cli.train][INFO] - end of epoch 128 (average epoch stats below)
[2023-07-04 18:22:45,592][train][INFO] - {"epoch": 128, "train_loss": "24.58", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.486", "train_wps": "4947.4", "train_ups": "1.98", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "74082", "train_lr": "2.33657e-06", "train_gnorm": "94.795", "train_loss_scale": "64", "train_train_wall": "279.04", "train_gb_free": "20.7", "train_wall": "30600"}
[2023-07-04 18:22:45,637][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 18:22:45,650][fairseq.trainer][INFO] - begin training epoch 129
[2023-07-04 18:22:45,651][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 18:23:43,200][train_inner][INFO] - {"epoch": 129, "update": 128.204, "loss": "25.229", "ntokens": "2499.16", "nsentences": "49.23", "nll_loss": "0.497", "wps": "5019.5", "ups": "2.01", "wpb": "2499.2", "bsz": "49.2", "num_updates": "74200", "lr": "2.31601e-06", "gnorm": "95.723", "loss_scale": "64", "train_wall": "93.55", "gb_free": "20.7", "wall": "30657"}
[2023-07-04 18:25:21,722][train_inner][INFO] - {"epoch": 129, "update": 128.549, "loss": "24.025", "ntokens": "2502.88", "nsentences": "49.55", "nll_loss": "0.476", "wps": "5081.4", "ups": "2.03", "wpb": "2502.9", "bsz": "49.5", "num_updates": "74400", "lr": "2.28158e-06", "gnorm": "94.863", "loss_scale": "64", "train_wall": "92.1", "gb_free": "20.8", "wall": "30756"}
[2023-07-04 18:26:08,396][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 32.0
[2023-07-04 18:27:06,207][train_inner][INFO] - {"epoch": 129, "update": 128.896, "loss": "24.773", "ntokens": "2477.64", "nsentences": "48.975", "nll_loss": "0.49", "wps": "4769.3", "ups": "1.92", "wpb": "2477.6", "bsz": "49", "num_updates": "74600", "lr": "2.24766e-06", "gnorm": "97.992", "loss_scale": "32", "train_wall": "96.49", "gb_free": "20.9", "wall": "30860"}
[2023-07-04 18:27:33,258][fairseq_cli.train][INFO] - end of epoch 129 (average epoch stats below)
[2023-07-04 18:27:33,267][train][INFO] - {"epoch": 129, "train_loss": "24.682", "train_ntokens": "2493.62", "train_nsentences": "49.2993", "train_nll_loss": "0.488", "train_wps": "5010.4", "train_ups": "2.01", "train_wpb": "2493.6", "train_bsz": "49.3", "train_num_updates": "74660", "train_lr": "2.23758e-06", "train_gnorm": "96.72", "train_loss_scale": "32", "train_train_wall": "267.92", "train_gb_free": "20.7", "train_wall": "30888"}
[2023-07-04 18:27:33,291][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 18:27:33,298][fairseq.trainer][INFO] - begin training epoch 130
[2023-07-04 18:27:33,299][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 18:28:40,333][train_inner][INFO] - {"epoch": 130, "update": 129.242, "loss": "24.868", "ntokens": "2499.26", "nsentences": "49.39", "nll_loss": "0.491", "wps": "5311.2", "ups": "2.13", "wpb": "2499.3", "bsz": "49.4", "num_updates": "74800", "lr": "2.21424e-06", "gnorm": "96.897", "loss_scale": "32", "train_wall": "88.42", "gb_free": "20.8", "wall": "30955"}
[2023-07-04 18:30:19,085][train_inner][INFO] - {"epoch": 130, "update": 129.587, "loss": "24.503", "ntokens": "2496.81", "nsentences": "49.395", "nll_loss": "0.485", "wps": "5057.3", "ups": "2.03", "wpb": "2496.8", "bsz": "49.4", "num_updates": "75000", "lr": "2.18132e-06", "gnorm": "93.857", "loss_scale": "32", "train_wall": "90.48", "gb_free": "20.8", "wall": "31053"}
[2023-07-04 18:31:57,603][train_inner][INFO] - {"epoch": 130, "update": 129.933, "loss": "24.647", "ntokens": "2486.67", "nsentences": "49.135", "nll_loss": "0.487", "wps": "5049.3", "ups": "2.03", "wpb": "2486.7", "bsz": "49.1", "num_updates": "75200", "lr": "2.14889e-06", "gnorm": "93.773", "loss_scale": "32", "train_wall": "95.87", "gb_free": "20.9", "wall": "31152"}
[2023-07-04 18:32:17,276][fairseq_cli.train][INFO] - begin validation on "dev_other" subset
[2023-07-04 18:32:35,439][dev_other][INFO] - {"epoch": 130, "dev_other_loss": "43.088", "dev_other_ntokens": "272.352", "dev_other_nsentences": "10.6074", "dev_other_nll_loss": "1.678", "dev_other_uer": "22.508", "dev_other_wer": "22.985", "dev_other_raw_wer": "22.985", "dev_other_wps": "4423.7", "dev_other_wpb": "272.4", "dev_other_bsz": "10.6", "dev_other_num_updates": "75239", "dev_other_best_wer": "22.985"}
[2023-07-04 18:32:35,458][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 130 @ 75239 updates
[2023-07-04 18:32:35,459][fairseq.trainer][INFO] - Saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt
[2023-07-04 18:32:40,703][fairseq.trainer][INFO] - Finished saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt
[2023-07-04 18:32:44,333][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt (epoch 130 @ 75239 updates, score 22.985) (writing took 8.874957790598273 seconds)
[2023-07-04 18:32:44,333][fairseq_cli.train][INFO] - end of epoch 130 (average epoch stats below)
[2023-07-04 18:32:44,348][train][INFO] - {"epoch": 130, "train_loss": "24.658", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.487", "train_wps": "4641.3", "train_ups": "1.86", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "75239", "train_lr": "2.14263e-06", "train_gnorm": "94.08", "train_loss_scale": "32", "train_train_wall": "267.46", "train_gb_free": "20.8", "train_wall": "31199"}
[2023-07-04 18:32:44,393][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 18:32:44,402][fairseq.trainer][INFO] - begin training epoch 131
[2023-07-04 18:32:44,402][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 18:34:06,551][train_inner][INFO] - {"epoch": 131, "update": 130.278, "loss": "24.692", "ntokens": "2490.59", "nsentences": "49.31", "nll_loss": "0.489", "wps": "3863.5", "ups": "1.55", "wpb": "2490.6", "bsz": "49.3", "num_updates": "75400", "lr": "2.11695e-06", "gnorm": "95.37", "loss_scale": "32", "train_wall": "97.84", "gb_free": "20.8", "wall": "31281"}
[2023-07-04 18:35:43,486][train_inner][INFO] - {"epoch": 131, "update": 130.623, "loss": "24.217", "ntokens": "2488.43", "nsentences": "49.25", "nll_loss": "0.479", "wps": "5135.1", "ups": "2.06", "wpb": "2488.4", "bsz": "49.2", "num_updates": "75600", "lr": "2.08547e-06", "gnorm": "92.662", "loss_scale": "32", "train_wall": "94.18", "gb_free": "20.8", "wall": "31378"}
[2023-07-04 18:37:23,674][train_inner][INFO] - {"epoch": 131, "update": 130.969, "loss": "24.453", "ntokens": "2499.87", "nsentences": "49.505", "nll_loss": "0.484", "wps": "4992.4", "ups": "2", "wpb": "2499.9", "bsz": "49.5", "num_updates": "75800", "lr": "2.05447e-06", "gnorm": "94.796", "loss_scale": "32", "train_wall": "96.22", "gb_free": "20.8", "wall": "31478"}
[2023-07-04 18:37:31,925][fairseq_cli.train][INFO] - end of epoch 131 (average epoch stats below)
[2023-07-04 18:37:31,949][train][INFO] - {"epoch": 131, "train_loss": "24.49", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.484", "train_wps": "5020.4", "train_ups": "2.01", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "75818", "train_lr": "2.0517e-06", "train_gnorm": "94.673", "train_loss_scale": "32", "train_train_wall": "277.19", "train_gb_free": "20.7", "train_wall": "31486"}
[2023-07-04 18:37:31,983][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 18:37:32,011][fairseq.trainer][INFO] - begin training epoch 132
[2023-07-04 18:37:32,012][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 18:39:01,869][train_inner][INFO] - {"epoch": 132, "update": 131.314, "loss": "24.991", "ntokens": "2489.61", "nsentences": "49.06", "nll_loss": "0.492", "wps": "5071.6", "ups": "2.04", "wpb": "2489.6", "bsz": "49.1", "num_updates": "76000", "lr": "2.02392e-06", "gnorm": "94.306", "loss_scale": "32", "train_wall": "93.27", "gb_free": "20.8", "wall": "31576"}
[2023-07-04 18:40:40,930][train_inner][INFO] - {"epoch": 132, "update": 131.66, "loss": "24.28", "ntokens": "2497.18", "nsentences": "49.195", "nll_loss": "0.478", "wps": "5042.4", "ups": "2.02", "wpb": "2497.2", "bsz": "49.2", "num_updates": "76200", "lr": "1.99383e-06", "gnorm": "92.988", "loss_scale": "32", "train_wall": "95.44", "gb_free": "20.7", "wall": "31675"}
[2023-07-04 18:42:21,878][fairseq_cli.train][INFO] - end of epoch 132 (average epoch stats below)
[2023-07-04 18:42:21,916][train][INFO] - {"epoch": 132, "train_loss": "24.465", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.484", "train_wps": "4979.7", "train_ups": "2", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "76397", "train_lr": "1.96463e-06", "train_gnorm": "93.425", "train_loss_scale": "32", "train_train_wall": "274.53", "train_gb_free": "20.8", "train_wall": "31776"}
[2023-07-04 18:42:21,988][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 18:42:21,998][fairseq.trainer][INFO] - begin training epoch 133
[2023-07-04 18:42:21,998][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 18:42:23,860][train_inner][INFO] - {"epoch": 133, "update": 132.005, "loss": "24.328", "ntokens": "2494.8", "nsentences": "49.395", "nll_loss": "0.482", "wps": "4848.2", "ups": "1.94", "wpb": "2494.8", "bsz": "49.4", "num_updates": "76400", "lr": "1.96419e-06", "gnorm": "93.841", "loss_scale": "32", "train_wall": "95.16", "gb_free": "20.8", "wall": "31778"}
[2023-07-04 18:44:01,193][train_inner][INFO] - {"epoch": 133, "update": 132.351, "loss": "24.57", "ntokens": "2491.89", "nsentences": "49.22", "nll_loss": "0.485", "wps": "5121", "ups": "2.06", "wpb": "2491.9", "bsz": "49.2", "num_updates": "76600", "lr": "1.93499e-06", "gnorm": "93.749", "loss_scale": "64", "train_wall": "91.08", "gb_free": "20.8", "wall": "31875"}
[2023-07-04 18:45:36,114][train_inner][INFO] - {"epoch": 133, "update": 132.696, "loss": "25.171", "ntokens": "2491.14", "nsentences": "49.145", "nll_loss": "0.497", "wps": "5249.7", "ups": "2.11", "wpb": "2491.1", "bsz": "49.1", "num_updates": "76800", "lr": "1.90622e-06", "gnorm": "97.595", "loss_scale": "64", "train_wall": "88.65", "gb_free": "20.8", "wall": "31970"}
[2023-07-04 18:47:01,777][fairseq_cli.train][INFO] - end of epoch 133 (average epoch stats below)
[2023-07-04 18:47:02,101][train][INFO] - {"epoch": 133, "train_loss": "24.678", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.488", "train_wps": "5158.8", "train_ups": "2.07", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "76976", "train_lr": "1.88126e-06", "train_gnorm": "95.509", "train_loss_scale": "64", "train_train_wall": "261.57", "train_gb_free": "20.8", "train_wall": "32056"}
[2023-07-04 18:47:02,143][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 18:47:02,150][fairseq.trainer][INFO] - begin training epoch 134
[2023-07-04 18:47:02,150][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 18:47:14,689][train_inner][INFO] - {"epoch": 134, "update": 133.041, "loss": "24.09", "ntokens": "2496.18", "nsentences": "49.66", "nll_loss": "0.479", "wps": "5067.1", "ups": "2.03", "wpb": "2496.2", "bsz": "49.7", "num_updates": "77000", "lr": "1.87788e-06", "gnorm": "94.351", "loss_scale": "64", "train_wall": "91.91", "gb_free": "20.8", "wall": "32069"}
[2023-07-04 18:48:53,878][train_inner][INFO] - {"epoch": 134, "update": 133.387, "loss": "24.757", "ntokens": "2507.28", "nsentences": "49.37", "nll_loss": "0.487", "wps": "5056.4", "ups": "2.02", "wpb": "2507.3", "bsz": "49.4", "num_updates": "77200", "lr": "1.84996e-06", "gnorm": "95.82", "loss_scale": "64", "train_wall": "95.08", "gb_free": "20.7", "wall": "32168"}
[2023-07-04 18:50:27,146][train_inner][INFO] - {"epoch": 134, "update": 133.732, "loss": "24.328", "ntokens": "2484.53", "nsentences": "49.345", "nll_loss": "0.483", "wps": "5328.5", "ups": "2.14", "wpb": "2484.5", "bsz": "49.3", "num_updates": "77400", "lr": "1.82246e-06", "gnorm": "93.631", "loss_scale": "64", "train_wall": "90.97", "gb_free": "20.8", "wall": "32261"}
[2023-07-04 18:51:39,868][fairseq_cli.train][INFO] - end of epoch 134 (average epoch stats below)
[2023-07-04 18:51:39,884][train][INFO] - {"epoch": 134, "train_loss": "24.348", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.481", "train_wps": "5197.7", "train_ups": "2.08", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "77555", "train_lr": "1.80143e-06", "train_gnorm": "94.882", "train_loss_scale": "64", "train_train_wall": "268.43", "train_gb_free": "20.8", "train_wall": "32334"}
[2023-07-04 18:51:39,926][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 18:51:39,938][fairseq.trainer][INFO] - begin training epoch 135
[2023-07-04 18:51:39,939][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 18:52:01,995][train_inner][INFO] - {"epoch": 135, "update": 134.078, "loss": "24.356", "ntokens": "2487.09", "nsentences": "49.185", "nll_loss": "0.482", "wps": "5245.2", "ups": "2.11", "wpb": "2487.1", "bsz": "49.2", "num_updates": "77600", "lr": "1.79537e-06", "gnorm": "95.768", "loss_scale": "64", "train_wall": "92.02", "gb_free": "20.8", "wall": "32356"}
[2023-07-04 18:53:36,429][train_inner][INFO] - {"epoch": 135, "update": 134.423, "loss": "24.032", "ntokens": "2494.28", "nsentences": "49.355", "nll_loss": "0.476", "wps": "5283.4", "ups": "2.12", "wpb": "2494.3", "bsz": "49.4", "num_updates": "77800", "lr": "1.76867e-06", "gnorm": "94.905", "loss_scale": "64", "train_wall": "92", "gb_free": "20.9", "wall": "32451"}
[2023-07-04 18:55:07,602][train_inner][INFO] - {"epoch": 135, "update": 134.769, "loss": "24.677", "ntokens": "2491.01", "nsentences": "49.125", "nll_loss": "0.487", "wps": "5465.7", "ups": "2.19", "wpb": "2491", "bsz": "49.1", "num_updates": "78000", "lr": "1.74238e-06", "gnorm": "93.56", "loss_scale": "64", "train_wall": "88.06", "gb_free": "20.8", "wall": "32542"}
[2023-07-04 18:56:10,580][fairseq_cli.train][INFO] - begin validation on "dev_other" subset
[2023-07-04 18:56:25,895][dev_other][INFO] - {"epoch": 135, "dev_other_loss": "43.038", "dev_other_ntokens": "272.352", "dev_other_nsentences": "10.6074", "dev_other_nll_loss": "1.676", "dev_other_uer": "22.547", "dev_other_wer": "22.983", "dev_other_raw_wer": "22.983", "dev_other_wps": "4910.7", "dev_other_wpb": "272.4", "dev_other_bsz": "10.6", "dev_other_num_updates": "78134", "dev_other_best_wer": "22.983"}
[2023-07-04 18:56:25,898][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 135 @ 78134 updates
[2023-07-04 18:56:25,899][fairseq.trainer][INFO] - Saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt
[2023-07-04 18:56:28,752][fairseq.trainer][INFO] - Finished saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt
[2023-07-04 18:56:32,581][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt (epoch 135 @ 78134 updates, score 22.983) (writing took 6.682574227452278 seconds)
[2023-07-04 18:56:32,581][fairseq_cli.train][INFO] - end of epoch 135 (average epoch stats below)
[2023-07-04 18:56:32,645][train][INFO] - {"epoch": 135, "train_loss": "24.403", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.482", "train_wps": "4932.6", "train_ups": "1.98", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "78134", "train_lr": "1.72498e-06", "train_gnorm": "94.364", "train_loss_scale": "64", "train_train_wall": "262.85", "train_gb_free": "20.9", "train_wall": "32627"}
[2023-07-04 18:56:32,675][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 18:56:32,681][fairseq.trainer][INFO] - begin training epoch 136
[2023-07-04 18:56:32,681][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 18:57:04,312][train_inner][INFO] - {"epoch": 136, "update": 135.114, "loss": "24.584", "ntokens": "2500.44", "nsentences": "49.11", "nll_loss": "0.483", "wps": "4286", "ups": "1.71", "wpb": "2500.4", "bsz": "49.1", "num_updates": "78200", "lr": "1.71648e-06", "gnorm": "96.172", "loss_scale": "64", "train_wall": "91.95", "gb_free": "20.7", "wall": "32659"}
[2023-07-04 18:58:38,824][train_inner][INFO] - {"epoch": 136, "update": 135.459, "loss": "24.259", "ntokens": "2495.39", "nsentences": "49.04", "nll_loss": "0.477", "wps": "5281.5", "ups": "2.12", "wpb": "2495.4", "bsz": "49", "num_updates": "78400", "lr": "1.69096e-06", "gnorm": "93.02", "loss_scale": "64", "train_wall": "93.46", "gb_free": "20.8", "wall": "32753"}
[2023-07-04 19:00:10,713][train_inner][INFO] - {"epoch": 136, "update": 135.805, "loss": "24.304", "ntokens": "2490.68", "nsentences": "49.465", "nll_loss": "0.483", "wps": "5421.7", "ups": "2.18", "wpb": "2490.7", "bsz": "49.5", "num_updates": "78600", "lr": "1.66582e-06", "gnorm": "95.861", "loss_scale": "128", "train_wall": "89.47", "gb_free": "20.8", "wall": "32845"}
[2023-07-04 19:01:01,815][fairseq_cli.train][INFO] - end of epoch 136 (average epoch stats below)
[2023-07-04 19:01:01,827][train][INFO] - {"epoch": 136, "train_loss": "24.35", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.481", "train_wps": "5363.7", "train_ups": "2.15", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "78713", "train_lr": "1.65178e-06", "train_gnorm": "94.745", "train_loss_scale": "128", "train_train_wall": "263.85", "train_gb_free": "20.8", "train_wall": "32896"}
[2023-07-04 19:01:01,865][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 19:01:01,873][fairseq.trainer][INFO] - begin training epoch 137
[2023-07-04 19:01:01,874][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 19:01:41,159][train_inner][INFO] - {"epoch": 137, "update": 136.15, "loss": "24.253", "ntokens": "2491.6", "nsentences": "49.565", "nll_loss": "0.482", "wps": "5510.2", "ups": "2.21", "wpb": "2491.6", "bsz": "49.6", "num_updates": "78800", "lr": "1.64105e-06", "gnorm": "92.735", "loss_scale": "128", "train_wall": "88.59", "gb_free": "20.8", "wall": "32935"}
[2023-07-04 19:03:11,603][train_inner][INFO] - {"epoch": 137, "update": 136.496, "loss": "24.615", "ntokens": "2501.05", "nsentences": "49.21", "nll_loss": "0.484", "wps": "5531.2", "ups": "2.21", "wpb": "2501", "bsz": "49.2", "num_updates": "79000", "lr": "1.61665e-06", "gnorm": "94.535", "loss_scale": "128", "train_wall": "88.47", "gb_free": "20.8", "wall": "33026"}
[2023-07-04 19:04:36,398][fairseq.trainer][INFO] - NOTE: gradient overflow detected, ignoring gradient, setting loss scale to: 64.0
[2023-07-04 19:04:45,364][train_inner][INFO] - {"epoch": 137, "update": 136.843, "loss": "23.978", "ntokens": "2490.55", "nsentences": "48.87", "nll_loss": "0.47", "wps": "5313.1", "ups": "2.13", "wpb": "2490.6", "bsz": "48.9", "num_updates": "79200", "lr": "1.59262e-06", "gnorm": "94.042", "loss_scale": "64", "train_wall": "89.91", "gb_free": "20.8", "wall": "33120"}
[2023-07-04 19:05:29,427][fairseq_cli.train][INFO] - end of epoch 137 (average epoch stats below)
[2023-07-04 19:05:29,436][train][INFO] - {"epoch": 137, "train_loss": "24.407", "train_ntokens": "2493.79", "train_nsentences": "49.2889", "train_nll_loss": "0.482", "train_wps": "5386.4", "train_ups": "2.16", "train_wpb": "2493.8", "train_bsz": "49.3", "train_num_updates": "79291", "train_lr": "1.5818e-06", "train_gnorm": "93.835", "train_loss_scale": "64", "train_train_wall": "258.74", "train_gb_free": "20.8", "train_wall": "33164"}
[2023-07-04 19:05:29,455][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 19:05:29,461][fairseq.trainer][INFO] - begin training epoch 138
[2023-07-04 19:05:29,462][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 19:06:22,501][train_inner][INFO] - {"epoch": 138, "update": 137.188, "loss": "24.725", "ntokens": "2492.07", "nsentences": "49.525", "nll_loss": "0.491", "wps": "5131.6", "ups": "2.06", "wpb": "2492.1", "bsz": "49.5", "num_updates": "79400", "lr": "1.56894e-06", "gnorm": "94.389", "loss_scale": "64", "train_wall": "92.07", "gb_free": "20.7", "wall": "33217"}
[2023-07-04 19:07:56,733][train_inner][INFO] - {"epoch": 138, "update": 137.534, "loss": "24.105", "ntokens": "2491.29", "nsentences": "49.715", "nll_loss": "0.481", "wps": "5288.1", "ups": "2.12", "wpb": "2491.3", "bsz": "49.7", "num_updates": "79600", "lr": "1.54562e-06", "gnorm": "92.229", "loss_scale": "64", "train_wall": "87.49", "gb_free": "20.8", "wall": "33311"}
[2023-07-04 19:09:30,122][train_inner][INFO] - {"epoch": 138, "update": 137.879, "loss": "23.57", "ntokens": "2503.86", "nsentences": "48.64", "nll_loss": "0.458", "wps": "5362.8", "ups": "2.14", "wpb": "2503.9", "bsz": "48.6", "num_updates": "79800", "lr": "1.52264e-06", "gnorm": "91.988", "loss_scale": "64", "train_wall": "89.74", "gb_free": "20.8", "wall": "33404"}
[2023-07-04 19:10:03,114][fairseq_cli.train][INFO] - end of epoch 138 (average epoch stats below)
[2023-07-04 19:10:03,123][train][INFO] - {"epoch": 138, "train_loss": "23.946", "train_ntokens": "2493.53", "train_nsentences": "49.2902", "train_nll_loss": "0.473", "train_wps": "5275.3", "train_ups": "2.12", "train_wpb": "2493.5", "train_bsz": "49.3", "train_num_updates": "79870", "train_lr": "1.51468e-06", "train_gnorm": "92.694", "train_loss_scale": "64", "train_train_wall": "258.48", "train_gb_free": "20.8", "train_wall": "33437"}
[2023-07-04 19:10:03,138][fairseq.data.iterators][INFO] - grouped total_num_itrs = 579
[2023-07-04 19:10:03,143][fairseq.trainer][INFO] - begin training epoch 139
[2023-07-04 19:10:03,144][fairseq_cli.train][INFO] - Start iterating over samples
[2023-07-04 19:11:02,957][train_inner][INFO] - {"epoch": 139, "update": 138.225, "loss": "23.598", "ntokens": "2489.76", "nsentences": "49.54", "nll_loss": "0.47", "wps": "5364.5", "ups": "2.15", "wpb": "2489.8", "bsz": "49.5", "num_updates": "80000", "lr": "1.5e-06", "gnorm": "94.06", "loss_scale": "64", "train_wall": "88.87", "gb_free": "20.8", "wall": "33497"}
[2023-07-04 19:11:02,958][fairseq_cli.train][INFO] - Stopping training due to num_updates: 80000 >= max_update: 80000
[2023-07-04 19:11:02,959][fairseq_cli.train][INFO] - begin validation on "dev_other" subset
[2023-07-04 19:11:19,143][dev_other][INFO] - {"epoch": 139, "dev_other_loss": "43.174", "dev_other_ntokens": "272.352", "dev_other_nsentences": "10.6074", "dev_other_nll_loss": "1.681", "dev_other_uer": "22.512", "dev_other_wer": "22.914", "dev_other_raw_wer": "22.914", "dev_other_wps": "4915.8", "dev_other_wpb": "272.4", "dev_other_bsz": "10.6", "dev_other_num_updates": "80000", "dev_other_best_wer": "22.914"}
[2023-07-04 19:11:19,146][fairseq.checkpoint_utils][INFO] - Preparing to save checkpoint for epoch 139 @ 80000 updates
[2023-07-04 19:11:19,147][fairseq.trainer][INFO] - Saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt
[2023-07-04 19:11:24,866][fairseq.trainer][INFO] - Finished saving checkpoint to /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt
[2023-07-04 19:11:27,991][fairseq.checkpoint_utils][INFO] - Saved checkpoint /mnt/lustre/sjtu/home/gry10/fairseq/debug/checkpoint_best.pt (epoch 139 @ 80000 updates, score 22.914) (writing took 8.844650680199265 seconds)
[2023-07-04 19:11:27,993][fairseq_cli.train][INFO] - end of epoch 139 (average epoch stats below)
[2023-07-04 19:11:28,002][train][INFO] - {"epoch": 139, "train_loss": "23.711", "train_ntokens": "2503.09", "train_nsentences": "49.1", "train_nll_loss": "0.465", "train_wps": "3834.1", "train_ups": "1.53", "train_wpb": "2503.1", "train_bsz": "49.1", "train_num_updates": "80000", "train_lr": "1.5e-06", "train_gnorm": "94.643", "train_loss_scale": "64", "train_train_wall": "57.38", "train_gb_free": "20.8", "train_wall": "33522"}
[2023-07-04 19:11:28,003][fairseq_cli.train][INFO] - done training in 33522.1 seconds


"dev_other_best_wer": "22.914" 